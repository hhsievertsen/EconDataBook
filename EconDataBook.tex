% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Introduction to Economic Data},
  pdfauthor={Hans Henrik Sievertsen},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Introduction to Economic Data}
\author{Hans Henrik Sievertsen}
\date{2022-11-08}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{welcome}{%
\chapter*{Welcome}\label{welcome}}
\addcontentsline{toc}{chapter}{Welcome}

This book is written for Economics students at the University of Bristol to bridge the gap between technical documents about economic concepts and textbook treatments of economic concepts. Each chapter concludes with some suggestions for further readings.

Please let me know if you find mistakes, find a section unclear, or if you have suggestions for improvements. You can contact me on \href{mailto:h.h.sievertsen@bristol.ac.uk}{\nolinkurl{h.h.sievertsen@bristol.ac.uk}}.\footnote{I owe a big thanks to all students who have contributed to this book, especially to Viktoria Leins who updated several figures and identified numerous mistakes.}

Thanks,
Hans
Last updated on Tuesday, November 08, 2022

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{a-first-look-at-data}{%
\subsubsection*{A first look at data}\label{a-first-look-at-data}}
\addcontentsline{toc}{subsubsection}{A first look at data}

Figure \ref{fig:fig1} shows a line chart of annual levels of economic activity per person in the United Kingdom based on data from the Maddison Project Database (MPD) 2018.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./resources/chapter_introduction/fig1} 

}

\caption{GDP per capita in the United Kingdom. Source: Maddison Project Database (MPD) 2018.}\label{fig:fig1}
\end{figure}

The chart is a good illustration of the core topics of this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{What is the chart showing?} The chart shows economic activity per person measured as the Gross Domestic Product (also known as GDP) per person. But what is the GDP? Is the number of persons in the United Kingdom measured at the beginning or the end of the year? We cover definitions of economic data concepts such as GDP, unemployment, and prices in part I.
\item
  \textbf{Where does the data come from?} We know that the data source for Figure \ref{fig:fig1} is the Maddison Project Database (MPD) 2018, but where do they get the data from? How can we download the data to create our own chart? We will cover data basics in part II.
\item
  \textbf{Why did we use a chart?} The chart is known as the ``History's hockey stick,'' because the line chart has the shape of a hockey stick. The hockey stick shape is all that we want the reader to remember, because it represents the overall long term trend. If we wanted to reader to remember a precise value, we would have used a table like the one shown in Figure \ref{fig:fig2}.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./resources/chapter_introduction/table1} 

}

\caption{GDP per capita in the United Kingdom. Source: Maddison Project Database (MPD) 2018.}\label{fig:fig2}
\end{figure}

However, this table does a poor job in communicating the overall trend. How do we know whether to use a table or a chart? How do we design a table or chart? We will cover basic data visualisation techniques in part II.

\hypertarget{part-i-working-with-economic-data}{%
\chapter*{Part I: Working with Economic Data}\label{part-i-working-with-economic-data}}
\addcontentsline{toc}{chapter}{Part I: Working with Economic Data}

\hypertarget{po}{%
\chapter{People}\label{po}}

\hypertarget{what-this-chapter-is-about}{%
\section{What this chapter is about}\label{what-this-chapter-is-about}}

Economics is about people. As the Bristol economist Alfred Marshall wrote in the first chapter of the book ``Principles of Economics'' in 1890, \emph{``{[}\ldots{]} economics is a study of mankind in the ordinary business of life''}. In other words, economics is about the interactions and behaviours of normal people in their day to day life. A good starting point for working with economic data is therefore data about people. This chapter is about how to describe changes in the number of people in a region, about quantifying fertility and about measuring life expectancy.

After reading this chapter you should be able to apply the following concepts.

\begin{itemize}
\tightlist
\item
  Distinguishing between stock and flow variables
\item
  Quantifying fertility trends
\item
  Estimating period life expectancy
\end{itemize}

\hypertarget{population-stocks-and-flows}{%
\section{Population stocks and flows}\label{population-stocks-and-flows}}

\hypertarget{what-are-flow-and-stock-variables}{%
\subsection{What are flow and stock variables?}\label{what-are-flow-and-stock-variables}}

Economic variables can be classified as either flow or stock variables. We can illustrate the difference between these two types using a bathtub as in Figure \ref{fig:baththub}. The water level in the bathtub at a given point in time is a stock variable. The amount of water that has flown into the tub over a period of time is a flow variable.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_people/flowbathtub} 

}

\caption{A bathtub with water illustrating flows and stocks}\label{fig:baththub}
\end{figure}

An easy way to distinguish between flow and stock variables is that a flow variable is measured over a \emph{period} of time while a stock variable is measured at a specific \emph{point} in time.

If someone asked you, ``How much water flowed into the bathtub on September 4 at 4:40pm and 10 seconds?'', it would be very difficult to answer because it is difficult to measure the amount of water flowing at a specific second.

However, if someone asked, ``How much water was in the bathtub on September 4 at 4:40pm and 10 seconds?'', it would be quite easy to answer (given that you had some tool to measure the level of water). This is because the water level is a stock variable. A stock variable is measured at a point in time and ``September 4, at 4:40pm and 10 seconds'' is a point in time.

On the other hand if someone asked ``How much water flowed into the bathtub between September 4 between 4:40pm and 4:50pm?'', you would also be able to answer it, because you are now given a ``period of time'' (a period of 10 minutes) which means you are measuring a flow variable.

Let's think about economic variables instead of water and bathtubs. An example of a stock variable would be wealth. We measure wealth at a ``point in time''. For example my wealth at the end of the year. An example of a flow variable would be income. We measure income over a period of time. Can you think of other examples? Is consumption a flow or a stock variable? For example my monthly income.

\begin{myblock}
\textbf{Flow variable and stock variables}

\begin{itemize}
\tightlist
\item
  A \emph{flow} variable measures a flow of quantity over a
  \emph{period} of time.

  \begin{itemize}
  \tightlist
  \item
    For example the flow of migrants into the UK from January 1 2017 to
    December 31 2017.
  \end{itemize}
\item
  A \emph{stock} variable measures the level of quantity at a
  \emph{point} in time.

  \begin{itemize}
  \tightlist
  \item
    For example the number of people residing in the UK on January 1,
    2018.
  \end{itemize}
\end{itemize}
\end{myblock}

Why is it important to know whether a variable is a flow or stock variable? First, because it is useful if we want to understand changes in a variable over time. The change in the water level of the bathtub (stock) can be described by the inflow (flow) and outflow (flow) of water. The change in wealth (stock) between two points in time depends on the income (flow) and consumption (flow) in the period of time. Second, because the best way to visualize the data depends on the type of variable.

We can often describe the change in a stock variable by underlying flows:

\[ Stock_{1}-Stock_{0}=\Delta Stock=Flow_{0-1} \]

Here we use subscript to denote the point in time (i.e.~time 0 and time 1), and the symbol \(\Delta\) to denote changes (it's the Greek letter ``Delta'' capitalized). This notation is very common in economics.

For example the change in the population level of the UK from 1 January, 2002 to 1 January, 2003 equals

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the number of people who immigrated to the UK
\item
  minus the number of people who left the UK (emigrated)
\item
  plus the number of children born
\item
  minus the number of people who died
\end{enumerate}

In this example the population level is a stock variable. It is measured at a point in time (January 1, 2002). The other variables are all flow variables that are measured over a period of time. For example the number of births from 1 January 2002 to 1 January, 2003.

We could measure the number of people living in the UK on January 1, 2002 at five seconds and 3 milliseconds after 10:00AM, but how many children are born in exactly that millisecond? A childbirth typically takes more than a second, so how do we allocate a birth a precise millisecond?

\hypertarget{quantifying-fertility-trends}{%
\section{Quantifying fertility trends}\label{quantifying-fertility-trends}}

We can describe changes in population stocks between two points in time by the underlying population flows. However, we can also dig deeper and get a detailed understanding of changes in population flows. One important reason for changes in population stocks is a change in childbirths. If more children are born, without any changes to the number of people dying or in the number of people migrating, the population stock will increase.

We use a number of specific definitions for descriptions of changes in childbirths over time and differences across regions. Let's first present these definitions and then discuss data requirements and what the definitions mean.

\hypertarget{definitions}{%
\subsection{Definitions}\label{definitions}}

\begin{itemize}
\item
  \emph{Age Specific Fertility Rate (ASFR)}

  The number of childbirths per woman in a specific age group.

  \begin{align}
        ASFR_a=\frac{\text{Number of births to women in age group} a}{\text{Number of  women in age     group} a}
    \end{align}
\item
  \emph{Total Fertility Rate (TFR)}:

  The number of children born per woman if she were to pass through the childbearing years (typically set to: 15-44y or 15-49y) bearing children according to current age-specific fertility rates.

  \begin{align}
    \text{Total Fertility Rate}=\sum_{a=15}^{44}ASFR_a
  \end{align}
\item
  \emph{General Fertility Rate (GFR)}

  All live births per woman of childbearing ages (also typically per 1000 women).

  \begin{align}
    \text{General Fertility Rate}=\frac{\text{Number of births }}{\text{Number of  women of childbearing age} }
  \end{align}
\item
  \emph{Crude Birth Rate (CBR)}
\end{itemize}

All live births per 1000 people of all ages
\begin{align}
    CBR=\frac{\text{Number of births }}{\text{Population size} }
  \end{align}

\hypertarget{data-requirements}{%
\subsection{Data requirements}\label{data-requirements}}

In order to be able to calculate the fertility rates described above we need data on:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the number of children born by women in specific age groups.
\item
  the number of women in each age group.
\item
  number of people in the population.
\end{enumerate}

\textbf{Note} that 1. above is a flow variable and 2. and 3. are stock variables. When calculating fertility rates we divide a flow variable with a stock variable. It is therefore important to pay attention to the timing of the measurement. Should the population levels (2. and 3.) be measured at the beginning, in the middle, or at the end of the year?

We can obtain such data from statistical agencies such as Eurostat. In Figure \ref{fig:death1}) we show the Total Fertility Rate and General Fertility Rate for the United Kingdom over the last five decades using data from Eurostat. We observe how the two lines representing respectively the General Fertility Rate and the Total Fertility Rate follow each other closely, although they are measured at very different scales. In 1970 a woman in the UK gave birth to on average more than 2.3 children, given the age specific fertility rates in that year. Today that number has dropped to less than 2. There are considerable fluctuations in these rates. The lowest fertility rates were observed around 2000, when the Total Fertility Rate dropped to around 1.8.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_people/fig10} 

}

\caption{Fertility rates for the United Kingdom. Data source: Eurostat. Note: Only births of women aged 15-45 are included.}\label{fig:death1}
\end{figure}

\hypertarget{relating-the-fertility-measures-to-each-other}{%
\subsection{Relating the fertility measures to each other}\label{relating-the-fertility-measures-to-each-other}}

Why do we have different fertility measures and what do they say? When thinking about fertility in layman's terms, we typically think about the number of children a woman will give birth to in her life. It is an easily understandable hypothetical measure of fertility, which is captured by the Total Fertility Rate. It is hypothetical because we sum the age-specific fertility measures across ages at a given point in time. Any woman in this sample will of course only be included in one of the age specific fertility rates and contribute to that value. We impute the total fertility rate by summing over a lot of different age groups, who will be at different ages at different points in time.

The General Fertility Rate on the other hand gives information about the number of new children relative to the number of women of childbearing ages. It is therefore an actual (and not a hypothetical) number. This is a refinement of the Crude Birth Rate by taking into account the share of women in the population. To sum up, we should use the Total Fertility Rate to describe the fertility (behavior) and General Fertility Rate and CBR to describe the ``number of individuals'' added to the society. How does the General Fertility Rate relate to the Total Fertility Rate?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The number of women in each age group varies
\item
  The fertility rate varies across age groups.
\end{enumerate}

If one of these sources is constant, the Total Fertility Rate will be the same as the General Fertility rate.

\textbf{What can we learn from the chart?}

So why did we combine the two line charts in Figure \ref{fig:death1}? Firstly, the goal was to investigate the link between these two series. The graph is scaled in a way such that the Total Fertility Rate should perfectly overlay the General Fertility Rate if they are the same (that is the level on the right vertical axis is equal to 31 times the corresponding value on the left axis). This is clearly not the case, but we see that the gap narrowed in the early 2000s. This will be the case if the age groups with higher age specific fertility rates are larger.

If every age group has the same fertility rates across years, but the number of people in an age group with a relatively high age specific fertility rate is larger next year compared to this year, the General Fertility Rate will increase, but the Total Fertility Rate will be unchanged.

\hypertarget{decomposing-the-development-in-childbirths}{%
\subsection{Decomposing the development in childbirths}\label{decomposing-the-development-in-childbirths}}

In the year 2000 the number of childbirths in England and Wales was 604,441. 16 years later, in 2016, the number of childbirths was 91,830 higher, at 696,271. What caused this increase? We can mechanically decompose this change into the two underlying factors:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The number of women in England and Wales of childbearing age.
\item
  The General Fertility Rate.
\end{enumerate}

It could be the case that the number of childbirths increased because there are more women of childbearing ages. The fertility behaviour of these women was actually unchanged (in other words, the General Fertility Rate was constant). It could also be the case that the number of women of childbearing age stayed constant, but that the General Fertility Rate increased. Or it could be a mixture of both.

We can use the following formula to decompose the change in childbirths. Let \(\Delta X\) be the change in childbirths. We can then write this change as:

\begin{align}
    \Delta X&=Y_1\frac{X_1}{Y_1}-Y_0\frac{X_0}{Y_0}\nonumber\\
\Rightarrow &=\overbrace{Y_0\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)}^{A}+\overbrace{\left(Y_1-Y_0\right)\frac{X_0}{Y_0}}^{B}+
    \overbrace{\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)\left(Y_1-Y_0\right)}^{C}
\end{align}

Where General Fertility Rate is the ratio \(X/Y\) and the number of women of childbearing age is \(Y\).

\begin{itemize}
\tightlist
\item
  \(A\) captures the change in childbirths that is due to the change in General Fertility Rate.
\item
  \(B\) captures the change that is due to a change in the number of women.
\item
  \(C\) captures a combined effect of these changes.
\end{itemize}

Let's apply this decomposition to the UK.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0930}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2209}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2791}}
  >{\centering\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3721}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0349}}@{}}
\caption{\label{tab:deathtx} Live births, women of childbearing age and General Fertility Rate. For England and Wales. Data source: UK Office for National Statistics Birth Summary Tables, England and Wales.}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Year
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Live births (\(X\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Women aged 15-44 (\(Y\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
General Fertility Rate (\(X/Y\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Year
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Live births (\(X\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Women aged 15-44 (\(Y\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
General Fertility Rate (\(X/Y\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule
\endhead
2000 & 604,441 & 10,812,898 & 0.0559 & \\
2016 & 696,271 & 11,176,100 & 0.0623 & \\
Change & 91,830 & 363,201 & 0.0064 & \\
\bottomrule
\end{longtable}

Using these numbers in the formula above, we get:

\begin{itemize}
\tightlist
\item
  \(A\) Change in fertility times number of women in 2000: \(0.0064*10,812,898=69,203\).
\item
  \(B\) Change in the number of women times fertility in 2000: \(363,201*0.0559=20,303\).
\item
  \(C\) Combined effect: \(0.0064*363,201=2,324\).
\item
  Total change: \(A+B+C= 91,830\)
\end{itemize}

The decomposition shows that the change in the number of live births is mainly due to an increasing General Fertility Rate, the change in the number of women of childbearing age has, however, also contributed positively to the increase.

This decomposition method is not only applicable to fertility trends, but can be used for all changes that can be expressed as a ratio.

\hypertarget{calculating-life-expectancy}{%
\section{Calculating life expectancy}\label{calculating-life-expectancy}}

Having considered the flow of childbirths let us now move to the other important natural flow: deaths. To understand and explain changes in the number of deaths from year to year we can use the same approach as for the fertility rates above and consider the following two aspects:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the population stock in each age group.
\item
  What is the mortality rate in each age group.
\end{enumerate}

The overall mortality over a period will increase if the mortality rates increase or if an age group with a higher mortality rate increases. A country can have a higher mortality rate than another country although all age-specific mortality rates are identical, because the age composition of the country differs. This comparison is just like comparing the General Fertility Rate (Or crude birth rate) across two countries.

While the Total Fertility Rate is a measure of the expected number of children that a woman will give birth to during her life, the Period Life Expectancy is a measure of the years a person can expect to live. However, although the intuition is the same, the computation of the Period Life Expectancy is slightly more complicated and we will therefore cover it in more detail.

Life expectancy is often considered one of the most important measures of social progress and it is often used in the public debate. The term ``Life expectancy'' seems quite intuitive. It answers an important question: how long can we expect to live? But how is it calculated? Just like with the Total Fertility Rate we compute the age specific mortality rates and then sum these in a given year. The life expectancy is therefore the number of years one can expect to live if one experiences the age specific mortality rates from that given year. However, we can have several children, but we can only die once. We therefore don't create a hypothetical person, but a hypothetical cohort to calculate life expectancy.

Note that there is an alternative measure of life expectancy called cohort life expectancy. In that measure we follow a cohort. The data requirements are considerably higher for this approach, as we need to follow cohorts for the full life. We will here just capture period life expectancy which is also the most widely used measure.

\hypertarget{life-tables}{%
\subsection{Life tables}\label{life-tables}}

To calculate life expectancy we start by creating life tables. Life tables provide a list of period life expectancy for given age groups. Given you are in a specific age group today and given the mortality rates of each age group, what is your expected life expectancy. Table \ref{tab:deatht} shows the ingredients of life tables, where \(n\) is the width of the age intervals. If we are looking at variables by age in 1 year intervals we would set n=1. \(x\) is the specific age group. So \(x,x+n\) could refer to age interval 5 to 6, if x=5 and n=1.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1364}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1136}}@{}}
\caption{\label{tab:deatht} Ingredients of life tables.}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Col
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Content
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Col
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Content
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} \\
\midrule
\endhead
(1) & \(x,x+n\) & The age interval & Provided \\
(2) & \(m_x\) & The age-specific mortality rate. & \(\frac{\text{deaths } x,x+n}{\text{population } x,x+n }\) \\
(3) & \(_nq_n\) & Prob. dying within interval. & \(\frac{2\times m_x}{2+ m_x}\) \\
(4) & \(I_x\) & Alive at age \(x\) & \(I_0=100,000\) \\
& & & \(I_{x+n}=I_x-_nd_x\) \\
(5) & \(_nd_x\) & Number of people who die within interval. & \(I_x \times _nq_x\) \\
(6) & \(L_x\) & Person-years of life in interval & \(\frac{I_{x}+I_{x+n}}{2}\) \\
(7) & \(T_x\) & Cumulative person-years of life & \(\sum_{end}^x{L_x}\) \\
(8) & \(e_x\) & Average years of life remaining at age \(x\) & \(T_x/I_x\) \\
\bottomrule
\end{longtable}

\hypertarget{the-simple-approach}{%
\subsection{The simple approach}\label{the-simple-approach}}

Before we turn to the ingredients of Table \ref{tab:deatht} it is useful first to consider a simplified version.

We consider the life expectancy of mice (mice unfortunately have shorter lives than humans and they are therefore better suited for an example). You have the following data. This year 50 percent of all mice between age 0 and 1 died. 60 percent off all mice aged between 1 and 2 died. And all mice between 2 and 3 died.

Let's create a simplified life table based on these statistics. We ignore \(_nq_n\) to make it simpler and consider an initial cohort of 10 mice. The table below shows a life table based on this information.

\begin{itemize}
\tightlist
\item
  Initially we have 10 mice. That is why the I column is 10 in row \(0-1y\). We know that 50 percent of mice in this age group died this year, so \(m_x\) is 0.5. That implies that 5 out of the 10 mice will die in this period, that is why \(ndx\) is 5. Looking at the next row, I is now 5 because out of the initial 10 mice, 5 died in the first year. 60 percent of the 5 mice die between before they turn 2, so we know that 3 of them will die in this age interval. We continue like this to fill out the first four columns,
\end{itemize}

In column \(L\) we enter the life years lived in this interval. So for the age group \(0-1y\) we know that 5 of the mice will survive this year so they will live five years in total (each mouse will live 1 year). For the remaining five mice we assume that they will die evenly throughout the year, meaning that they on average will live 0.5 year. So in total these five mice will live 2.5years, bringing the total up to 7.5years. We do the same in the next two rows.

Finally, in column \(T\) we add up how many live years there are left at this point. Starting for age group \(2-3y\), there are two mice who both will die. We assume that they die on average in the middle of the year, so they both can expect to live 0.5 years. 0.5 years times two mice gives 1 year. We do the same in row \(1-2y\) but here we also add the years left after they turn 2, so in total 4.5 and so on.

Finally in the last column we divide the total life years left by the number of mice at the beginning of that period, to get the average life years left for one mouse. As a result, the life expectancy at birth is 1.2y.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1429}}@{}}
\caption{\label{tab:micelife} Our mice life table}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
age ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ix ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(m_x\) ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
ndx ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
L ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
T ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
e ~~~
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
age ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ix ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(m_x\) ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
ndx ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
L ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
T ~~~
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
e ~~~
\end{minipage} \\
\midrule
\endhead
0-1y & 10 & 0.5 & 5 & 7.5 & 12 & 1.2 \\
1-2y & 5 & 0.6 & 3 & 3.5 & 4.5 & 0.9 \\
2-3y & 2 & 1 & 2 & 1 & 1 & 0.5 \\
\bottomrule
\end{longtable}

What was the simplifying step?

\begin{itemize}
\tightlist
\item
  We ignored that not everyone is born on the same day.
\item
  We ignored that the likelihood of dying is not the same every day. At birth you are much more likely to die within the first 48hours than in the remaining year.
\end{itemize}

Incorporating these two extensions is what makes the ``real'' life table more complex. However, the intuition is the same.

\hypertarget{data-requirements-1}{%
\subsection{Data requirements}\label{data-requirements-1}}

For each age group we require data on the number of people in that group and the number of people who died in that group. Once we have these two variables we can construct the other variables. We can get such data from statistical agencies like Eurostat or the Office for National Statistics.

\hypertarget{creating-life-tables}{%
\subsection{Creating life tables}\label{creating-life-tables}}

The first variable we construct is the age specific death rate, followed by the probability of dying within the age group interval. We then construct a synthetic population that has a size of 100,000 individuals at the beginning of the first period. In each period we calculate the number of people who survive this period and who die within this period. We can then use these estimates to calculate the number of life years lived in this period, and sum over these live years. At the end, we divide the number of life years left in any given period by the number of people getting to this period to obtain the estimated life expectancy.

\begin{longtable}[]{@{}llllllll@{}}
\caption{\label{tab:deatht2} Life table for the United Kingdom. Data source: Eurostat.}\tabularnewline
\toprule
age & mx & nqx & ndx & Ix & Lx & Tx & ex \\
\midrule
\endfirsthead
\toprule
age & mx & nqx & ndx & Ix & Lx & Tx & ex \\
\midrule
\endhead
0 & 0.004 & 0.004 & 385.000 & 100,000 & 99,808 & 8,081,572 & 80.816 \\
1 & 0.000 & 0.000 & 25.376 & 99,615 & 99,602 & 7,981,765 & 80.126 \\
2 & 0.000 & 0.000 & 14.013 & 99,589 & 99,582 & 7,882,163 & 79.147 \\
3 & 0.000 & 0.000 & 11.453 & 99,574 & 99,568 & 7,782,581 & 78.159 \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} & \ldots{} \\
98 & 0.346 & 0.295 & 980.052 & 3326 & 2836 & 3128 & 0.941 \\
99 & 0.386 & 0.324 & 758.769 & 2345 & 293 & 293 & 0.125 \\
\bottomrule
\end{longtable}

Table \ref{tab:deatht} shows a subset of a life table for the United Kingdom using data from Eurostat and the recipe outlined in Table \ref{tab:deatht2}. The table shows that the life expectancy at birth is 81 years. Conditional surviving to age 99, the life expectancy is 0.125 years. However,the life expectancy at higher ages is highly influenced by the assumption that all individuals die at a given age. In this case it is by age 100 years. In Figure \ref{fig:death2} we plot the variable \(e_x\) against \(x\) from the life table and life.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_people/fig11} 

}

\caption{Life expectancy by age in years (left) and survival probabilities (right). Data source: Eurostat. }\label{fig:death2}
\end{figure}

\hypertarget{further-readings}{%
\section{Further readings}\label{further-readings}}

\begin{itemize}
\item
  \href{https://ec.europa.eu/eurostat/cache/metadata/en/demo_fer_esms.htm}{Eurostat's Fertility definitions (demo\_fer)}
\item
  \href{https://data.oecd.org/pop/fertility-rates.htm}{OECD's Fertility definitions}
\item
  \href{https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/healthandlifeexpectancies/methodologies/guidetocalculatingnationallifetables}{The UK Office for National Statistics's guide for creating life tables}
\end{itemize}

\hypertarget{the-labour-market}{%
\chapter{The labour market}\label{the-labour-market}}

\hypertarget{what-this-chapter-is-about-1}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-1}}

This chapter is about the labour market. We start with a description of how we can divide the population into groups according to economic activity. We discuss how we define employment and unemployment and two ways of measuring unemployment rates. We will also discuss the difference between the intensive and extensive margin of labour supply and briefly describe how we can quantify the demand side of the labour market and create a graphical representation of the matching efficiency in the labour market by means of the Beveridge curve.

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  Explain and apply definitions of unemployment rates:

  \begin{itemize}
  \tightlist
  \item
    The survey based measure of unemployment.
  \item
    The register based measure of unemployment.
  \end{itemize}
\item
  Explain the difference between the extensive and intensive margin of labour supply.
\item
  Create data visualizations of labour demand and the Beveridge curve.
\end{itemize}

\hypertarget{from-population-data-to-the-labour-market}{%
\section{From population data to the labour market}\label{from-population-data-to-the-labour-market}}

We can divide the total population into groups according to their \emph{economic activity}. For economic analyses it is often useful to split the population into three groups by their age.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Children
\item
  Elderly
\item
  Working age population
\end{enumerate}

This distinction is used in most countries, but the exact definitions of groups vary from country to country. One reason for the variation in definitions is that they are linked to the institutional setting. The definition of what ages are defined as ``children'' will typically depend on the formal compulsory minimum school leaving age. The definition of what ages to include as the elderly will typically depend on the retirement policies.

Using the data from Eurostat, Figure \ref{fig:labour1} shows a stacked area chart of the population stock for the United Kingdom since 1970, split by age group. We observe that the working age population is by far the largest group. At the beginning of the period the group of children were clearly larger than the group of elderly, but at the end of the period the two groups have quite similar sizes.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_labour/fig13} 

}

\caption{Grouping the population of the United Kingdom by age group. Data source: Eurostat. }\label{fig:labour1}
\end{figure}

Within the working age population we can further split the population into

\begin{itemize}
\tightlist
\item
  In the labour force.
\item
  Out of the labour force
\end{itemize}

Where out of the labour force consists of the following:

\begin{itemize}
\tightlist
\item
  Students
\item
  Long-term sick
\item
  Looking after family/staying home
\item
  Retired
\item
  Other
\end{itemize}

Let's now focus on the labour force.The labour force consists of the following two groups:

\begin{itemize}
\tightlist
\item
  People who are unemployed
\item
  People who are employed (including self-employed)
\end{itemize}

The box below summarises the break-down of the population from the full population to the labour force.

\begin{myblock}
\textbf{From the population to the labour force}

The full population can be divided into

1 Children (UK definition: Aged below 16)

2 Elderly (UK definition: Aged above 64)

3 Working age population which consists of

\begin{itemize}
\item
  Out of the Labour Force

  \begin{itemize}
  \tightlist
  \item
    Students
  \item
    Long-term sick
  \item
    Looking after family/staying home
  \item
    Retired
  \item
    Other
  \end{itemize}
\item
  In the labour force

  \begin{itemize}
  \tightlist
  \item
    People who are unemployed
  \item
    People who are employed (including self-employed)
  \end{itemize}
\end{itemize}
\end{myblock}

We will now take a closer look at the labour force by defining the categories in the labour force.

\hypertarget{the-labour-force}{%
\section{The labour force}\label{the-labour-force}}

\hypertarget{unemployment}{%
\subsection*{Unemployment}\label{unemployment}}
\addcontentsline{toc}{subsection}{Unemployment}

\hypertarget{who-is-unemployed}{%
\subsubsection*{Who is unemployed?}\label{who-is-unemployed}}
\addcontentsline{toc}{subsubsection}{Who is unemployed?}

While most people have an idea about what unemployment is, the exact definition of unemployment is considerably less well known. Who is unemployed? Are retired people defined as unemployed? Are children defined as unemployed? Most people would probably say no to these questions. But there are more complex groups: Are students defined as unemployed if they don't work? Are parents on parental leave defined as unemployed? Am I defined as unemployed if I decide not to work? The answer to all these questions is ``no''.

Most countries and international statistics follow the definition of unemployment specified by the International Labour Organisation (ILO). According to the ILO definition, unemployed is being

\begin{itemize}
\tightlist
\item
  ``without a job, have been actively seeking work in the past four weeks and are available to start work in the next two weeks''.
\item
  ``out of work, have found a job and are waiting to start it in the next two weeks''.
\end{itemize}

This definition is used by the European Union (Eurostat), by the Organisation for Economic Cooperation and Development (OECD) and many national statistical offices (including the Office for National Statistics in the United Kingdom). But how do we get data on the questions above? The solution is \emph{survey data}. For the United Kingdom we obtain data on unemployment from the Labour Force Survey (LFS). The LFS is conducted by the Office for National Statistics by selecting random households from the Royal Mail's Postcode Address File. Once households are selected to participate in the survey, they are contacted and asked whether \emph{``they are without a job, have been actively seeking work\ldots{}''} and so on. This data is then included in the official unemployment numbers.

\hypertarget{an-internationally-coherent-definition-of-unemployment}{%
\subsubsection*{An internationally coherent definition of unemployment}\label{an-internationally-coherent-definition-of-unemployment}}
\addcontentsline{toc}{subsubsection}{An internationally coherent definition of unemployment}

All European Union member states are obliged to run labour force surveys on at least an annual basis. For the United Kingdom, the survey has been quarterly since 1992. The Office for National Statistics also releases monthly data, although this is not included in the official statistics.

The \textbf{ILO unemployment definition} above is also called the \textbf{survey measure of unemployment}. This name is based on the fact that the most common alternative measure of unemployment is based on \textbf{register data} from administrative records. *\textbf{Registered unemployment is measured by using data on the number of benefit claimants}. Instead of asking people whether they are looking for a job and not working, we assume that people that claim benefits are unemployed. Statistical offices typically release both measures of unemployment. The register and survey based measures of unemployment typically deviate substantially because:

\begin{itemize}
\tightlist
\item
  People might be looking for jobs even if they don't claim benefits because they are not eligible for benefits.
\item
  People might be claiming benefits without looking for jobs.
\end{itemize}

\begin{myblock}
\textbf{Measuring unemployment: Two definitions}

\emph{1. The survey based measure of unemployment (also known as the ILO
definition).}

\begin{itemize}
\item
  Based on surveys of random subsamples of the population.
\item
  People are defined as unemployed if they are

  \begin{itemize}
  \tightlist
  \item
    without a job, have been actively seeking work in the past four
    weeks and are available to start work in the next two weeks
  \item
    out of work, have found a job and are waiting to start it in the
    next two weeks
  \end{itemize}
\end{itemize}

\emph{2. The register based measure of unemployment.}

\begin{itemize}
\tightlist
\item
  Based on administrative registers of benefit claimants.

  \begin{itemize}
  \tightlist
  \item
    How many individuals received unemployment benefits.
  \end{itemize}
\end{itemize}
\end{myblock}

Let's now look at the other part of the labour force. The employed.

\hypertarget{employment}{%
\subsection*{Employment}\label{employment}}
\addcontentsline{toc}{subsection}{Employment}

\hypertarget{an-internationally-coherent-definition-of-employment}{%
\subsubsection*{An internationally coherent definition of employment}\label{an-internationally-coherent-definition-of-employment}}
\addcontentsline{toc}{subsubsection}{An internationally coherent definition of employment}

Just like unemployment, measuring employment is not straightforward and the ILO has specified a definition, which the Office for National Statistics applies in the LFS. Following this definition people are employed if they are above 16 and satisfy one of the following conditions:

\begin{itemize}
\tightlist
\item
  work at least one hour for pay in a week, people who are temporarily away from jobs.
\item
  are on Government-supported training/employment programs.
\item
  do unpaid family work.
\end{itemize}

Paid work refers to both employees and self-employed, and unpaid family work refers to working for family businesses without receiving a formal wage, but still benefiting from the business.

It is important to note that employment is not the same as jobs. Employment measures refer to people, and people with several jobs will only be counted once in the employment statistics. In the job statistics, each job is counted.

Like with unemployment, we can also compute register based measures of employment by using information from income tax payments, insurance status and other administrative registers.

\begin{myblock}
\textbf{Measuring employment: Two definitions}

\emph{1. The survey based measure of employment.}

\begin{itemize}
\tightlist
\item
  work at least one hour for pay in a week, people who are temporarily
  away from jobs.
\item
  are on Government-supported training/employment programs.
\item
  do unpaid family work.
\end{itemize}

\emph{2. The register based measure of employment.}

\begin{itemize}
\tightlist
\item
  information from income tax payments, insurance status and other
  administrative registers.
\end{itemize}
\end{myblock}

\hypertarget{the-unemployment-rate}{%
\subsection*{The unemployment rate}\label{the-unemployment-rate}}
\addcontentsline{toc}{subsection}{The unemployment rate}

Having defined who is unemployed and who is employed it is straightforward to define the labour force. The labour force is simply the sum of these two groups:

\begin{align}
  \text{Labour force}=Unemployed+Employed
\end{align}

We are now ready to calculate the unemployment rate. The unemployment rate is the fraction of the labour force that is unemployed:

\begin{align}
  \text{Unemployment rate}&=\frac{Unemployed}{\text{Labour force}}\nonumber\\
  &=\frac{Unemployed}{Unemployed+Employed}
\end{align}

How can the unemployment rate change? If people move from unemployment to employment, the unemployment rate clearly goes down, as the size of the denominator is unchanged and the size of the numerator is reduced. Vice versa if people move from employment to unemployment.

What happens to the unemployment rate if people move from unemployment to out of the labour force? The unemployment rate will go down, everything else equal, because the numerator is increased by relatively more than the numerator. Vice versa if people go from out of the labour force to unemployment.

\hypertarget{an-illustration-using-data-for-the-united-kingdom}{%
\subsubsection*{An illustration using data for the United Kingdom}\label{an-illustration-using-data-for-the-united-kingdom}}
\addcontentsline{toc}{subsubsection}{An illustration using data for the United Kingdom}

Figure \ref{fig:labour2} shows the unemployment rate for the United Kingdom using both measures. As you can see, for the period considered, the registered unemployment rate is always lower than the survey based measure of unemployment. Why do you think this is the case? And why is the difference not constant over time?

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_labour/fig14} 

}

\caption{The unemployment rate in the United Kingdom, using two different measures of unemployment. Data source: OECD }\label{fig:labour2}
\end{figure}

Recall that the register based unemployment is based on the number of people receiving benefits. However not everyone who is looking for a job is necessarily eligible for unemployment benefits. In that case the survey based unemployment rate will be higher than the register based. On the other hand some people who receive benefits might not be actively looking for jobs. In that case the survey based unemployment measure will be lower. Whether the former or latter dominates partly depends on the institutional setting. Who is eligible for benefits and who is not. That is also one reason why the difference between the two lines might change over time. It can be because benefit policies change. It could also be because economic conditions change, and the composition of job seekers changes.

\hypertarget{out-of-the-labour-force}{%
\subsection{Out of the labour force}\label{out-of-the-labour-force}}

In the United Kingdom, the labour force is about half of the population (about 33 out of 66 million). What about the rest? First, we've already covered children and individuals aged above 64. But then there are still about 8.9 million people left, where did they go? This group is called economically inactive by the Office for National Statistics. We covered them in the box above. They include students, long-term sick and people who decide not to work. Personally I am not a big fan of calling them economically inactive, but that is the definition. The Office for National Statistics also calculates inactivity rate is defined as follows:

\begin{align}
  \text{Inactive rate}=\frac{\text{Number of people aged 16 to 64 not in work/ available for work}}{\text{All people aged 16 to 64}}
\end{align}

So what do the ``economically inactive'' people do (or people who are not in the labour force, as I prefer to call them)? In the UK, the distribution of economically inactive is approximately as follows:

\begin{itemize}
\tightlist
\item
  27 percent are studying.
\item
  24 percent are looking after the family/staying home.
\item
  23 percent are long-term sick.
\item
  13 percent are retired.
\end{itemize}

Now that we have divided the population into groups according to their economic activity, we are ready to create graphs and tables on unemployment rate, employment rates and inactivity rates.

\begin{myblock}
\textbf{How to reduce the unemployment rates}

Imagine that you are working for a newly elected prime minister, and the
prime minister promised to lower unemployment rates, how could you
achieve this?

\begin{itemize}
\item
  Abandon the survey based measure of unemployment (the ILO measure),
  and only use the register based measure, because the latter tends to
  be lower.
\item
  Tighten the criteria for receiving unemployment benefits, as this will
  make less people receive benefits, which will lower the register based
  unemployment measure.
\item
  Introduce ``leave'' policies that allow unemployed workers to be ``on
  leave'' instead of unemployment. This will move people out of the
  unemployment category.
\end{itemize}

\emph{Are these policies good?}

\begin{itemize}
\tightlist
\item
  There might be normative arguments against and for these policies, but
  it is importantly: the immediate reduction in unemployment is caused
  by relabeling (or classification) of people, not by changing their
  actual situation.
\item
  (it might be that labeling people as ``unemployed'' or a leave policy
  affects the unemployment rate beyond the pure relabeling effect).
\end{itemize}
\end{myblock}

\hypertarget{labour-supply-extensive-vs.-intensive-margin}{%
\subsection*{labour supply: Extensive vs.~intensive margin}\label{labour-supply-extensive-vs.-intensive-margin}}
\addcontentsline{toc}{subsection}{labour supply: Extensive vs.~intensive margin}

\hypertarget{what-about-the-intensive-margin}{%
\subsubsection*{What about the intensive margin?}\label{what-about-the-intensive-margin}}
\addcontentsline{toc}{subsubsection}{What about the intensive margin?}

So far we have only discussed whether people are working or not. This is called the \textbf{extensive margin} of the labour supply.

However, labour supply is both a function of whether people work, and \emph{how much} they work. The former is called the \emph{extensive margin}, and the latter is called the \emph{intensive margin}. The extensive margin is typically a binary variable (to work or not), while the intensive margin is a continuous variable (how many minutes or hours of work). In the section about people we saw how we could decompose changes in live births in changes in the general fertility rates and changes in the number of of women in childbearing ages. We could now use the same approach to decompose changes in labour supply in changes in how many people work, and changes in how many hours people on average work.

\hypertarget{policy-relevance-of-the-intensive-margin}{%
\subsubsection*{Policy relevance of the intensive margin}\label{policy-relevance-of-the-intensive-margin}}
\addcontentsline{toc}{subsubsection}{Policy relevance of the intensive margin}

The distinction between extensive and intensive margin is important in many policy discussions. For example if we adjust tax policies, we might be interested in how it affects people's decision to join the labour market (the extensive margin) and people's decision on how much to work (the intensive margin).

\hypertarget{measuring-labour-supply-on-the-intensive-margin}{%
\subsubsection*{Measuring labour supply on the intensive margin?}\label{measuring-labour-supply-on-the-intensive-margin}}
\addcontentsline{toc}{subsubsection}{Measuring labour supply on the intensive margin?}

Measuring variation in intensive labour supply is slightly more challenging than measuring the extensive margin. I know that I work, but I have no precise idea about how many hours I work. For the United Kingdom, data on hours worked also comes from the Labour Force Survey. The Office for National Statistics makes the distinction between actual hours worked, average hours worked and the usual hours worked. They key difference is whether the measure is affected by absence (due to sickness or holiday).

\hypertarget{measuring-labour-supply-an-illustration-using-hours-worked}{%
\subsubsection*{Measuring labour supply: An illustration using hours worked}\label{measuring-labour-supply-an-illustration-using-hours-worked}}
\addcontentsline{toc}{subsubsection}{Measuring labour supply: An illustration using hours worked}

In Figure \ref{fig:labour3}) we show the average weekly hours in the United Kingdom by gender compared to the European Union. The first observation we can make is that women have lower weekly hours than men. The second observation is that while the average weekly hours of men in the United Kingdom is slightly higher than the European Union 28 average, the average weekly hours of women is lower in the United Kingdom compared to the European Union 28.

\begin{figure}

{\centering \includegraphics[width=0.89\linewidth]{./resources/chapter_labour/fig17} 

}

\caption{The intensive margin of labour supply: weekly hours worked in United Kingdom and the European Union 28. Data source: OECD. }\label{fig:labour3}
\end{figure}

\hypertarget{labour-demand}{%
\section{Labour demand}\label{labour-demand}}

\hypertarget{measuring-labour-demand}{%
\subsection*{Measuring labour demand}\label{measuring-labour-demand}}
\addcontentsline{toc}{subsection}{Measuring labour demand}

So far we only discussed the supply side of the labour market. The size of the labour force captures the potential supply of labour in an economy. But what about the demand side? How much labour is demanded in the economy? Measuring the demand size is challenging and considerably less standardized compared to the supply size. Just like for the labour supply side, there are two different sources of labour demand measures:

\begin{itemize}
\tightlist
\item
  Register based measures of labour demand: Using data from public employment services we can use the number of announced job vacancies as an indicator for labour demand.
\item
  Survey based measures: we can ask firms about their labour demand needs.
\end{itemize}

\hypertarget{advantages-and-disadvantages}{%
\subsubsection*{Advantages and disadvantages}\label{advantages-and-disadvantages}}
\addcontentsline{toc}{subsubsection}{Advantages and disadvantages}

The two labour demand measures above each have their own advantages and disadvantages. The register based measure is considerably cheaper and tends to exist for longer periods and in more countries. However, not all firms post their vacancies in the public employment service, so the sample of vacancies might not be representative of the actual number of vacancies. Moreover, the use of traditional job vacancy posting has changed over time, so this measure might be less representative today compared to what it used to be.

The survey based measure of vacancies on the other hand is more expensive and suffers from the ``usual'' survey issues: not every firm responds and maybe the firms that respond are not representative. But compared to the register based measure, the ``non-representativeness'' might be less of a worry, although empirical evidence on this issue is not clear. As mentioned, the survey-based measure of job vacancies is less standardized than the survey-based measure of unemployment, but international organizations collect data on job vacancies and attempt to unify the definitions of job vacancies. The definition provided by Eurostat is as follows:

\begin{myblock}
\textbf{The Eurostat definition of a job vacancy}

According to the Eurostat job vacancy statistics a `vacancy' is defined
as a paid post that is newly created, unoccupied, or about to become
vacant:

\begin{itemize}
\tightlist
\item
  for which the employer is taking active steps and is prepared to take
  further steps to find a suitable candidate from outside the enterprise
  concerned; and
\item
  which the employer intends to fill either immediately or within a
  specific period of time.
\end{itemize}
\end{myblock}

\hypertarget{the-job-vacancy-rate}{%
\subsubsection*{The job vacancy rate}\label{the-job-vacancy-rate}}
\addcontentsline{toc}{subsubsection}{The job vacancy rate}

We can relate the number of vacancies to the size of the labour force to obtain a measure of the job vacancy rate. While this is the typically textbook measure of the job vacancy rate, statistical databases often provide slightly different measures. Eurostat defines the job vacancy rate as follows:

\begin{align}
  \text{JVR}_{\text{Eurostat}}=\frac{\text{number of vacancies}}{\text{number of occupied posts}+\text{number of vacancies}}\times 100
\end{align}

If we are willing to approximate the number of occupied posts by the number of employed people, the main difference between these two definitions of the job vacancy rate is whether we include vacancies or unemployment in the denominator. Both measures are commonly used, but it is of course important to be consistent when comparing job vacancy rates across regions and time. A reduction in vacancies will lead to a smaller reduction in the job vacancy rate using the Eurostat definition than the definition above, because in the latter it only affects the numerator.

\hypertarget{supply-meets-demand}{%
\section{Supply meets demand}\label{supply-meets-demand}}

We can combine our measures of labour supply and demand to create the Beveridge Curve, which is named after its ``inventor'', the English economist William Beveridge. The Beveridge curve shows the job vacancy rate on the vertical axis against the unemployment rate on the horizontal axis. The Beveridge curve is a simple indicator of the matching efficiency of the labour market. Without any frictions and in the simple economic model, the line should only ``exist'' on the axes: We should only have a positive job vacancy rate if unemployment is zero, and we should only have unemployment if we have no vacancies. In practice, this is clearly not the case as Figure \ref{fig:labour4} shows. We have unemployment and vacancies at the same time. How can that be and how does that say something about the labour market?

\begin{itemize}
\item
  The unemployed worker and the vacancy haven't ``matched'' yet: search frictions and other difficulties mean that even if there is a suitable unemployed candidate, the open position might not be filled immediately. There is an application deadline, formal procedures and the unemployed first has to find the job.
\item
  An outward shift in the Beveridge curve (as illustrated) suggests a reduction in the matching efficiency of the labour market: For a given number of vacancies in the economy, we have a higher unemployment rate.
\item
  However, there are other reasons for shifts in the labour market than pure search frictions.
\item
  The assumptions of a homogeneous labour market are very simplified.
\item
  There might be vacancies in Manchester and the unemployed in London (geographical mismatch)
\item
  There might be firms looking for lawyers, but only unemployed economists (skill mis-match).
\item
  and so on.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.89\linewidth]{./resources/chapter_labour/fig16} 

}

\caption{The Beveridge curve for the United Kingdom. Data source: OECD. }\label{fig:labour4}
\end{figure}

\hypertarget{further-readings-1}{%
\section{Further readings}\label{further-readings-1}}

\begin{itemize}
\item
  \href{https://www.ilo.org/ilostat-files/Documents/description_UR_EN.pdf}{The International Labour Organisation's definition on the unemployment rate.}
\item
  \href{https://data.oecd.org/unemp/unemployment-rate.htm}{OECD's Unemployment rate definitions}
\item
  \href{https://ec.europa.eu/eurostat/cache/metadata/en/jvs_esms.htm}{Eurostat about Job Vacancies}
\end{itemize}

\hypertarget{activity}{%
\chapter{Economic Activity}\label{activity}}

\hypertarget{what-this-chapter-is-about-2}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-2}}

This chapter is about economic activity. Along with the unemployment rate, economic activity is one of the most used economic concepts in policy discussions. What is it? What does it capture? And importantly, what does it not capture?

Economic activity is measured in the System of National Accounts (SNA) and conceptualized by the Gross Domestic Product, (GDP). We will not cover the SNA in detail.\footnote{For details on the SNA, please visit the following \href{https://unstats.un.org/unsd/nationalaccount/sna.asp}{website}} The System of National Accounts is basically big bookkeeping of economic transactions in a region over a given period of time. The SNA includes a set of rules and instructions that have been agreed upon internationally to ensure that measures of economic activity are comparable across countries. In this chapter we will go through some of the key \emph{aggregates} of the SNA, for example Gross Domestic Product, a measure of economic activity. An aggregate is a measure that \emph{aggregates} several underlying variables. This chapter is mainly about the GDP, but we will also briefly touch upon other aggregates of the SNA as well as what the GDP is used for.

\hypertarget{intended-learning-outcomes}{%
\subsection{Intended learning outcomes}\label{intended-learning-outcomes}}

After reading this chapter you should be able to:

\begin{itemize}
\tightlist
\item
  Explain what the gross domestic product (GDP) is and calculate it.
\item
  Explain the three ways to measure GDP

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    The Income Approach
  \item
    The Expenditure Approach
  \item
    The Output approach.
  \end{enumerate}
\item
  Explain what the gross national income (GNI) is and calculate it.
\item
  Calculate GDP per person and productivity.
\item
  Visualize data on economic activity.
\end{itemize}

\hypertarget{a-super-brief-history-of-gdp}{%
\section{A super brief history of GDP}\label{a-super-brief-history-of-gdp}}

Most texts about the history of GDP start around the Great Depression in the 1930ies United States. The US Congress realised that the economy was not doing as well as it could, but had a hard time quantifying how bad the situation actually was. To the ``rescue'' came the economist Simon Kuznets who provided a report on the ``National Income, 1929-1935'' for the Congress (see \ref{fig:gdp1}), where he presented the idea of capturing the entire production, income and expenditure of the economy. And so the modern concept of GDP was born. However, measures of economic activity have existed for many years.

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{./resources/chapter_gdp/Kusnetz} 

}

\caption{Kuznets' report for the U.S. Congress, 1934. Source:  [Fraser St. Louis FED](fraser.stlouisfed.org/title/971).}\label{fig:gdp1}
\end{figure}

The idea of quantifying the size of the economy probably goes back to at least the 17th century. The exact definition of GDP has since then been redefined and adjusted. It is actually continuously adjusted. More on that later. Giving Simon Kuznets a lot of credit for the GDP is not completely wrong. He refined the concept a lot and his report made it prominent. However, it wasn't until much later that it became the ``statistic to rule them all''.

The GDP as a concept is criticized a lot. The most prominent criticism is probably the ``Report by the Commission on the Measurement of Economic Performance and Social Progress'' published in Autumn 2009 by the economists Joseph Stiglitz, Amartya Sen and Jean-Poul Fitoussi. What is the key criticism of GDP? The main problem with the GDP is not so much the GDP itself, but more the use and policy focus on GDP as a measure of well-being or welfare. Simon Kuznets was actually already aware of some of these issues and the potential misuse of GDP. Figure \ref{fig:gdp1} shows a small section of the 273 page long report by Kuznets.

Figure \ref{fig:gdp2} shows extracts of pages 5-7 in Kuznets original report \citep{kuznets1934national}. Kuznets made several points that are at the heart of the discussion today, for example that ``With quantitative measurements especially, the definiteness of the result suggests, often misleadingly, a precision and simplicity in the outlines of the object measured.'' and ``Economic welfare cannot be adequately measured unless the personal distribution of income is known. And no income measurement undertakes to estimate the reverse side of income, that is, the intensity and unpleasantness of effort going into the earning of income.''

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_gdp/Kusnetz2} 

}

\caption{Page 5-7 in 'National Income, 19291932'. 73rd US Congress, 2d session, Senate document no. 124, 1934. Source:  [Fraser St. Louis FED](fraser.stlouisfed.org/title/971). }\label{fig:gdp2}
\end{figure}

So why should we care about GDP if it is no good? Because the GDP is a reasonably good of market economic activity. We will return to the criticism of GDP in later chapters, but here we will discuss what it actually captures. When we know what the GDP measures, we can say more about what it doesn't measure and how we should and should not use it.

\hypertarget{the-economy-of-microcountry}{%
\section{The Economy of Microcountry}\label{the-economy-of-microcountry}}

\hypertarget{ordinary-business-of-life-in-microcountry}{%
\subsubsection*{``\ldots ordinary business of life'' in Microcountry}\label{ordinary-business-of-life-in-microcountry}}
\addcontentsline{toc}{subsubsection}{``\ldots ordinary business of life'' in Microcountry}

Let me introduce a very small country. It is not my home country, Denmark, but a country that is even smaller: Microcountry. Microcountry is just next to Neighbourcountry. Microcountry is so small that I can explain all economic activity in this country to you in a few paragraphs.

In Microcountry we have one farm that produces flour. The farm sells the flour to a bakery for 10 . To produce the flour, the farm has workers, and these workers earn a wage of 8 . Finally, the farm pays a tax to the government of 2 .

The bakery produces bread based on labor inputs in terms of workers and the flour bought from the farm. The workers at the bakery receive 14  in wages, and the government receives 2  in taxes from the bakery. The bakery sells bread for 18  to the households in Microcountry. The households of Neighbourcountry buy bread from the bakery in Microcountry for 9 , and the bakery in Microcountry is actually owned by residents of Neighbourcountry.

The households in Microcountry work for the bakery, the farm and for the government. They pay 1  in taxes to the government, and buy bread for 18  at the bakery. The households also import cheese from Neighbourcountry for a value of in total 8 . The Government provides health service and a school for the residents of Microcountry and spend 5  in wages to teachers and health providers to be able to supply this service.

\hypertarget{quantifying-economic-activity-in-microcountry}{%
\subsubsection*{Quantifying economic activity in Microcountry}\label{quantifying-economic-activity-in-microcountry}}
\addcontentsline{toc}{subsubsection}{Quantifying economic activity in Microcountry}

So we know that the people in Microcountry go to work at a farm, in a bakery, in a school or in health services. We know that they buy bread and cheese. These activities are just examples of ``\ldots ordinary business of life'' (from Alfred Marshal's quote \emph{``{[}\ldots{]} economics is a study of mankind in the ordinary business of life''} in The Principles of Economics). How can we quantify these economic activities?

What is economic activity? Just think of when you are economically active:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  When you go shopping and spend money.
\item
  When you work and receive a wage, and when you earn profits.
\item
  When you create a product and sell it to someone.
\end{enumerate}

These three examples of how we as individuals are economically active actually capture the three ways we measure the Gross Domestic Product (GDP). The expenditure approach, the income approach and the output approach. Let us now discuss these approaches in detail. The GDP captures how much is spent, how much is produced or how much is earned within a period. It is therefore a flow variable.

You know basically know how to measure GDP. Just consider the sum of all expenditures in Microcountry. Or the sum of all income generated. Or the sum of all output created. All these approaches give the same value. Try it on the Microcountry above. You will probably realise that it is slightly more complicated. We will therefore cover this in more detail below.

Before we turn to the description of the measurement approaches, here is a short video of what the GDP is, created by the UK Treasury.

\begin{figure}

{\centering \href{https://www.youtube.com/embed/UOuzPLjwkMc}{\includegraphics[width=0.7\linewidth]{04_gdp_files/figure-latex/whatisgdp-1} }

}

\caption{What is GDP?. Source: HM Treasury. }\label{fig:whatisgdp}
\end{figure}

\hypertarget{the-3-ways-to-measure-gdp}{%
\section{The 3 ways to measure GDP}\label{the-3-ways-to-measure-gdp}}

\hypertarget{the-expenditure-approach}{%
\subsection*{The Expenditure Approach}\label{the-expenditure-approach}}
\addcontentsline{toc}{subsection}{The Expenditure Approach}

The \emph{expenditure} approach (called the spending approach in \href{https://core-econ.org/the-economy/index.html}{The Core}) measures the GDP in terms of expenditures by households and the Government, as well as investments and net exports of goods and services (i.e.~exports minus imports). All these expenditures are summarised by the following equation:
\begin{align}
   \text{GDP}^{\text{E}} \text{=Y=C+G+I+X-M}
\end{align}
where:

\begin{itemize}
\tightlist
\item
  \textbf{Y} is the Gross Domestic Product (GDP).
\item
  \textbf{C} is the final consumption of goods and services by households. It includes goods like food, cars, and clothing, as well as services such as hotel stays.
\item
  \textbf{G} is the final consumption expenditure of goods and services by the government.
\item
  \textbf{I} are the investments (also called gross capital formation) in fixed assets such as machinery, buildings etc.
\item
  \textbf{X} is goods and services produced domestically but consumed abroad (Exports)
\item
  \textbf{M} is goods and services produced abroad and consumed domestically (Imports).
\end{itemize}

Let us return to Microcountry and use the expenditure approach to calculate the economic activity of Microcountry.

\begin{itemize}
\tightlist
\item
  \(C\) household consumption:

  \begin{itemize}
  \tightlist
  \item
    The households buy bread at the bakery for 18 and import goods from Neighbourcountry for 8, \(C=8+18=26\).
  \end{itemize}
\item
  \(G\) Government consumption:

  \begin{itemize}
  \tightlist
  \item
    The government spends 5 on health services, \(G=5\).
  \end{itemize}
\item
  \(I\) Investments:

  \begin{itemize}
  \tightlist
  \item
    There are no investments in this economy, \(I=0\).
  \end{itemize}
\item
  \(X\) Exports:

  \begin{itemize}
  \tightlist
  \item
    The bakery exports bread to Neighbourcountry for 9, \(X=9\).
  \end{itemize}
\item
  \(M\) Imports:

  \begin{itemize}
  \tightlist
  \item
    Microcountry imports goods for the value of 8 from Neigbourcountry, \(M=8\).
  \end{itemize}
\end{itemize}

The GDP of Microcountry is therefore \(Y=26+5+9-8=32\).

Let's now move to a real economy, the United Kingdom. In the following Table we show the expenditure approach to calculate GDP for the United Kingdom. Private consumption, that is our \(C\), constitutes for about two-thirds of the GDP. Government consumption, \(G\), constitutes for 18\%, Investments, \(I\), constitute for 17\%, and Net exports are only slightly negative (as Imports are larger than Exports).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/tab1} 

}

\caption{Gross Domestic Product of the United Kingdom using the expenditure approach, in 2017.Data source: OECD. All values are in 2017 prices.}(\#fig:gdpexp_)
\end{figure}

\hypertarget{the-income-approach}{%
\subsection*{The income approach}\label{the-income-approach}}
\addcontentsline{toc}{subsection}{The income approach}

A second approach to measuring GDP is the income approach. The income approach measures the GDP in terms of the generated income in the economy. The income generated in an economy consists of all compensation to workers (wages, pension contributions etc.), operating surplus (profits and rents) and sales taxes minus subsidies.\footnote{Note that while the notation for the expenditure approach is fairly standard, the notation for the production and income approaches are less standardized.}

\begin{align}
   \text{GDP}^{\text{I}} \text{=W+P+NT}
\end{align}
where

\begin{itemize}
\tightlist
\item
  \emph{W} is worker compensation.
\item
  \emph{P} is operating surplus.
\item
  \emph{NT} is sales taxes minus subsidies.
\end{itemize}

Let us return to Microcountry and use the income approach to calculate the economic activity of Microcountry.

\begin{itemize}
\item
  \(W\),worker compensation:

  \begin{itemize}
  \tightlist
  \item
    The farm workers receive a wage compensation of 8, the bakery workers receive a wage compensation of 14 and the health service workers receive a compensation of 5. The total wage compensation is therefore \(W=8+14+5=27\).
  \end{itemize}
\item
  \(P\), operating surplus:

  \begin{itemize}
  \tightlist
  \item
    The farm has zero profits, but the bakery has a profit of 1, \(P=1\).
  \end{itemize}
\item
  \(NT\), taxes minus subsidies:

  \begin{itemize}
  \tightlist
  \item
    The farm pay 2 in taxes and the bakery pays 2. There are no subsidies. The taxes minus subsidies are therefore, \(NT=2+2=4\).
  \end{itemize}
\end{itemize}

The GDP of Microcountry is therefore \(Y=27+4+1=32\).

Let's now move back to the real economy of the United Kingdom. In the following Table we show the income approach to measure GDP for the United Kingdom. Compensation of employees, that is our \(W\), constitutes for about half of the GDP. Profits, \(P\), constitute for 38\%, and the remaining 12\% are net taxes.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/tab2} 

}

\caption{Gross Domestic Product of the United Kingdom using the income approach, in 2017.Data source: OECD. All values are in 2017 prices.}(\#fig:gdpexp_2)
\end{figure}

\hypertarget{the-production-approach}{%
\subsection*{The production approach}\label{the-production-approach}}
\addcontentsline{toc}{subsection}{The production approach}

The third and last approach to measuring GDP is the production approach (also known as the output approach). So far we have considered how much we've spent (the expenditure approach), how much income was generated (the income approach) and now we finally look at how much we produced. The production approach measures the GDP in terms of production or \emph{value added}. The value added is the value of the output minus the costs of the intermediate goods. If a bakery buys flour for 15  and sells bread for 50 , the value added by the bakery is 50-15=35 . Intermediate goods are all goods used in the production process, such as raw materials, fuel, rental costs, cleaning and marketing costs.

We typically distinguish between two types of outputs, market and non-market outputs. The market outputs are goods and services sold on the market, such as the bread sold by the bakery. In that case the value added is straightforward to calculate, as it is the sales price minus the price of the intermediate goods. However, not all goods are necessarily sold, so we also include the change in inventories. For non-market output, such as health and defence, the output is the production costs, i.e.~the cost of labor and intermediate goods (and depreciation in fixed assets). Finally, there is a distinction between value added in basic prices and value added in market prices. To obtain the latter we have to add sales tax and subtract subsidies.

\begin{align}
   \text{GDP}^{\text{P}} \text{=GVA+NT}
\end{align}
where

\begin{itemize}
\tightlist
\item
  \emph{GVA} is gross value added.
\item
  \emph{NT} is taxes minus subsidies.
\end{itemize}

Let us return to Microcountry and use the expenditure approach to calculate the economic activity of Microcountry.

\begin{itemize}
\item
  \(GVA\), gross value added

  \begin{itemize}
  \item
    The farm sells flour for 10 and pays 2 in taxes. The gross value added of the bakery is therefore 8. The bakery sells bread for 27, pays a sales tax of 2 and pays 10 for the flour from the bakery. The gross value added of the bakery is therefore 15. Finally, the public sector provides a health service. The value of public sector provision is typically estimated by means of the costs, which in this case is 5. The total gross value added in Microcountry is therefore \$GVA=8+15+5=28.
  \item
    The farm pays 2 in taxes and the bakery pays 2. There are no subsidies. The sales taxes minus subsidies are therefore, \(NT=2+2=4\).
  \end{itemize}
\end{itemize}

The GDP of Microcountry is therefore \(Y=28\)+4=32.

Finally, let's now move back to the real economy of the United Kingdom. In the Table below we show the production approach to measure GDP for the United Kingdom. In this example we show Gross Value Added separately by sector. This is one of the advantages of having several measures of GDP: We can decompose the GDP into different dimensions. In this example we observe that Public services and distributive trades are some of the largest elements of the UK GDP.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/tab3} 

}

\caption{Gross Domestic Product of the United Kingdom using the production approach, in 2017.Data source: OECD. All values are in 2017 prices.}(\#fig:gdpexp_3)
\end{figure}

\hypertarget{what-is-included-in-the-gdp-measure}{%
\subsection{What is included in the GDP measure?}\label{what-is-included-in-the-gdp-measure}}

Measuring GDP also requires us to understand which activities we should include, and which we should not include. Based on the general principles described in the \href{https://unstats.un.org/unsd/nationalaccount/sna.asp}{ESA 2010}, the Office for National Statistics decides on a production boundary, which contains all economic activities that should be included in the GDP measurements. An activity is included in the boundaries if:

\begin{itemize}
\tightlist
\item
  The activity produces a meaningful output.
\item
  The product or activity has a meaningful market value, or the market value can be imputed.
\item
  The inclusion of the activity increases the meaningfulness of cross-country comparisons.
\end{itemize}

Several activities are less clear-cut than you might think, for example activities where ``production is forbidden by law; as long as all units involved in the transaction enter into it voluntarily'' are included. Breeding of fish in fish farms is included, but breeding of fish in open seas is not included.

\hypertarget{gdp---why-3-approaches}{%
\subsection{GDP - Why 3 approaches?}\label{gdp---why-3-approaches}}

Note how all three approaches show the same results in form of the same GDP. For simplicity, one might therefore argue that we should just stick to one approach and ignore the two other approaches. However, each approach has its own advantage. First,the expenditure approach is very useful if you want to assess whether changes in GDP are driven by for example domestic consumption or exports. Moreover, we can decompose all approaches in more detail. We could for example identify which sector is contributing most to the value added using the production approach. While the three approaches in theory should lead to exactly the same number, we often observe small discrepancies in practice. These discrepancies are called ``statistical discrepancy''.

\begin{myblock}
\textbf{Measuring GDP - an overview}

\emph{1. The expenditure approach}

\begin{itemize}
\tightlist
\item
  The expenditure approach (called the spending approach in {[}@core{]})
  measures the GDP in terms of expenditures by households and the
  Government, as well as investments and net exports of goods and
  services (i.e.~exports minus imports).
\end{itemize}

\begin{align}
  Y=C+G+I+X-M=C+G+I+NX
\end{align}

\begin{itemize}
\tightlist
\item
  \emph{Y} is the Gross Domestic Product (GDP).
\item
  \emph{C} is the final consumption of goods and services by households.
  It includes goods like food, cars, and clothing, as well as services
  such as hotel stays.
\item
  \emph{G} is the final consumption expenditure of goods and services by
  the government.
\item
  \emph{I} are investments (also called gross capital formation) in
  fixed assets such as machinery, buildings etc.
\item
  \emph{X} is goods and services produced domestically but consumed
  abroad (Exports)
\item
  \emph{M} is goods and services produced abroad and consumed
  domestically (Imports).
\end{itemize}

\emph{2. The income approach}

\begin{itemize}
\tightlist
\item
  The income approach measures the GDP in terms of the generated income
  in the economy.
\end{itemize}

\begin{align}
   Y=W+P+NT
\end{align}

\begin{itemize}
\tightlist
\item
  \emph{W} is worker compensation.
\item
  \emph{P} is operating surplus.
\item
  \emph{NT} is sales taxes minus subsidies.
\end{itemize}

\emph{3. The production approach} (also known as the output approach)

\begin{itemize}
\tightlist
\item
  The production approach measures the GDP in terms of production or
  \emph{gross value added}.
\end{itemize}

\begin{align}
  Y=GVA+NT
\end{align}

\begin{itemize}
\tightlist
\item
  \emph{GVA} is gross value added.
\item
  \emph{NT} is sales taxes minus subsidies.
\end{itemize}
\end{myblock}

\hypertarget{gross-national-income-gni}{%
\section{Gross National Income (GNI)}\label{gross-national-income-gni}}

Gross national income (GNI) is the income received by residents of the domestic economy. The GNI is thus defined as the GDP plus the net property income from abroad. Where property income consists of interests, rent on land and income from corporations. The GDP and GNI can be very different. If for example most firms in the economy have foreign owners, the profits of these firms will be subtracted from the GDP, and the GNI will thus be considerably lower.

Let's look at Microcountry. We found a GDP of 32 independent of how we measured GDP. However, because the bakery is owned by residents in Neighborcountry, the profits go abroad, and the Gross National Income is: \$GNI=32-1=31.

\hypertarget{what-we-use-gdp-for}{%
\section{What we use GDP for}\label{what-we-use-gdp-for}}

Now what do we need these measures for? The GDP is an important aspect in many policymakers evaluation of the condition of the economy. For example, during the Great Depression in the late 1920ies and early 1930ies the economy looked quite bad, but how bad was actually hard to describe. The United States congress therefore asked the economist Simon Kuznetz to quantify US economic activity. Kuznetz's estimates gave the first insights into the magnitude of the Great Depression by showing the change in economic activity during the great depression. Let us just consider a few uses of GDP.

\hypertarget{growth-rates}{%
\subsubsection*{1 Growth rates}\label{growth-rates}}
\addcontentsline{toc}{subsubsection}{1 Growth rates}

As it was the case during the Great Depression, we are in general typically more interested in changes than in levels of GDP. It is maybe the most popular statistic of policy makers: the growth rates. Getting from the level of GDP to the growth rates is straightforward, given that the levels are measured in \emph{real} terms, that is at a constant price level (we will return to the issue of real and nominal terms in later chapters). We can use the following formula to calculate the growth rate in percent:

\begin{align}
\text{growth rate in percent}=100\times \left(\frac{GDP_t}{GDP_{t-1}}-1\right)
\end{align}

In this expression the letter \(t\) refers to the time period. This could be a year, a quarter or a month. Figure \ref{fig:gdp13} shows the GDP of the UK using a fixed price level and the annual growth rates. The yearly growth rates roughly correspond to the first derivative of the level, as they show the changes. Therefore, we are actually able to identify the large dip in 2009 even at the levels shown in the graphs above. However, identifying whether growth rates are 2 or 3 percent is difficult based on the levels, and bar charts of growth rates are therefore a very common way to visualize the economic conditions.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/fig10} 

}

\caption{Annual GDP growth rates for the UK, 2000-2018. Using a bar  chart. Source: OECD. The GDP level is measured in terms of the 2017 price level.}\label{fig:gdp13}
\end{figure}

\hypertarget{decompose-growth}{%
\subsubsection*{2 Decompose growth}\label{decompose-growth}}
\addcontentsline{toc}{subsubsection}{2 Decompose growth}

We can use each of the GDP measurement approaches above to decompose the overall GDP growth. Using the expenditure approach, we could calculate the overall GDP growth as follows:

\begin{align}
growth\text{ }rate=&I's growth\text{ }rate\times I's\text{ }initial\text{ }share\text{ }of\text{ }GDP\\
                   &+G's growth\text{ }rate\times G's\text{ }initial\text{ }share\text{ }of\text{ }GDP\\
                   &+C's growth\text{ }rate\times C's\text{ }initial\text{ }share\text{ }of\text{ }GDP\\
                   &+NX's growth\text{ }rate\times NX's\text{ }initial\text{ }share\text{ }of\text{ }GDP
\end{align}
In words, the overall GDP growth is simply a weighted average of each component's growth rate. The weights are the share of overall GDP in the initial period.

Why is this useful? Say we wanted to know how household consumption \(C\) contributed to GDP growth. \(C's\) contribution is given by: \(growth\text{ }in\text{ }C\times C's\text{ }share\text{ }of\text{ }GDP\), which we can relate to the overall growth:

\begin{align}
C's\text{ }contribution\text{ }to\text{ }growth=\frac{growth\text{ }in\text{ }C\times C's\text{ }share\text{ }of\text{ }GDP}{overall\text{ }GDP\text{ }growth}
\end{align}

\hypertarget{business-cycles}{%
\subsubsection*{3 Business cycles}\label{business-cycles}}
\addcontentsline{toc}{subsubsection}{3 Business cycles}

Once we know the changes in economic activity, we can start characterizing periods by terms such as business cycles, booms, overheating and recessions. The actual definitions of these concepts are considerably less clear. The US National Bureau of Economic Research has a ``Business Cycle Dating Committee'' that specifies the chronology of the US business cycles. The committee does not have a fixed definition of recessions. Instead they combine real GDP, with data on the labour market and data on income. However, their definitions of recessions often coincide with a definition based on two consecutive quarters of decline in real GDP.

How exactly expansions and recessions are identified varies from country to country, but in the European Union we typically define a recession as two successive quarters of negative economic growth. A business cycle is typically defined as the period from a boom to recession and back to boom, in other words, from peak to peak. Figure \ref{fig:gdp13} shows annual levels, and we clearly see a drop in real output in 2008 and 2009. In terms of quarters, the growth rate was negative from the second quarter of 2008 to the second quarter of 2009.

\begin{myblock}
\textbf{GDP and business cycles}

\begin{itemize}
\tightlist
\item
  An economic recession is the period from peak economic activity to the
  lowest level of economic activity.
\item
  An economic expansion is the period from the lowest level of economic
  activity to the highest level of economic activity.
\item
  The economic cycle of recessions and expansions is called business
  cycles.
\item
  There is no general stringent definition of a recession, but two
  consecutive quarters of decline in real GDP is often seen as a sign of
  a recession.
\end{itemize}
\end{myblock}

\hypertarget{gdp-per-capita}{%
\subsubsection*{4 GDP per capita}\label{gdp-per-capita}}
\addcontentsline{toc}{subsubsection}{4 GDP per capita}

While GDP growth rates are used across time, we are sometimes also interested in comparing across regions or countries. First, we could be interested in identifying regional recessions and expansions. Second, we could be interested in comparing the level of economic activity per capita. To achieve the latter, we divide data on the total GDP for each region or country and divide by the number of residents in the region or country. Figure \ref{fig:gdp14} shows the economic activity per person in 2015. We have adjusted the price levels to be comparable across time and space. In this chart the values correspond to the price level of 2017 and we have adjusted all national values to the US price level and show the values in US dollars. To be clear, we do not simply use the exchange rate to translate the national currencies, but we also take differences in price levels across countries into account. Luxembourg has, by far, the highest level of economic activity per person, followed by Ireland and Switzerland. Of the OECD data with available data, Chile has the lowest GDP per person.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/fig11} 

}

\caption{GDP per capita for selected countries in 2015, measured in 2017 USD - PPP adjusted. Source: OECD. }\label{fig:gdp14}
\end{figure}

Figure \ref{fig:gdp15} shows the relative change in real economic activity per person from 2000 to 2015. Most countries increased the output per person, but not all.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_gdp/fig12} 

}

\caption{Real change in GDP per capita for selected countries 2000-2015, real values measured  in 2017 USD - PPP adjusted. Source: OECD.  }\label{fig:gdp15}
\end{figure}

\hypertarget{productivity}{%
\subsubsection*{Productivity}\label{productivity}}
\addcontentsline{toc}{subsubsection}{Productivity}

Productivity is a measure of how much we can produce relative to the resources used in the production. A higher productivity means that we produce more given resources (or produce the same with fewer resources).

A very common approach is to measure the Gross Value Added per worker or per hour worked. A higher value then suggests that we can produce a greater value added with fewer labor inputs. However, we could also consider other inputs such as capital. However, the most simple approach is probably GDP per worker. This is closely related to GDP capita, which we discussed above, but in this approach we only consider the individuals who are in the labor market. Using this approach we can provide a crude but straightforward indicator for the labor productivity of a country. Changes in productivity are often the first step in understanding changes in economic activity.

\hypertarget{the-balance-of-trade}{%
\subsubsection*{The balance of trade}\label{the-balance-of-trade}}
\addcontentsline{toc}{subsubsection}{The balance of trade}

The balance of trade is the difference between exports and imports, also called net exports and denoted \(NX\):

\begin{align}
  NX=X-M
\end{align}

\begin{itemize}
\tightlist
\item
  \emph{NX} is the balance of trade or net exports.
\item
  \emph{X} is goods and services produced domestically but consumed abroad (Exports)
\item
  \emph{M} is goods and services produced abroad and consumed domestically (Imports).
\end{itemize}

If the balance of trade is positive it means that a country has a trade surplus, because it exports more than it imports. If a country imports more than it exports, in other words, when the trade balance is negative, the country has a trade deficit.

\hypertarget{balance-of-payments}{%
\subsection*{Balance of payments}\label{balance-of-payments}}
\addcontentsline{toc}{subsection}{Balance of payments}

The balance of payments (BoP) captures the overall transactions between a country and the rest of the world. The ``balance'' means that the sum of the current account, financial account and capital account has to be zero.

\begin{itemize}
\tightlist
\item
  The current account consists of the balance of trade (as defined above) and the income balance (income earned abroad from domestic residents minus income earned by foreign residents).
\item
  The capital account captures international capital transfers.
\item
  The balancing item captures statistical inaccuracies.
\end{itemize}

\begin{align}
  \text{current account}+\text{capital account}+\text{balancing item}=0 
\end{align}

Let's consider an example: If we go to Germany on holiday and spend 10 in restaurants and hotels using our English credit card, we are causing a 10 debit on the trade balance. Let's say that we also export some English Breakfast tea for the value of 100 to Germany. This is noted as a 100 credit on the trade balance. The balance of trade is then \(100-10=+90\). We don't earn anything abroad and no foreigner earned something in England. The current account would then be \(+90\).

Now let us look at the capital account. The 10 spent abroad using our English credit card will be recorded in our capital account as an investment. If we also buy some German stocks for say 15, then these stocks will appear in debit as ``portfolio investment''. However, because we use our English credit card to buy these stocks, the 15 will also appear on our capital account as a credit (just like the hotel and restaurant shopping). Finally, the trade credit payment from the German tea buyer is recorded in the financial accounts as a debit. The net capital account is then \(25-115=-90\). As expected, the sum of the current account plus the capital account is zero. This occurs by definition through the double entry accounting framework (each entry is entered both as a debit or a credit).

It is common to separate out ``financial account'' from the capital account and use this extended definition:
\begin{align}
  \text{current account}+\text{capital account}+\text{financial account}+\text{balancing item}=0
\end{align}

\hypertarget{further-readings-2}{%
\section{Further readings}\label{further-readings-2}}

\begin{itemize}
\tightlist
\item
  \href{https://www.ons.gov.uk/economy/grossdomesticproductgdp/articles/gdpandme/2017-03-20}{GDP and Me by the ONS}
\item
  \href{https://www.ons.gov.uk/economy/grossdomesticproductgdp/articles/whatisgdp/2016-11-21}{What is GDP by the ONS}
\item
  \href{https://www.bankofengland.co.uk/knowledgebank/what-is-gdp}{What is GDP by the Bank of England}
\end{itemize}

\hypertarget{wellbeing}{%
\chapter{Wellbeing}\label{wellbeing}}

\hypertarget{about-this-chapter}{%
\section{About this chapter}\label{about-this-chapter}}

We will now follow up on some of the issues on measuring wellbeing raised in the last chapter. In the last chapter we learned how GDP is a measure of economic activity and how it is (mis)used as a measure of wellbeing. In this chapter we discuss the problems with using GDP as a wellbeing measure, what wellbeing is, and how we can measure it.

\hypertarget{intended-learning-outcomes-1}{%
\subsection{Intended learning outcomes}\label{intended-learning-outcomes-1}}

After reading this chapter you should be able to:

\begin{itemize}
\tightlist
\item
  Explain the problems of using GDP as a wellbeing measure.
\item
  Explain and identify subjective and objective measures of wellbeing.
\item
  Use publicly available measures of wellbeing and explain how they are created and relate to each other.
\item
  Use scatter plots and understand how we can combine several variables in one measure.
\end{itemize}

\hypertarget{the-limits-of-gdp}{%
\section{The limits of GDP}\label{the-limits-of-gdp}}

Based on last chapter's explanation of what GDP is and what it isn't we can already list some limitations.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  GDP only measures market activities. Recall the economy of Microeconomy. If the farmer produced the same flour, but didn't sell it to the bakery, but instead made bread at home, the bread would not be included in GDP, even though the actual output in terms of bread (assuming the farmer is as good a baker as the baker) is the same! In a situation like the COVID-19 pandemic, where we cannot go to shops like normal, we might increase our home production and reduce our market activities. This will lead GDP to fall.
\item
  It is unclear what activities are included. As discussed in the last chapter there is a greyzone of activities that could be included in GDP. This area reduces the comparability across regions and time.
\end{enumerate}

These limitations relate to GDP as a measure of economic activity. However, GDP (per person) is mostly criticized for being a poor measure of wellbeing. That is understandable, because such a measure would assume that (market) economy activity equals wellbeing. That is not necessarily the case.

\hypertarget{what-is-wellbeing}{%
\section{What is wellbeing?}\label{what-is-wellbeing}}

One of the reasons why the GDP is so popular is that it has a more or less globally accepted standard way of quantifying economic activity. Very few variables are as standardized as GDP (although there is some variation in what is included in the GDP measure). We use GDP because the GDP is available and because the GDP is comparable across countries and regions. Not even the definition of the unemployment rate is as standardized as the measure of GDP. We now know what the GDP captures and what we should use it for and for what we shouldn't use it. It is a measure of economic activity, not a measure of wellbeing. But what is wellbeing? What is welfare?

The first challenge is to agree on what we want to measure and what we want to call it. Is it wellbeing, happiness, welfare or quality of life? The ``Stiglitz report'' \citep{stiglitz2010report} (discussed below) uses the term ``Quality of Life'' and states the following:

\begin{quote}
``While a long tradition of philosophical thought has addressed the issues of what gives
life its quality, recent advances in research have led to measures that are both new and
credible. This research suggests that the need to move beyond measures of economic
resources is not limited to developing countries (the traditional focus of much work on
human development in the past) but is even more salient for rich industrialised countries.
These measures, while not replacing conventional economic indicators, provide an
opportunity to enrich policy discussions and to inform people's view of the conditions of the
communities where they live. More importantly, the new measures now have the potential to
move from research to standard statistical practice. While some of them reflect structural
conditions that are relatively invariant over time but that differ systematically across
countries, others are more responsive to policies and more suitable for monitoring changes
over shorter periods of time. Both types of indicator play an important role in evaluating
quality of life.
\end{quote}

\citep[page 41 in][]{stiglitz2010report}

We will go through the three conceptual approaches discussed in the Stiglitz report below and later present some measures of quality of life and wellbeing in practice and how they relate to the conceptual approaches.

\hypertarget{gdp-and-wellbeing}{%
\section{GDP and wellbeing}\label{gdp-and-wellbeing}}

\hypertarget{the-stiglitz-report}{%
\subsection*{The Stiglitz Report}\label{the-stiglitz-report}}
\addcontentsline{toc}{subsection}{The Stiglitz Report}

One important milestone in the debate on measuring wellbeing and quality of life is the so called ``Stiglitz Report'' \citep{stiglitz2010report}, named after one of the authors, professor Joseph E. Stiglitz. The official title of the report is ``Report by the Commission on the Measurement of Economic Performance and Social Progress''. The goal of the commission behind the report was

\begin{quote}
``to identify the limits of GDP as an indicator of economic performance and social progress, including the problems with its measurement; to consider what additional information might be required for the production of more
relevant indicators of social progress; to assess the feasibility of alternative measurement
tools, and to discuss how to present the statistical information in an appropriate way.''
\end{quote}

page 7 in \citep{stiglitz2010report}.

The report provides detailed examples and criticism of GDP as a measure of wellbeing and social progress as well, as discussed, conceptual approaches to measure wellbeing. We will first briefly discuss some of the most prominent criticism of GDP as a measure of wellbeing and then return to how we could do a better job.

\hypertarget{criticism-of-gdp-as-a-wellbeing-measure}{%
\subsection*{Criticism of GDP as a wellbeing measure}\label{criticism-of-gdp-as-a-wellbeing-measure}}
\addcontentsline{toc}{subsection}{Criticism of GDP as a wellbeing measure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{GDP is a poor measure of human welfare}

  The first criticism is probably the most-known critique: GDP measures the consumption of goods and services (the expenditure approach), and while these aspects might be correlated with quality of life, there are many aspects of utility and wellbeing that are not captured by GDP. To list a few:

  \begin{itemize}
  \tightlist
  \item
    Nature and environment (pollution)
  \item
    Education
  \item
    Health
  \item
    Crime and safety
  \end{itemize}

  Consider two countries that have an identical GDP per capita. In the first country there is almost no pollution, there are beautiful mountains, forests, lakes and beaches. In the second country there is lots of pollution and no access to nature. Moreover, in the first country life expectancy is high and the population have very few health problems. In the second country life expectancy is low and the mental and physical health of the population is very low.

  Would you say that wellbeing is the same in the two countries (they have the same GDP per capita)? Probably not. GDP per capita does not capture all these elements listed above (and many elements we did not list).

  Many studies find that GDP per capita is correlated with the dimensions above. For example that higher GDP capita is associated with lower infant mortality rates. But this is not the case for all dimensions, and the question is whether it is sufficient that GDP is correlated with these aspects.
\item
  \textbf{GDP ignores the distribution}

  Again, consider two countries with identical GDP per capita. In the first country, some have a bit more resources than others, but very few are poor and very few are extremely rich. In the second country all inhabitants are poor, with the exception of one extremely rich person. Is the wellbeing the same in these two countries?

  In practice we often observe GDP growth rates that affect the population unevenly. The well-educated population may benefit more from growth driven by advanced innovation than unskilled workers. The GDP per capita measure does not capture these distributional effects. Recall from the last chapter that Kusnets already mentioned the issue of not accounting for the distribution of income \citep[page 6 in][]{kuznets1934national}.
\item
  \textbf{wellbeing is not monotonically increasing}

  Does GDP growth always make people happier? And is the effect constant? Promoting GDP growth appears to be an endless goal, but in practice, the effect of more GDP on wellbeing might be non-linear and even non-monotonic. Going from starvation to having enough food and decent living conditions might affect wellbeing more than the same monetary increase for people who already have very high living standards. Moreover, there might be a certain level of saturation, after which more GDP does not lead to increases in wellbeing.

  Some evidence suggests that after a certain level of resources, people care mostly about their relative position. This is phenomenon is called ``keeping up with the Joneses'', where we envy those who have more than us, and enjoy looking at those who have less than us. In such a case, a uniform increase in income for all of us has no effect on our wellbeing.
\end{enumerate}

\hypertarget{how-to-measure-wellbeing-quality-of-life}{%
\section{How to measure wellbeing \& quality of life}\label{how-to-measure-wellbeing-quality-of-life}}

\hypertarget{recommendations-from-the-stiglitz-report}{%
\subsection*{Recommendations from the Stiglitz report}\label{recommendations-from-the-stiglitz-report}}
\addcontentsline{toc}{subsection}{Recommendations from the Stiglitz report}

The commission identified the following three conceptual approaches to measuring quality of life:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Subjective wellbeing}

  The key idea is that we simply ask people about their wellbeing and happiness with the idea that: ``that enabling people to be happy and satisfied with their life is a universal goal of human existence.'' from page 7 in \citep{stiglitz2010report}
\end{enumerate}

There are several standardized questionnaires to capture the measures above and many of them show consistent patterns:

\begin{quote}
``Research has shown that it is possible to collect meaningful and reliable data on
subjective wellbeing. Subjective wellbeing encompasses different aspects (cognitive
evaluations of one's life, positive emotions such as joy and pride, and negative emotions such as pain and worry): each of them should be measured separately to derive a more comprehensive appreciation of people's lives. Quantitative measures of these subjective aspects hold the promise of delivering not just a good measure of quality of life per se, but also a better understanding of its determinants, reaching beyond people's income and material conditions.''
\end{quote}

page 58 in \citep{stiglitz2010report}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \emph{Capabilities}

  The second conceptual approach to measuring wellbeing is to measure individuals' ability to pursue and realise the goals that they value (the capabilities).
\item
  \emph{Fair allocations}

  The third conceptual approach to measuring wellbeing is to measure the allocation of resources among people with different tastes and abilities.
\end{enumerate}

\hypertarget{operationalizing-wellbeing-measures}{%
\subsection*{Operationalizing wellbeing measures}\label{operationalizing-wellbeing-measures}}
\addcontentsline{toc}{subsection}{Operationalizing wellbeing measures}

\hypertarget{subjective-wellbeing-measures}{%
\subsubsection*{Subjective wellbeing measures}\label{subjective-wellbeing-measures}}
\addcontentsline{toc}{subsubsection}{Subjective wellbeing measures}

Subjective wellbeing measures are often divided into the following three types:

\begin{itemize}
\item
  Evaluative measures

\begin{verbatim}
In this approach we ask respondents to evaluate their life satisfaction, their health, or in general their wellbeing. We can anchor these questions ("relative to the best possible state" or relative to some objective state.).
\end{verbatim}
\item
  Experience measures

  In this approach we ask respondents about their feelings or experiences at specific points during the day (or during the week).
\item
  Eudemonic measures

  This approach focuses on psychological aspects of individual wellbeing and relates to the individual's position and control over their life.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_wellbeing/subwb} 

}

\caption{Ask people how they feel}\label{fig:wfig2}
\end{figure}

\hypertarget{objective-wellbeing-measures}{%
\subsubsection*{``Objective'' wellbeing measures}\label{objective-wellbeing-measures}}
\addcontentsline{toc}{subsubsection}{``Objective'' wellbeing measures}

Objective measures of wellbeing are called objective because they are based on objective quantities, such as measures of income, health, crime, and access to nature. This could for example be my disposable income, the life expectancy in my neighbourhood, the number of crimes committed per inhabitant in my neighbourhood, and the amount of green space in my neighboorhood. As long as we agree on how to measure these quantities there is no subjectivity involved in these measures of wellbeing. However, aggregate objective wellbeing measures should not be taken better measures than the subjective measures, because the choice of indicators to include depend on a normative judgement.

\begin{quote}
``The information relevant to valuing quality of life goes beyond people's self-reports and perceptions to include measures of their functionings and freedoms. While the precise list of these features inevitably rests on value judgements, there is a consensus that quality of life depends on people's health and education, their everyday activities (which include the right to a decent job and housing), their participation in the political process, the social and natural
environment in which they live, and the factors shaping their personal and economic security. Measuring all these features requires both objective and subjective data. The challenge in all these fields is to improve upon what has already been achieved, to identify gaps in available information, and to invest in statistical capacity in areas (such as time-use) where available indicators remain deficient.''
\end{quote}

page 58 in \citep{stiglitz2010report}

\hypertarget{measuring-wellbeing-in-practice}{%
\section{Measuring wellbeing in practice}\label{measuring-wellbeing-in-practice}}

Let us now discuss approaches to measuring wellbeing in practice and how they relate to the approaches discussed above.

\hypertarget{quick-introduction-reducing-dimensionality}{%
\subsection*{Quick introduction: reducing dimensionality}\label{quick-introduction-reducing-dimensionality}}
\addcontentsline{toc}{subsection}{Quick introduction: reducing dimensionality}

How can we create a wellbeing measure that combines measures of subjective wellbeing, measures of health, education, environment, and crime in one statistic?

When working with topics such as global development or wellbeing, we are often interested in aggregating several variables to obtain one variable. Many of the strategies to achieve this are beyond the scope of this unit, but you should be aware of these methods.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Creating an index

  wellbeing measures such as the Human Development Index are based on aggregating three individual indices by means of the \textbf{geometric mean}.
\end{enumerate}

\begin{align}
   HDI=(LEI\times EI\times II)^{1/3}
\end{align}

Where \(LEI\) is the life expectancy index, \(EI\) is the education index, and \(II\) is the income index. Each of these indices are measured on a scale from 0 to 1, where the raw variables are related to some ``max'' value. For example for life expectancy, the maximum is 85 (i.e.~an index value of 1) and the minimum is 20 (i.e.~an index value of 0). A standard formula for measuring the individual index is as follows:

\begin{align}
   I=\frac{Y-Y_{MIN}}{Y_{MAX}-Y_{MIN}}.
\end{align}

To create an index, just like the HDI, we therefore first convert each variable to be on a scale between 0 and 1 using the formula above, and we then compute the geometric mean across all Indexes \(i\):

\begin{align}
   \text{Aggregate Index}=\left(\prod_{i=1}^N I_i\right)^{1/N}
\end{align}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Principal Component Analysis and Factor Analysis
\end{enumerate}

Principal component analysis (PCA) and Factor analysis are methods to reduce the dimensionality of data. These approaches are very often used in regressions, when you want to reduce the number of variables. With these methods you can identify a set of \emph{components} or \emph{factors} that describe the variation in the data. The goal is typically to identify a set of components and factors that are smaller than the number of variables used.

Intuitively speaking, the goal is to identify variables that ``move in the same direction''. Imagine that you have a dataset with 25 behavioural measures of a child. Five of these measures relate to the child's peer relations. When one of these variables goes up, the other four also tend to go up. Another five variables might capture the child's level of hyperactivity and inattention, again, if one of the five variables goes up, the other four also tend to go up. Therefore, we have identified two separate components, that each cover five underlying variables.

Factor analysis and principal component analysis are two distinct methods. Factor analysis is more based on theories of underlying latent (unobserved) variables, while principal component analysis is more based on the objective to reduce the number of dimensions (number of variables) in the data.

\begin{myblock}
\textbf{Reducing the dimensions}

Because wellbeing depends on several aspects, such as health,
environment, income and education, it is hard to compare across time and
space. There are simply too many ``dimensions''. We would like to reduce
the wellbeing to one variable, to one dimension. There are several
approaches to combining several variables into one variable. The
following two methods are very common:

\begin{itemize}
\tightlist
\item
  \emph{An index based on a geometric mean}
\item
  \emph{Principal component analysis}
\end{itemize}
\end{myblock}

\hypertarget{the-human-development-index-un}{%
\subsection*{The Human Development Index (UN)}\label{the-human-development-index-un}}
\addcontentsline{toc}{subsection}{The Human Development Index (UN)}

The Human Development Index (HDI) is developed by the United Nations Development Programme (UNDP). The index is an example of combining several objective indicators of wellbeing in one measure. The index consists of the three dimensions:

\begin{itemize}
\tightlist
\item
  Life expectancy index
\item
  Education index
\item
  Income index.
\end{itemize}

The HDI is created by the geometric mean of the three indices above. There has been some changes in the HDI definition over time. Data is available for the period 1995-2015 for many countries across the world. The data can be downloaded from the website of the United Nations: \href{http://worldhappiness.report/}{UN}.

\hypertarget{world-happiness-report}{%
\subsection*{World Happiness Report}\label{world-happiness-report}}
\addcontentsline{toc}{subsection}{World Happiness Report}

Published by the United Nations since 2012, the World Happiness Report uses data from the Gallup World Poll to describe global happiness patterns, by linking these data to specific topics (for example migration). The data is available for download here: \href{http://worldhappiness.report/}{World Happiness Report}.

\hypertarget{oecd-better-life-index}{%
\subsection*{OECD Better Life Index}\label{oecd-better-life-index}}
\addcontentsline{toc}{subsection}{OECD Better Life Index}

The OECD has computed the ``Better Life Index'' since 2013. The index is a combination of subjective and objective indicators that captures 11 dimensions of wellbeing: housing, income, jobs, community, education, environment, civic engagement, health, life satisfaction, safety and work-life balance. The data is available both as a total, by subgroups (men and women) and by distribution (low vs.~high). The data can be downloaded from the OECD website: \href{https://stats.oecd.org/}{OECD}.

\hypertarget{ons-measuring-national-wellbeing}{%
\subsection*{ONS Measuring National wellbeing}\label{ons-measuring-national-wellbeing}}
\addcontentsline{toc}{subsection}{ONS Measuring National wellbeing}

The UK office for National Statistics collects data on wellbeing measures. These data are a combination of subjective and objective indicators and capture personal wellbeing, relationships, health, what we do, where we live, personal finance, the economy, education and skills, governance, and the natural environment. The data is available both on an aggregated level, and also on a regional level from the ONS website: \href{https://www.ons.gov.uk/peoplepopulationandcommunity/wellbeing}{ONS}.

\hypertarget{quality-of-life-indicators}{%
\subsection*{Quality of life indicators}\label{quality-of-life-indicators}}
\addcontentsline{toc}{subsection}{Quality of life indicators}

Eurostat publishes various statistics related to quality of life. They have identified nine indicators to capture quality of life. These aspects are also a mix of subjective and objective indicators. A description of their approach and links to data is available here: \href{http://ec.europa.eu/eurostat/statistics-explained/index.php/Quality_of_life_indicators_-_measuring_quality_of_life\#Overall_experience_of_life}{eurostat}.

\hypertarget{why-is-the-gdp-used-anyway}{%
\subsection*{Why is the GDP used anyway?}\label{why-is-the-gdp-used-anyway}}
\addcontentsline{toc}{subsection}{Why is the GDP used anyway?}

Why is GDP so important in policy making despite the criticism above? First of all, as discussed above GDP has the advantage of being available and being standardized. Secondly, it is correlated with many of the wellbeing measures discussed above. In Figure \ref{fig:wb1} we combine data on GDP per capita and the quality of life measures from Eurostat. What do you think of the relationship? Do you recognize any of the criticism of GDP as a wellbeing measure?

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./resources/chapter_wellbeing/fig1} 

}

\caption{GDP per capita and subjective wellbeing in 2018 Source: Eurostat }\label{fig:wb1}
\end{figure}

To assess the relationship between the two variables, GDP per capita and Subjective wellbeing we used a scatter plot. A scatter plot is like an unconnected line chart where the vertical and horizontal positions represent the values of respectively the variables on the vertical (y) axis and horizontal axis (x). Scatter plots are very powerful tools to show relationships between variables, especially when we have a lot of data.

\hypertarget{further-readings-3}{%
\section{Further readings}\label{further-readings-3}}

In this chapter we covered the following topics:

\begin{itemize}
\item
  \href{https://www.stat.si/doc/drzstat/Stiglitz\%20report.pdf}{Executive Summary of the Stiglitz Report}
\item
  \href{Beyond\%20GDP\%20Measuring\%20What\%20Counts\%20for\%20Economic\%20and\%20Social\%20Performance}{Beyond GDP (The Stiglitz Report)}
\item
  \href{https://press.princeton.edu/books/paperback/9780691169859/gdp}{GDP: A Brief but Affectionate History: A Brief But Affectionate History - Revised and Expanded Edition Paperback -- 22 Sept.~2015}
\end{itemize}

\hypertarget{inequality}{%
\chapter{Inequality}\label{inequality}}

\hypertarget{about-this-chapter-1}{%
\section{About this chapter}\label{about-this-chapter-1}}

One of the criticisms of GDP as a well-being measure is that ``GDP ignores the distribution''. GDP is simply an average across the entire economy. It doesn't tell us who experiences the ``economic activity'', beyond the decomposition into sectors or workers and firms. If we look behind these total numbers and consider the \emph{distribution} of income, we would probably see something like the chart shown in Figure \ref{fig:in0}. The chart is a histogram of income for a simulated income. Most individuals earn an income well below 100 thousand pounds per year, but some earn way more than that. This chapter is about how we can describe such patterns and compare them across countries and across time.

\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{./resources/chapter_inequality/hist2} 

}

\caption{The distribution of income. Data is simulated.}\label{fig:in0}
\end{figure}

\hypertarget{intended-learning-outcomes-2}{%
\subsection{Intended learning outcomes}\label{intended-learning-outcomes-2}}

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  Explain the difference between macro and micro level data.
\item
  Explain the data requirements for studying income or wealth inequality.
\item
  Create histograms and compute income shares
\item
  Create a Lorenz curve
\item
  Calculate and interpret the GINI coefficient
\end{itemize}

\hypertarget{inequality-dimensions}{%
\section{Inequality dimensions}\label{inequality-dimensions}}

Before we turn to the examples of actual measures of inequality it is worth discussing the multi-dimensionality of inequality. Let's list of issues.

\begin{itemize}
\item
  Inequality across domains: Inequality is not only about income or wealth, it is also about health, law, and access to cultural and natural amenities.
\item
  Inequality by gender and race: Inequality is often systematically related to gender and race.
\item
  Segregation: Inequality is also closely related to segregation in the society. Do we live together and meet people of different backgrounds?
\end{itemize}

This list is very far from being exhaustive (you could write books with such lists). The goal of the list is just to help you get started thinking about inequality dimensions and aspects.

\hypertarget{data-requirements-2}{%
\section{Data requirements}\label{data-requirements-2}}

\hypertarget{macro-and-micro-level-data}{%
\subsection{Macro and micro level data}\label{macro-and-micro-level-data}}

\hypertarget{macro-level-data}{%
\subsubsection*{Macro level data}\label{macro-level-data}}
\addcontentsline{toc}{subsubsection}{Macro level data}

So far we've mostly been using macro level data. Macro level data is data about countries, regions or other entities comprising many individuals, households, firms and institutions. An observation in macro data represents the average, the sum or another statistic of these individuals, firms and institutions. We can typically download most macro data from a public source.

\hypertarget{micro-level-data}{%
\subsubsection*{Micro level data}\label{micro-level-data}}
\addcontentsline{toc}{subsubsection}{Micro level data}

In micro level data each observation represents the value for an individual, a household, a firm or an institution. Micro data is often the basis for macro data. It is often based on surveys or administrative records. Micro data is rarely directly accessible from public sources. One reason for this is that micro data often contains a lot of detailed information that shouldn't be shared freely with everyone. Getting access to micro data therefore often requires us to submit an application and sign a confidentiality agreement. Moreover, when working with micro level data we should be careful about how we share and store the data.

\hypertarget{net-and-gross-values}{%
\subsection*{Net and gross values}\label{net-and-gross-values}}
\addcontentsline{toc}{subsection}{Net and gross values}

When assessing the distribution of income within the population it is important first to decide whether we are interested in the net or gross income distribution. We've already used the term ``net'' and ``gross'' on several occasions. When discussing net-migration or Gross Domestic Product. But what do these terms mean? In general we can think of the terms net and gross as follows:

\begin{itemize}
\tightlist
\item
  Gross: The value without deductions, contributions etc.
\item
  Net: The value after deductions, contributions etc.
\end{itemize}

We use the terms net and gross in many situations. If you buy packaged food the label might display the gross and net weight. The gross weight will then be the total weight before deductions, the net weight will be the weight of the product after we deducted the weight of the packaging etc.

The most common use of the terms net and gross is probably in income, where gross refers to the income before taxes, and net to the income after taxes. Statistical offices and economists in general agree on excluding taxes from gross terms and including taxes in net terms, but there is less agreement on whether transfers such as housing benefits and unemployment benefits in net terms should be included.

When working with income data, the concept of disposable income is therefore also often used instead. The idea is that we want to consider the income that the household can spend, which will be the income after all taxes, transfers, and deductions.

\hypertarget{equivalenced-income}{%
\subsection*{Equivalenced income}\label{equivalenced-income}}
\addcontentsline{toc}{subsection}{Equivalenced income}

When working with income data we are often interested in comparing households instead of individuals. However, households are not all of the same sizes, and we will therefore have to adjust monetary measures to the size of the households. We call income that is adjusted to household equivalenced income. We will here briefly discuss the three most common approaches to equivalise income.

\begin{itemize}
\item
  The Oxford scale or OECD equivalence scale.

  \begin{itemize}
  \tightlist
  \item
    The first person in the household: Weight 1
  \item
    Each additional adult household member: Weight 0.7 (person aged 14 and over)
  \item
    Each child household member: Weight 0.5
  \end{itemize}
\item
  The OECD modified scale.

  \begin{itemize}
  \tightlist
  \item
    The first person in the household: Weight 1
  \item
    Each additional adult household member: Weight 0.5 (person aged 14 and over)
  \item
    Each child household member: Weight 0.3
  \end{itemize}
\item
  The Square root scale.

  \begin{itemize}
  \tightlist
  \item
    Total weight: square root of the number of household members.
  \end{itemize}
\end{itemize}

While the square root method is probably the most popular approach, the choice of approach is non-trivial as Table \ref{tab:povt0} shows. The table shows four different households that all have the same income, but the composition of households varies. The Oxford scale does for example put quite high weight on children compared to the modified OECD scale. The square root scale on the other hand puts the same weight on adults and children, but each additional member gets a lower weight.

\begin{longtable}[]{@{}lcccc@{}}
\caption{\label{tab:povt0} Equivalencing income}\tabularnewline
\toprule
Adults & 1 & 2 & 1 & 2 \\
\midrule
\endfirsthead
\toprule
Adults & 1 & 2 & 1 & 2 \\
\midrule
\endhead
Children & 0 & 0 & 1 & 2 \\
Household income & 100 & 100 & 100 & 100 \\
Equivalised income & & & & \\
Oxford scale & 100 & 58.824 & 66.667 & 37.037 \\
OECD modified & 100 & 66.667 & 76.923 & 47.619 \\
Square root & 100 & 70.711 & 70.711 & 50.000 \\
\bottomrule
\end{longtable}

When working with household income data you should adjust income measures and be aware of the differences between the approaches.

\hypertarget{income-shares}{%
\section{Income shares}\label{income-shares}}

Having discussed inequality dimensions and data requirements we are finally ready to start looking at inequality. But how? How can we summarise the distribution shown in Figure \ref{fig:in0} in a measure of inequality? If we share a cake among four friends, we would evaluate whether the distribution of cake is equal by assessing whether everyone had an equal share of the cake. Everyone should have 25 percent of the cake. We can conduct a similar exercise with income. Let's first try this on the simulated example from above. The chart below splits the population 100 percentile groups according to their income.

The 1st percentile has a share of the total income of 0.2\%. That is one-fifth of what this group would have if income was equally distributed. In terms of the cake it would correspond to me only getting 5\% of the total cake when sharing it with three friends.
The person at the 25th percentile has an income share of 0.6\%. This is still almost half of what this person would have if income was equally distributed. Looking at the top 1\% we observe from the figure that this group gets 3.4\% of the income share. That is more than 3 times the equal share. That is like me getting more than 75\% of the cake. If we had calculated the share of income of the top 0.1 \% we would get that this group got about 0.5\% of total income. That is 5 times more than the equal share. Sounds like a lot of inequality? That is nothing compared to actual inequality.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{06_inequality_files/figure-latex/inx1-1} 

}

\caption{\label{fig:figx} Income shares based on simulated data.}\label{fig:inx1}
\end{figure}

Let's try to look at some real data. We don't have access to individual level income data, but several data sources provide processed income data on income. The following example uses data from the \href{https://wid.world/data/}{World Inequality Database}.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./resources/chapter_inequality/fig2} 

}

\caption{ Income shares in the UK. Data source: World Inequality database}\label{fig:inx2}
\end{figure}

So what does this chart tell us? We can see that in the early 1980ies, the top 1 percent (the p99p100) had about seven percent of the total income in the UK. That is about 7 times more than their equal share. In 2012 that share was about 12 percent. The income share of the top 1 percent has increased and almost doubled over the last three decades.

Where did that increase in income for the top 1 percent come from? The red line in the chart shows the income share of the bottom 50 percent. This group had about 24 of the total income in the early 1980ies. That is about half of their equal share. Over the three decades their income share dropped by about 2.5 percentage points. Part of the increase in the top income share is therefore from the bottom 50 percent, but not everything.

We have now introduced already used our first measures of inequality:

\begin{itemize}
\tightlist
\item
  the income share of the top 1 percent.
\item
  the income share of the bottom 50 percent.
\end{itemize}

\hypertarget{the-lorenz-curve-and-the-gini-coefficient}{%
\section{The Lorenz curve and the Gini coefficient}\label{the-lorenz-curve-and-the-gini-coefficient}}

So far, we have looked at specific parts of the income distribution. What about the other parts of the income distribution and their income shares? And can we combine all these income shares in one measure? Yes, that is what the Lorenz curve does.

One of the most common approaches to showing income distributions is the Lorenz-curve, developed by the American economist, Max Lorenz. The curve plots the share of total income relative to the position in the income distribution. So on the x-axis we rank the population by their income and on the y-axis we show the cumulative income share. Here is a cookbook for creating a Lorenz curve:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort all households (individuals) by their income, from lowest to highest and give them a relative income rank.
\item
  Compute the total income for the population.
\item
  For each individual in the household calculate their share of total income.
\item
  Calculate the cumulative income share by adding the individual shares. So for the household with the lowest income, the cumulative share is just their income share. For the second lowest income household, the cumulative income share is their share plus the share of the lowest income household.
\item
  Create a line chart of the cumulative income shares against the household (individual) income rank.
\end{enumerate}

In Figure \ref{fig:inx2} we already did steps 1 to 3. We now just need to calculate the cumulative share and draw a line. Let's see how that looks. In \ref{fig:inx3a} we've simply replaced the individual income shares with the cumulative shares. This is our first Lorenz Curve. We also added the 45 degree line. It shows how the line should look if income was perfectly equally distributed. We see that the actual line deviates considerably from the equal distribution. The size of the area between the two lines divided by the size of the triangle is known as the \textbf{GINI coefficient}. The larger the larger the deviation, the larger the GINI coefficient and the more unequal the income distributed.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{06_inequality_files/figure-latex/inx3a-1} 

}

\caption{\label{fig:figx} Income shares based on simulated data.}\label{fig:inx3a}
\end{figure}

Let's now consider a very simple example of an economy with 10 households as shown in Table \ref{tab:povt1}. In scenario 1 all households have the same income. In scenario 2, one household has all income of the economy. In scenario 3 the income is gradually increasing.

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:povt1} 3 examples of distributions}\tabularnewline
\toprule
Household & Scenario 1 & Scenario 2 & Scenario 3 \\
\midrule
\endfirsthead
\toprule
Household & Scenario 1 & Scenario 2 & Scenario 3 \\
\midrule
\endhead
1 & 10 & 0 & 3 \\
2 & 10 & 0 & 5 \\
3 & 10 & 0 & 6 \\
4 & 10 & 0 & 8 \\
5 & 10 & 0 & 9 \\
6 & 10 & 0 & 10 \\
7 & 10 & 0 & 12 \\
8 & 10 & 0 & 13 \\
9 & 10 & 0 & 14 \\
10 & 10 & 100 & 20 \\
\bottomrule
\end{longtable}

In situation 1, where every individual has the same share of the total income the Lorenz curve will be a straight line, the 45 degree line, as shown by the black line in Figure \ref{fig:poverty0}. While this situation is never seen in practice, this situation is important because it serves as a reference point for a completely equal income distribution.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_inequality/ex6_1} 

}

\caption{Lorenz curves for 3 different income distributions.}\label{fig:poverty0}
\end{figure}

Situation 2 is the other extreme, where one household has 100 percent of the income, as shown in Figure @ref\{fig:poverty0\}. Finally, the green line in \ref{fig:poverty0} shows situation 3, where every household has some income, but the income share is slowly increasing. Note from Table \ref{tab:povt1} that in Situation 3, the sixth household has the same income as in the perfectly equal situation. All households below (1-5) have a lower share than in the equal situation and all households above have a higher share.

Based on the Lorenz curve we can make statements on the income distribution, such as ``the bottom 30 percent has 14 percent of the total income'' or ``the bottom 50 percent has 31 percent of the income'' (Situation 3).

While the Lorenz curve provides a graphical representation of the income distribution, we are often interested in quantifying the income distribution in one number. This can be done by means of the Gini coefficient. We use the Lorenz-curve and situation 1 above as a point of departure to calculate the Gini coefficient.

\hypertarget{the-gini-coefficient}{%
\subsection*{The Gini coefficient}\label{the-gini-coefficient}}
\addcontentsline{toc}{subsection}{The Gini coefficient}

Note from the discussion above, that the 45 degree line represents a perfectly equal distribution. To quantify the degree of inequality we are interested in quantifying how far we are from that situation. One way to quantify this is by means of the area between the actual income distribution and the 45 degree line, corresponding to area A in Figure \ref{fig:poverty1}. The smaller this area is, the closer we are to the perfect equal distribution. We can then scale this area to the total area below the 45 degree line, which is area A and area B in Figure \ref{fig:poverty1}, and that is the Gini coefficient. The Gini coefficient will always be between 0 (perfectly equal) and 1 (perfectly unequal).

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{./resources/chapter_inequality/tikz} 

}

\caption{The Lorenz curve and the Gini coefficient. The Gini coefficient is $A/(A+B)$.}\label{fig:poverty1}
\end{figure}

Returning to the example above, how can we calculate the Gini coefficient? First note, that the curves in Figure \ref{fig:poverty1} are not smooth as in Figure \ref{fig:poverty1}. In practice, it is discrete and not continuous. We can therefore approximate the areas by considering the difference between the 45 degree line and the actual income share for each household, as shown by the grey bars in Figure \ref{fig:poverty2}. We can then relate the sum of the area of these bars to the sum of the area of these bars and the orange bars in Figure \ref{fig:poverty2} (corresponding to area B).

\begin{figure}

{\centering \includegraphics[width=0.48\linewidth]{./resources/chapter_inequality/ex6_4} \includegraphics[width=0.48\linewidth]{./resources/chapter_inequality/ex6_5} 

}

\caption{Approximating the Gini coefficient using the Lorenz curve Left: approximation of area A. Right: approximation of are B.}\label{fig:poverty2}
\end{figure}

Table \ref{tab:povt2} shows how we can approximate areas A and B in the simple examples above to calculate the Gini coefficient. We simply use the approach illustrated in Figure \ref{fig:poverty3}. Each bar has a width of 0.1 which we multiply by the height of the bar.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1053}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.3421}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0658}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.4079}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0789}}@{}}
\caption{\label{tab:povt2} Calculation of the Gini coefficients for scenario 2 and 3.}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Scenario 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Scenario 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Scenario 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Scenario 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule
\endhead
Decile & Income share (B) & A & Income share (B) & A \\
1 & 0 & 0.1 & 0.03 & 0.07 \\
2 & 0 & 0.2 & 0.08 & 0.12 \\
3 & 0 & 0.3 & 0.14 & 0.16 \\
4 & 0 & 0.4 & 0.22 & 0.18 \\
5 & 0 & 0.5 & 0.31 & 0.19 \\
6 & 0 & 0.6 & 0.41 & 0.19 \\
7 & 0 & 0.7 & 0.53 & 0.17 \\
8 & 0 & 0.8 & 0.66 & 0.14 \\
9 & 0 & 0.9 & 0.8 & 0.1 \\
10 & 1 & 0 & 1 & 0 \\
& & & & \\
Sum & 1 & 4.5 & 4.18 & 1.32 \\
& & & & \\
Gini & \(\frac{4.5}{1+4.5}=0.82\) & & \(\frac{1.32}{1.32+4.18}=0.24\) & \\
\bottomrule
\end{longtable}

In the case of the very unequal distribution of resources, we get a Gini coefficient of 0.82 (situation 2) and in the (more realistic) situation 3, we get a Gini coefficient of 0.24. So how do these Gini coefficients correspond to real world Gini coefficients? Figure \ref{fig:poverty3} shows a bar chart of Gini coefficients for European countries in 2016. According to Eurostat, the UK had a Gini coefficient of 0.315 in 2016. Serbia had a Gini coefficient of 0.386 and Slovakia a coefficient of 0.243. The simple ``realistic'' example (situation 3) is therefore not far from what we observe in the real world.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_inequality/ex7} 

}

\caption{Gini coefficients in 2016 for European countries. Source: Eurostat.}\label{fig:poverty3}
\end{figure}

Can we generalize our ``Gini'' approximation above to obtain a formula? First, note that both the x and y axis go from 0 to 1, the area of A+B will therefore always be 0.5 (\(1\times 1\times 0.5=0.5\)), we can therefore write:

\begin{align}
    Gini&=A/(A+B)\nonumber\\
    &=A/0.5\nonumber\\
    &=1-2B
\end{align}

where we simply used that since \(A+B=0.5\) we have that \(A=0.5-B\). Now we just need to find the area \(B\). First, let us define household \(i's\) income (or wealth) be \(y_i\), where we have sorted all households according to their income (or wealth) rank. The first household (the one with the lowest income or wealth) will have the following contribution to the area B:

\begin{align}
  b_1=\frac{y_1}{\sum_i^ny_i}
\end{align}

the second household will contribute with the following value:

\begin{align}
  b_2=\frac{y_1+y_2}{\sum_i^ny_i}
\end{align}

finally, we sum over all these households to get:

\begin{align}
  B=&\frac{1}{n}\frac{y_1}{\sum_i^ny_i}+\frac{1}{n}\frac{y_1+y_2}{\sum_i^ny_i}+\dots+\frac{1}{n}\frac{y_1+y_2+\dots+y_n}{\sum_i^ny_i}\nonumber\\
  B=&\frac{1}{n}\frac{y_1+y_1+y_2+\dots y_1+y_2+\dots+y_n}{\sum_i^ny_i}\nonumber\\
  B=&\frac{1}{n}\frac{ny_1+(n-1)y_2+\dots+y_n}{\sum_i^ny_i}\nonumber\\
  B=&\frac{1}{n}\frac{\sum_i^n(n-i+1)y_i}{\sum_i^ny_i}\nonumber\\
\end{align}

which we can insert in the expression for \(Gini\) above to get an expression for the approximate Gini coefficient:

\begin{align}
    Gini&=1-\frac{2}{n}\frac{\sum_i^n(n-i+1)y_i}{\sum_i^ny_i}\nonumber
\end{align}

It is important to note that the formula is an approximation based on the bar chart approach. It will work well as long as the number of bars is sufficiently large. There are many formulas for the Gini coefficient. The above is simple and straightforward, but there are other formulas that give more precise estimates. This formula tends to overestimate area B, because we are approximating the area using the height at the right end of the bars (a small improvement is simply to use the average of the height of the bar and the height of the lagged bar).

What is good about the Gini coefficient? First of all, the Gini coefficient is just one number, and it is thus easy to compare across countries and time. Secondly, it satisfies a number of key principles: (A) it is independent of a of a country's size and the currency used, (B) if a rich a household transfers money to a poor household the Gini will be reduced and (C) it is anonymous (it does not say anything about who the poorest and richest households are).

Is the Gini coefficient a perfect measure of inequality? No! Institutional settings differ considerably. How health care in a country is financed will affect the inequality. If all health care is privately funded, it will take out a large share of low income households, and a relatively low share of high income households. On the other hand, if health care is financed by a progressive income tax this will not be the case.

Another issue with the Gini coefficient is that it depends on the quality of the data. If it is only calculated based on deciles (as above) it will be considerably less precise than if it is calculated based on thousands of observations.

\hypertarget{other-measures-of-inequality}{%
\section{Other measures of inequality}\label{other-measures-of-inequality}}

The Gini coefficient is by far the most popular measure of inequality. The data is available across time and areas for many different countries. However, as mentioned above, it is not perfect and there are alternative measures. Let's briefly discuss a few:

\hypertarget{ratios}{%
\subsubsection*{Ratios}\label{ratios}}
\addcontentsline{toc}{subsubsection}{Ratios}

One straightforward measure of inequality is a comparison of ratios in the income distribution, for example:

\begin{itemize}
\tightlist
\item
  What is the ratio of income of the top 20 percent to the bottom 20 percent?
\item
  What is the ratio of income of the top 10 percent to the bottom 10 percent?
\end{itemize}

\hypertarget{the-wage-share}{%
\subsubsection*{The Wage share}\label{the-wage-share}}
\addcontentsline{toc}{subsubsection}{The Wage share}

We can also return to the National Accounts and compute a measure of inequality based on based on the Gross Domestic Product using the income approach. The Wage share is the share of GDP (or GNI) that goes to the compensation of workers. The wage share is also often used as a measure of inequality.

\hypertarget{further-readings-4}{%
\section{Further readings}\label{further-readings-4}}

\begin{itemize}
\item
  \href{https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/families/methodologies/theginicoefficient}{ONS on the GINI coefficient}
\item
  \href{https://data.oecd.org/inequality/income-inequality.htm}{OECD on Income inequality}
\item
  \href{http://www.oecd.org/social/inequality.htm}{OECD on Inequality}
\end{itemize}

\hypertarget{poverty}{%
\chapter{Poverty}\label{poverty}}

\hypertarget{what-this-chapter-is-about-3}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-3}}

In the last chapter we discussed how we could quantify the distribution of resources. This chapter is about quantifying the degree of poverty.

\hypertarget{intended-learning-outcomes-3}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-3}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  Describe the difference between relative and absolute poverty
\item
  Create data visualizations of poverty over time and across regions.
\end{itemize}

\hypertarget{measuring-global-development}{%
\section{Measuring global development}\label{measuring-global-development}}

Quantifying global development is a challenging task. First, it is challenging to obtain data covering the globe. Administrative data is only
available for a small number of selected countries, global censuses would be very expensive, and it is challenging to create representative surveys across the world (but it is done). Second, as we already discussed, even within one single country, there is a lot of work involved in measuring and standardizing concepts such as unemployment and GDP. Third, countries differ substantially in their institutional setting.

Despite these challenges, we have quite good indicators of the direction of global development. Let us consider the graphs from Our World In Data shown Figure \ref{fig:poverty4} (again). What data is required to create these charts? Poverty measures, education measures, literacy rates, democracy, vaccination data, and child mortality rates. None of these variables are easy to collect, and behind these simple illustrations of global development there is an enormous amount of work. To get an idea of the amount of work, you can go to the website of the source \href{https://www.ourworldindata.org}{ourworldindata.org}, and search for one of these indicators. You will find that all these Figures are based on an extensive set of sources.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_inequality/fig1} 

}

\caption{The world as 100 people. Source: Our World in Data. }\label{fig:poverty4}
\end{figure}

But measuring global development is not only challenging because it is difficult to obtain the important variables. It is also challenging, because it is difficult to decide \emph{which} variables we should focus on. Figure \ref{fig:poverty4} does, for example, not include any measures on crime, environment or corruption.

One approach to deciding which measures to include is to focus on variables that capture stated policy targets. At the United Nations Millennium Summit in 2000, all member states committed to the eight Millennium Development Goals (MDG). These eight goals were all linked to specific target dates. Should we just measure progress on these stated goals and follow global development? This is not ideal, as these goals are not linked to any analytical framework or economic principles. And even given these goals, it is unclear how to measure each goal. How would you for example measure ``Global Partnership for Development''? The MDG were replaced by the 17 Sustainable Development Goals (SDQ) in 2015 with a target of achieving these goals by 2030.

Compared to the MDG, the SDQ headlines are somewhat more general, but SDGs are linked to 169 specific targets with concrete indicators. For example behind the first goal, ``No Poverty'', there are four targets. You can read about all 169 indicators on the following website: \href{https://www.globalgoals.org}{globalgoals.org}.

\hypertarget{measuring-poverty}{%
\section{Measuring poverty}\label{measuring-poverty}}

Eradicating poverty was the first goal both in the MDG and SDG list. Global development in poverty is also the first statistic shown in Figure \ref{fig:poverty4}. This is no surprise: Poverty is a core measure of global development. And even though numbers have improved substantially, we still observe that 1 out of 10 people live in extreme poverty. This is much better than when I was born, where 4 out of 10 people lived in extreme poverty, or in the 1960ies when more than 6 out of 10 people lived in extreme poverty. But how do we define poverty?

The \emph{poverty line} is the core of defining poverty. People below this line are defined as being poor, people above this line are defined as non-poor. The line thereby represents a threshold, below which an ``acceptable'' life is not possible. One way to define this level is to quantify the food intake required for an adequate diet (say 2000-2500 calories per day for an adult), and calculate the costs of this intake. To this we would add the costs of shelter and clothing. People with a consumption below this level or an income below this level are then defined as being poor. The level will differ substantially from country to country. Moreover country differences in institutional settings also affect which other factors we would consider important. For example, is health care publicly provided or should that be included in minimum cost calculation?

Basing poverty levels on the minimum costs for an adequate food intake is actually not uncommon. The official poverty measure in the US is for example based on estimates from the 1960ies, based on the cost of a minimum food diet.\footnote{See also \url{https://poverty.ucdavis.edu/faq/what-current-poverty-rate-united-states} .}

An alternative to minimum costs of diet based measures is a relative poverty line, where we specify the poverty line relative to the income distribution in the country, for example by defining households with an income less than 60 percent of the median income as in poverty. Below we'll discuss some of the key issues in measuring poverty.

\hypertarget{income-or-consumption}{%
\subsubsection*{Income or consumption?}\label{income-or-consumption}}
\addcontentsline{toc}{subsubsection}{Income or consumption?}

We could define poverty both by what individuals and households consume and by their consumption possibilities, i.e.~their income. Observing actual consumption is much harder than observing income, which makes the latter approach much more attractive because it is based on a practical point of view. Moreover, if an individual had the option to consume a sufficiently healthy diet, but for some reason decided not to, should this person be defined as poor? Moreover, actual nutritional intake might not be monotonically increasing in expenditure. Some more expensive and enjoyable food might have a lower nutritive value. So in practice, poverty measures based on income are much more common than poverty measures based on consumption.

\hypertarget{relative-or-absolute-measures}{%
\subsubsection*{Relative or absolute measures?}\label{relative-or-absolute-measures}}
\addcontentsline{toc}{subsubsection}{Relative or absolute measures?}

Given the introduction above, an absolute level of income seems like a natural threshold for poverty. Below this line, a household cannot afford sufficient nutrients, cannot afford to buy clothing and cannot afford shelter. Such an absolute poverty line is based on what is ``required to survive''.

An alternative approach is to think of a poverty line reflecting the ability to participate in society. What is required to participate in the society will vary from country to country. In some countries owning a means of transportation might be crucial, in other countries access to the internet might be more important. Identifying the exact level of income necessary for participating in the society is very difficult. Instead, we can define the poverty threshold \emph{relative} to the median income in the economy.

It is important not to define poverty by the \emph{mean} of the income distribution, because this would imply that if an extremely rich person moves out of the country, the poverty rates would be reduced considerably. Finally, it is important to stress that relative poverty measures never can replace absolute measures completely. At some low level of median income the relative poverty line might be below the absolute poverty line and thereby not allow people to survive.

\hypertarget{poverty-definitions}{%
\section*{Poverty definitions}\label{poverty-definitions}}
\addcontentsline{toc}{section}{Poverty definitions}

\textbf{The OECD Definition}

The OECD defines people as being in poverty if their income is less than 50 percent of the median income.

\textbf{The EU Definition}

\begin{itemize}
\tightlist
\item
  The EU defines people as being in poverty if their income is less than 60 percent of the median income. The group of people below this threshold are defined as being ``at-risk-of-poverty''.
\end{itemize}

\textbf{Extreme Poverty}

\begin{itemize}
\tightlist
\item
  The concept of ``Extreme Poverty'' was introduced by the United Nations in mid 1990ies. This definition is an absolute measure of poverty, and refers to the minimum level of income that a person needs to survive. This poverty measure is known as the ``1 dollar a day'' measure. The 1 (US) dollar a day refers to the 1996 price level in the US. In terms of 2005 price levels the threshold is 1.25 USD a day. This is the measure used in the Figure
\end{itemize}

\textbf{UK poverty measures}

\begin{itemize}
\tightlist
\item
  Various poverty measures are in use and have been used in the UK. In the Child Poverty Act of 2010, an income of 60 percent of the median income is used. The Joseph Rowntree Foundation has defined a minimum income standard, which is ``based on what people think is required for an acceptable living''. In 2016 the minimum income standard threshold for a single person was 17,100 GBP (before taxes). For two adults with two children, the threshold was 37,600 GBP (total across the two parents).
\end{itemize}

\textbf{Other indicators}

\begin{itemize}
\item
  There are a wide range of poverty definitions and indicators in addition to those discussed above. Some of these indicators have very different approaches to measuring poverty. One alternative is the Multidimensional Poverty Index, which is based on ten indicators covering schooling (years of schooling and school attendance), child mortality, nutrition, electricity, sanitation, drinking water, the condition of the floor, cooking fuel, and assets.
\item
  For each person, a weighted average (measured in terms of percentages) across these indicators is constructed and added. The total index is then the product of the number of people who are poor and the intensity.
\end{itemize}

\hypertarget{challenges-with-poverty-line}{%
\subsection{Challenges with poverty line}\label{challenges-with-poverty-line}}

Poverty lines are very useful because they allow us to track progress, however, poverty lines can also be ``dangerous'', as they might lead policymakers to focus on people close to the line, while ignoring people far away from the line, because they will have a lower impact on the numbers. However, people further below the poverty line might need support more than those just below the poverty line.

\hypertarget{further-readings-5}{%
\section{Further readings}\label{further-readings-5}}

\emph{Poverty}

\begin{itemize}
\item
  \href{https://www.worldbank.org/en/topic/measuringpoverty}{The World Bank about Measuring Poverty}
\item
  \href{https://www.jrf.org.uk/mpse-2015/measuring-poverty}{JRF on Measuring Poverty}
\end{itemize}

\hypertarget{prices}{%
\chapter{Prices}\label{prices}}

\hypertarget{what-this-chapter-is-about-4}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-4}}

We've discussed how the Policy Interest Rate is set by the Bank of England. The Bank of England has one objective in mind when deciding on the interest rate, the inflation in the UK should be 2 percent. So if you had spent 100 GBP to buy a basket of goods last year, you should spend 102 GBP to buy the basket of goods this year, that gives you the same utility. If the price of the basket is now less than 101 or more than 103 the Bank of England is required to explain why. In other words, the Bank of England faces an inflation target of 2 percent, and deviations of more than one percentage point require a public explanation. Now this all sounds simple and straightforward. However, the question is what baskets of goods should we compare? Should the basket this year contain exactly the same goods as the basket last year, in the same quantity and quality? What if a new product arrives on the market? We will discuss these issues in this chapter along with the concept of the Purchasing Power Parity, which concerns the comparison of prices across countries.

\hypertarget{intended-learning-outcomes-4}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-4}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  Explain the difference between the Laspeyres and Paasche price indexes.
\item
  Explain how the consumer price index is constructed.
\item
  Explain what inflation is and how it is measured.
\item
  Explain what Purchasing Power Parity is, and how we can use it to compare prices across countries.
\end{itemize}

\hypertarget{price-indexes---in-theory}{%
\section{Price indexes - in theory}\label{price-indexes---in-theory}}

\hypertarget{the-objective}{%
\subsection*{The objective}\label{the-objective}}
\addcontentsline{toc}{subsection}{The objective}

Before we discuss how we measure changes in prices, let's briefly discuss what our objective is. There are many different price indexes, such as the consumer price index, the producer price index, the house price index and the GDP deflator. They all track the development of prices, but they focus on the prices of slightly different goods. The consumer price index, which is the index central banks typically use in the inflation target, measures the development of prices over time. We would like to know, as a consumer, how much more expensive (in nominal terms) it is it today compared to yesterday. But what comparison should we make? There are many goods and prices, and we need to combine their development into one overall number. We therefore compare the price of a basket of goods over time. And what determines the composition of this basket? A fair comparison would be to compare two baskets that give us the same utility. Unfortunately we do not observe people's utility, and it is therefore not possible to make this comparison in practice. The price indexes discussed in the next section are therefore concerned with how we in practice can create this basket of goods.

\hypertarget{a-simple-index}{%
\subsection*{A simple index}\label{a-simple-index}}
\addcontentsline{toc}{subsection}{A simple index}

Let us first consider the simple case of an index with one variable:

\begin{align}
    I_t=100\times \frac{P_t}{P_0}
    \label{eq1}
\end{align}

Where \(I_t\) is the index value of price \(P\) at time \(t\), using time \(t=0\) as the base year. Note that we also have:
\begin{align}
    I_{t-1}=100\times \frac{P_{t-1}}{P_0}
    \label{eq2}
\end{align}

which we can rewrite to:

\begin{align}
    Y_0=100\times \frac{P_{t-1}}{I_{t-1}}
    \label{eq3}
\end{align}

And then insert into equation \eqref{eq1}:

\begin{align}
    I_t&=100\times \frac{P_t}{100\times \frac{P_{t-1}}{I_{t-1}}}\nonumber\\
        \Rightarrow I_t&=I_{t-1}\times \frac{P_t}{ P_{t-1}}\nonumber\\
    \label{eq4}
\end{align}

Instead of computing the index based on the base year, we take the index value last period and multiply it by the change in our variable from last year to this year.

But what if we are interested in the price development across more than one good, but we still want to summarise the price development in one value. For example if \(P1\) is the price of coffee and \(P2\) is the price of tea. One approach would simply be to take the average across these two products:

\begin{align}
   I_t&=100\times \left(\frac{0.5\times P1_t+0.5\times P2_t}{0.5\times P1_0+0.5\times P2_0}\right)
    \label{eq5}
\end{align}

Let's apply this formula to an example: In the table below I've inserted some artificial prices for the seven years from 2001 to 2006 and the resulting price index. On average prices have increased by 53 percent over the period.

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:price2} Index based on the simple mean across two variables}\tabularnewline
\toprule
Year & P1 & P2 & I \\
\midrule
\endfirsthead
\toprule
Year & P1 & P2 & I \\
\midrule
\endhead
2001 & 136 & 100 & 100.0 \\
2002 & 186 & 110 & 125.4 \\
2003 & 197 & 120 & 134.3 \\
2004 & 204 & 125 & 139.4 \\
2005 & 215 & 132 & 147.0 \\
2006 & 222 & 140 & 153.4 \\
\bottomrule
\end{longtable}

But what if we drink much more coffee than tea (I am not British)? Let's say that for every ten cups I drink, nine of them are coffee and one of them is tea. Now this should also be reflected in our price index. The simple arithmetic mean is therefore not representative, instead we should use the weighted mean, where we assign a higher weight on P1 (for coffee) than on P2 (for tea).

\begin{align}
   I_t&=100\times \left(\frac{0.75\times P1_t+0.25\times P2_t}{0.75\times P1_0+0.25\times P2_0}\right)
    \label{eq6}
\end{align}

or expressed in more general terms:

\begin{align}
   I_t&=100\times \left(\frac{Q1 \times P1_t+Q2 \times P2_t}{Q1 \times P1_0+Q2 \times P2_0}\right)
    \label{eq7}
\end{align}

Where \(Q\) refers to the quantities or weights.

Table \ref{tab:price3} shows the weighted price index, along with the weights, \(Q\). The overall price of our hot drinks consumption now increased 62 percent from 2001 to 2006, this is slightly higher than the price index in Table \ref{tab:price2}, reflecting that the price of coffee has increased more than tea, and we consume relatively more coffee.

\begin{longtable}[]{@{}llllll@{}}
\caption{\label{tab:price3} Index based on a weighted mean across two variables. With \(I=0.9\times P1+0.1\times P2\).}\tabularnewline
\toprule
Year & P1 & P2 & Q1 & Q2 & I \\
\midrule
\endfirsthead
\toprule
Year & P1 & P2 & Q1 & Q2 & I \\
\midrule
\endhead
2001 & 136 & 100 & 90 & 10 & 100.0 \\
2002 & 186 & 110 & 90 & 10 & 134.7 \\
2003 & 197 & 120 & 90 & 10 & 143.0 \\
2004 & 204 & 125 & 90 & 10 & 148.1 \\
2005 & 215 & 132 & 90 & 10 & 156.1 \\
2006 & 222 & 140 & 90 & 10 & 161.5 \\
\bottomrule
\end{longtable}

Computing a price index has been quite straightforward so far. However, in the later years we started to drink relatively more tea, so the weights changed. This is where we introduce slightly more complex price indexes that correspond more to the real world setting.

\hypertarget{the-laspeyres-index}{%
\subsection{The Laspeyres Index}\label{the-laspeyres-index}}

The German economist Etienne Laspeyres is the father of the Laspeyere index. In terms of our two goods world, with only tea and coffee, Laspeyres's index is defined as:

\begin{align}
I_t^L&=100\times \left(\frac{Q1_0 \times P1_t+Q2_0 \times P2_t}{Q1_0 \times P1_0+Q2_0 \times P2_0}\right)
    \label{eq8}
\end{align}

What is new compared to the other equations \eqref{eq6} is that not only do the prices have time periods, but also the weights (the quantities), \(Q\). Using Laspeyres's index, the weights are kept constant at the initial period, 0. In other words, Laspeyres's index tells us how much the price of our consumption has increased, given the relative weights in the base year. In more general terms (with more goods), we can write Laspeyres's index as follows:

\begin{align}
   I_t^L&=100\times \left(\frac{\sum^I_{i=1} Qi_0 \times Pi_t}{\sum^I_{i=1}Qi_0 \times Pi_0}\right)
    \label{eq9}
\end{align}

Where \(i\) refers to the product. So in the case of the Laspeyres price index, our movement away from tea to coffee is ignored. If we wanted to adjust the weights, an alternative methodology is provided by Paasche.

\hypertarget{the-paasche-price-index}{%
\subsection{The Paasche Price Index}\label{the-paasche-price-index}}

As with the Laspeyres index, the Paasche index is attributable to a German economist, this time it is Hermann Paasche. The Paasche index is very much just the opposite of the Laspeyres index. We use the current weights, both in the denominator and numerator.

\begin{align}
   I_t^P&=100\times \left(\frac{\sum^I_{i=1} Qi_t \times Pi_t}{\sum^I_{i=1}Qi_t \times Pi_0}\right)
    \label{eq10}
\end{align}

Instead of always comparing the same basket we bought in the reference period, we refer to the basket, in the current period. Table \ref{tab:price4} shows the Laspeyres index (\(I^L\)) and the Paasche index (\(I^P\)) for our two good case, where the quantities or weights change from year to year. Unsurprisingly, the Laspeyres index corresponds to the weighted average in Table \ref{tab:price3}, because the weight in the base year corresponds to the constant weights in Table \ref{tab:price3}. The Paasche index is, however, slightly different. Now as we start consuming relatively more tea, the good that increases less in price receives more weight. The Laspeyres index ignores this, but the Paasche does not, and therefore the Paasche price index is lower than the Laspeyres index.

\begin{longtable}[]{@{}ccccccc@{}}
\caption{\label{tab:price4} The Laspeyres and Paasche Index. Notes: \(I^L\) refers to the Laspeyres price index and \(I^P\) refers to the Paasche price index.}\tabularnewline
\toprule
Year & P1 & P2 & Q1 & Q2 & \(I^L\) & \(I^P\) \\
\midrule
\endfirsthead
\toprule
Year & P1 & P2 & Q1 & Q2 & \(I^L\) & \(I^P\) \\
\midrule
\endhead
2001 & 136 & 100 & 90 & 10 & 100.0 & 100.0 \\
2002 & 186 & 110 & 85 & 15 & 134.7 & 133.7 \\
2003 & 197 & 120 & 80 & 20 & 143.0 & 141.0 \\
2004 & 204 & 125 & 75 & 25 & 148.1 & 145.1 \\
2005 & 215 & 132 & 70 & 30 & 156.1 & 151.8 \\
2006 & 222 & 140 & 65 & 35 & 161.5 & 156.6 \\
\bottomrule
\end{longtable}

Our example is actually in line with what we typically observe in the real world, the Laspeyres index gives a higher increase than the Paasche index. This is because consumers tend to substitute away from the good that increases relatively more in price. So when one good's price increases less than the other, and we therefore tend to consume more of the relatively cheaper good, the Paasche index takes this into account because weights are updated every year. The Laspeyres index on the other hand always refers to the base year weights. Which index to prefer is, however, not obvious. Often the choice of index will be based on practical reasons. While the Paasche index requires new weights every year, the Laspeyres index only requires the base year weights and the prices for all periods. The Paasche index is therefore slightly more data demanding.

\hypertarget{the-fisher-price-index}{%
\subsection{The Fisher Price Index}\label{the-fisher-price-index}}

The Fisher index, introduced by the American economist Irving Fisher, is a compromise between the Laspeyres index and the Paasche index. It is also called Fisher ideal index, and it is based on an average between the Laspeyres and Paasche index. The average is computed by means of a geometric mean:

\begin{align}
      I_t^F&=\sqrt{I^ L_t\times I^ P_t} 
    \label{eq11}
\end{align}

\hypertarget{the-lowe-price-index}{%
\subsection{The Lowe Price Index}\label{the-lowe-price-index}}

The Lowe price index is attributed to the Scottish economist Joseph Lowe. The Lowe index is a more general price index, where the reference period for the weights is not set.

\begin{align}
   I_t^{Lo}&=100\times \left(\frac{\sum^I_{i=1} Qi_r \times Pi_t}{\sum^I_{i=1}Qi_r \times Pi_0}\right)
    \label{eq12}
\end{align}

The Laspeyres price index is a special case of the Lowe price index, where \(r=0\), and the Paasche price index is a special case of the Lowe price index where \(r=t\). The Laspeyres and the Paasche indexes are therefore often called ``Lowe type price indexes''.

\hypertarget{other-indexes}{%
\subsection*{Other indexes}\label{other-indexes}}
\addcontentsline{toc}{subsection}{Other indexes}

There are many different price indexes, and the price indexes applied by statistical offices will often be modified versions of the standard formulas. One modification is chain-linking, which we will discuss in the next section. However, before we get there, it is worth mentioning a few more price indexes. The Finnish statistician Leo Trnqvist introduced an index (the Trnqvist index), where we instead of taking the mean between the Fisher and Paasche index, take the mean of the weights between the base year and the current year. However, the Trnqvist index also differs by using a weighted geometric mean instead of the weighted arithmetic mean.

Also, another index worth mentioning is the Carli index, introduced by the Italian economist Gian Carli:

\begin{align}
   I_t^{C}&=\frac{1}{N}\sum^I_{i=1}\left(\frac{Pi_t}{Pi_0}\right)
    \label{eq13}
\end{align}

Note that the Carli index is unweighted. It is therefore called elementary, and it is typically only used when we are focusing on specific product types.

\hypertarget{chain-linked-vs.-unchained-indexes}{%
\subsection*{Chain-linked vs.~unchained indexes}\label{chain-linked-vs.-unchained-indexes}}
\addcontentsline{toc}{subsection}{Chain-linked vs.~unchained indexes}

So far we've three solutions regarding product weights. One, we use the weights in the base year (Laspeyres); two, we use the weights in the current year (Paasche); three we use an average between the base year and the current year (Fisher/Tornqvist). An alternative strategy is to constantly update the base year of the weights. This is where the alternative specification in equation \eqref{eq4} becomes handy. Recall that we could write the price index in year \(t\) as the price index in year \(t-1\) times the change from year \(t-1\) to \(t\). In general terms, as a chain-linked Laspeyere index, this works as follows:

\begin{align}
   I_t^{CL}&=I_{t-1}\times  \left(\frac{\sum^I_{i=1} Qi_{t-1} \times Pi_t}{\sum^I_{i=1}Qi_{t-1} \times Pi_{t-1}}\right)
\end{align}

We call this methodology chained, because we link each year using a chain of updated weights. We thus use the standard Laspeyres index, but every year we update the base year as the last year. We can do a similar exercise with the Paasche index

\begin{align}
   I_t^{CP}&=I_{t-1}\times  \left(\frac{\sum^I_{i=1} Qi_{t} \times Pi_t}{\sum^I_{i=1}Qi_{t} \times Pi_{t-1}}\right)
\end{align}

\hypertarget{summary-on-price-indexes}{%
\subsection*{Summary on price indexes}\label{summary-on-price-indexes}}
\addcontentsline{toc}{subsection}{Summary on price indexes}

\emph{Objective}

\begin{itemize}
\tightlist
\item
  A method to compare the price development across a large bundle of goods.
\end{itemize}

\emph{Challenge}

\begin{itemize}
\tightlist
\item
  The composition of the bundle might change over time, and some goods might gain higher and lower weight, while other goods might be removed or added to the bundle.
\end{itemize}

\emph{Method}

\begin{itemize}
\tightlist
\item
  The Laspeyres index: Keep the bundle fixed in the base year and assess the price development based on the development of the costs of the initial bundle.
\item
  The Paasche index: Update the bundle every year, and compare the price of the new bundle given current prices and given prices in the base year.
\item
  The Fisher index: The geometric mean of the Laspeyres and the Paasche indexes.
\item
  Chain-linking: Continuously update the reference period.
\end{itemize}

\hypertarget{weigths}{%
\subsection*{Weigths}\label{weigths}}
\addcontentsline{toc}{subsection}{Weigths}

Before we turn to the actual price indexes, we will briefly discuss how these weights are computed, \(Q1\) and \(Q2\). These weights could be obtained from various sources. In practice, most countries compute the weights based on total household final expenditure from the national accounts.

However, some indexes use surveys to compute the weights. For the UK, the Living Costs and Food Survey is based on reported consumption over a two week period for thousands of households. This survey is used in some price indexes constructed by the ONS (for example the RPI). One advantage of using surveys to compute weights is that we have more information on the household, and we can thus rely on households that we believe are more representative.

\hypertarget{price-indexes---in-practice}{%
\section{Price indexes - in practice}\label{price-indexes---in-practice}}

There is not only one price index. We might for example be interested in how costs for firms have developed. The typical consumption basket for firms is very likely to be different from the typical basket for households.

\hypertarget{consumer-price-indexes}{%
\subsection*{Consumer Price Indexes}\label{consumer-price-indexes}}
\addcontentsline{toc}{subsection}{Consumer Price Indexes}

Let us first consider how the price level for consumers develops. The ONS publishes several consumer price indexes. Let us consider three of the most important ones:

\begin{itemize}
\tightlist
\item
  The Consumer Price Index (CPI)
\item
  The Consumer Prices Index including owner occupiers' housing costs (CPIH)
\item
  The Retail Prices Index (RPI)
\end{itemize}

The CPI is calculated in line with European regulations, but the RPI does not satisfy the international standard. The latter is therefore not regarded as a National Statistic of the ONS anymore, but it is still produced, because contracts still rely on the RPI. The main difference between the CPI and the CPIH is that the CPIH includes costs related to owning a home, such as maintenance (owner occupiers' housing costs). The CPI and CPIH include the same items, except for the housing costs. The RPI differs somewhat to the CPI and CPIH in terms of items included. While the weights in the CPI and CPIH are based on total household final expenditure from the national accounts, the weights in the RPI are based on the Living Costs and Food Survey. The CPI is based on about 180,000 prices that cover about 700 items.

The CPI and CPIH are chain-linked Laspeyres-type price indexes computed on a monthly basis. The RPI is (approximately) also a chain-linked Laspeyres type index, but based on annual data.

Looking beyond the UK, the harmonised index of consumer prices (HICP), is the consumer price index by the European Union/ Eurostat, which is also a chain-linked Laspeyres-type price index. Both the CPI and CPIH use weights that are typically updated annually. For more details on the consumer price indexes, see \citep{cpions} for the ONS and \citep{cpieu} for the European level.

There are various data sources for price indexes. Figure \ref{fig:pricefig1} uses data from Eurostat to show the development in the price index for the UK and for the EURO area as a whole. Note that the index is based on 2015 as a reference year. This is slightly unusual, as we often prefer to have the first period as a reference.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{./resources/chapter_prices/ex1_1} 

}

\caption{The Consumer Price Index (HICP) for the EURO countries and the UK. Source: Eurostat. Notes: The index is constructed such that the 2015 average is 100.}\label{fig:pricefig1}
\end{figure}

\hypertarget{producer-price-index-import-price-index-and-export-price-index}{%
\subsection*{Producer Price Index, Import Price Index and Export Price Index}\label{producer-price-index-import-price-index-and-export-price-index}}
\addcontentsline{toc}{subsection}{Producer Price Index, Import Price Index and Export Price Index}

Firms typically have different weights than consumers. We typically distinguish between three indexes, the Producer Price Index (PPI), the Import Price Index (IPI) and Export Price Index (EPI). These indexes are all chain-linked Laspeyres-type price indexex, where weights are updated regularly, but typically less frequent than for consumer price indexes. The weights are constructed using sales data from different sources. For more details see \citep{ppions} for the ONS and \citep{ppieu} for the European level.

\hypertarget{other-indexes-1}{%
\subsection*{Other indexes}\label{other-indexes-1}}
\addcontentsline{toc}{subsection}{Other indexes}

A couple of additional indexes also deserve mentioning. First, the GDP deflator. The GDP deflator is considerably broader than the other price indexes, as it covers the complete domestic economy. The National Accounts typically also use a chain-linked Laspeyres type approach to be able to make monetary levels comparable across periods. For more details see \citep{gdpons}. Second, the House Price Index (HPI), again a chain-linked Laspeyres type index, with annual updating of weights. This index covers housing bought by households, such as flats, detached houses and terraced houses. Third, the Index of Private Housing Rental Prices (IPHRP) captures the development in the price tenants face when renting residential housing.

\hypertarget{across-time}{%
\section{Across time}\label{across-time}}

\hypertarget{inflation}{%
\subsection*{Inflation}\label{inflation}}
\addcontentsline{toc}{subsection}{Inflation}

As there are many price indexes, there are also many inflation measures. The Bank of England's inflation target relates to the Consumer Price Index inflation. The ONS publishes both annual and monthly rates, where annual rates relate to the change in prices over a 12 month period, and monthly to a month to month change. As inflation shows the change in price levels, inflation is the first derivative of the price index. In Figure \ref{fig:pricefig2} we show the year-to-year change in price levels based on the price indexes shown in Figure \ref{fig:pricefig1}.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{./resources/chapter_prices/ex1_2} 

}

\caption{Consumer Price Inflation for the EURO countries and the UK. {Source: Eurostat. Notes: The inflation relates to 12 month changes.}}\label{fig:pricefig2}
\end{figure}

Note that the UK inflation is currently considerably higher than the inflation in the EURO area.

\hypertarget{real-vs.-nominal-values}{%
\subsection*{Real vs.~nominal values}\label{real-vs.-nominal-values}}
\addcontentsline{toc}{subsection}{Real vs.~nominal values}

Price indexes are not only used to compute inflation measures. More than 100 years ago, in 1905, the English footballer Alf Common moved from Sunderland to Middlesbrough for a record fee of 1,000 GBP. In terms of today's transfer fees, this sounds unrealistic. But based on the amount you could purchase with 1,000 GBP in 1905, this corresponds to about 114,367 GBP in 2017, which is still low, but seems more reasonable. To make this adjustment, we use price indexes.

Using price indexes we can compare the fee of Alf Common to the fee of for example Kevin Keegan in 1977, when he moved from Liverpool to Hamburg for a fee of 500,000 GBP. The 500,000 GBP in 1977 corresponds to about 2,922,031 GBP in 2017. We can thus refer to the 1,000 GBP and 500,000 GBP as transfer fees in \emph{nominal} terms and the 114,367 GBP and 2,922,031 GBP as \emph{real} terms in the 2017 price level.

\begin{itemize}
\item
  Nominal values are monetary values that are expressed in current prices. For example your monthly income is measured in the price level used today or the transfer fee in 1905 is measured in the price level of that time.
\item
  Real values are monetary values, where we adjust for changes in price levels. To figure out whether you earn more today than 10 years ago, it is not sufficient just to compare the nominal earnings today and ten years ago, as the price level has changed. As goods and services have become more expensive, the same earnings as 10 years ago, in nominal terms, would enable you to buy less today than ten years ago. Adjusting the earnings to the same price level using inflation or price indexes is necessary to understand whether we are facing a real increase.
\end{itemize}

To convert the nominal values to real values (say the value in the base year) we multiply the nominal values by the change in the price index:

\begin{align}
    P_{BASE}=P_t\times \frac{CPI_{BASE} }{CPI_t}
\end{align}

\hypertarget{the-real-interest-rate}{%
\subsection{The real interest rate}\label{the-real-interest-rate}}

An annual interest rate of 2 percent means that if I place 100 GBP in that investment, I will receive 102 GBP in one year. But what if the price index also increases from 100 to 102? In real terms I am not richer in a year than I am now, because the same bundle of goods that I am able to buy for 100 GBP today, costs 102 GBP in one year. If we want to know whether we will actually get richer from an investment, we should consider the \emph{real interest rate}. Now let us consider how much richer we are in a year. We want to know the real interest rate \(r\), and we know the nominal interest rate \(i\) and the inflation rate \(\pi\) (it is fairly standard to use these letters for interest rates and inflation). We can thus write

\begin{align}
    1+r= \frac{(1+i)}{(1+\pi)}
\end{align}

which we can rewrite as:

\begin{align}
    1+\pi+r+r\times \pi&= 1+i\nonumber\\
 \Rightarrow    r&= i-\pi-r\times \pi
\end{align}

As inflation and the interest rates typically are fairly small, the term ``\(r\times \pi\)'' will be close to zero. We can therefore compute the approximate real interest rate as:

\begin{align}
    r\approx i-\pi
\end{align}

which is also known as the \emph{Fisher equation}. When inflation exceeds the real interest rate, we face a negative real interest rate.

\hypertarget{the-phillips-curve}{%
\subsection*{The Phillips Curve}\label{the-phillips-curve}}
\addcontentsline{toc}{subsection}{The Phillips Curve}

The Phillips curve was introduced by William Phillips an economist from New Zealand. He studied the relationship between inflation and unemployment, a relationship that is visualized in the Phillips Curve. The original Phillips is a scatter plot of wage inflation and unemployment in the UK. The curve showed that periods with low unemployment rates also tended to be periods with high inflation rates, and periods with high unemployment rates also tend to be periods with low inflation. The (short-run) intuition behind this relationship is that when employment is high, the pressure on wages is high, and wage inflation is high. For details on the Phillips curve, see \citep[p.~646 in][]{core} .

In 2008 Gregor \citep{smith2008japan} published a paper, where he showed how the Phillips of Japan looks like Japan. His plot is shown in Figure \ref{fig:pricejapan}, along with a picture from Google maps, of Japan. What do you think? Is this advanced chartjunk?

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./resources/chapter_prices/japan4} \includegraphics[width=0.5\linewidth]{./resources/chapter_prices/japan3} 

}

\caption{The Phillips curve of Japan and a map of Japan. Source: The Map is from Google Maps, the Phillips curve is from citet{smith2008japan}. The unemployment rate is multiplied by minus 1. }\label{fig:pricejapan}
\end{figure}

\hypertarget{across-regions}{%
\section{Across regions}\label{across-regions}}

\hypertarget{the-big-mac-index}{%
\subsection*{The Big Mac index}\label{the-big-mac-index}}
\addcontentsline{toc}{subsection}{The Big Mac index}

Considering price levels is not only important when we compare changes over time, but also across countries. Imagine that you would like to compare the earnings of a typical worker in Ukraine to the earnings of a typical worker in Switzerland. But prices in Ukraine are very different to prices in Switzerland, and just comparing the earnings using the exchange rates would not reflect the differences in living standards. One illustration of the difference is the Big Mac Index, which has been published by the Economist since 1986. According to the 2017 version of the index, a Big Mac costs around 6.35 USD in Switzerland and 1.54 USD in Ukraine. The price level, as approximated with the Big Mac Index is therefore about four times higher in Switzerland compared to Ukraine. If the Big Mac price level is reflective of the overall costs, it would suggest that to obtain the same living standards in Switzerland as in Ukraine, you need about four times the income in Switzerland compared to Ukraine.

Several indexes have been produced to mimic the idea of the Big Mac Index (the IPod index, the Starbucks Latte index, etc.). However, these indexes have some obvious short-comings. The product is not the same across countries and the product is not representative of the overall costs.

\hypertarget{purchasing-power-parity}{%
\subsection*{Purchasing Power Parity}\label{purchasing-power-parity}}
\addcontentsline{toc}{subsection}{Purchasing Power Parity}

While the Big Mac Index provides a very simple approach to comparing prices. A more rigorous way to compare nominal values across countries is by means of purchasing power parity (PPP). As a point of departure, let us consider the price of a Big Mac. In Switzerland the price is approximately 6.50 CHF and in the US the price is approximately 5.06 USD. This would suggest an exchange rate between the US and Switzerland of:

\begin{align}
    PPP_{BigMac,SUIUS}=\frac{6.50}{5.06}=1.28
\end{align}

now, according to the law of one price, we would expect the price of a big mac to be the same in the US and in Switzerland, so the difference must be the exchange rate. Having 5.06 USD must thus be the same as having 6.5 Swiss Francs, or having 1 USD must correspond to 1.28 Swiss Franc. However, at the time of the Big Mac price difference (January 2017), the USD to the CHF exchange rate was 1.01. According to the Big Mac index, the Swiss Franc was overvalued by about 30 percent compared to the USD. So to make the monetary values comparable across Switzerland and the US we multiply all US values by 1.28 instead of the actual exchange rate. We say that the purchasing power parity is 1.28 CHF to 1 USD.

Just like a basket of goods is used to compare prices across time, a representative basket of goods is used to compare prices across countries. The OECD and Eurostat cooperate in the measuring the PPP. Details on how to compute the PPP can be found in \citep{ppp}. We use PPP to compare GDP (and especially GDP per capita) across countries.

\hypertarget{further-readings-6}{%
\section{Further readings}\label{further-readings-6}}

In this chapter we've covered the following topics:

\begin{itemize}
\item
  \href{https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Paasche_price_index}{Eurostat on the Paasche price indexes}
\item
  \href{https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Laspeyres_price_index}{Eurostat on Laspeyres price indexes}
\item
  \href{https://www.ons.gov.uk/economy/inflationandpriceindices/articles/consumerpriceindicesabriefguide/2016}{Office for National Statistics about prices}
\end{itemize}

\hypertarget{money}{%
\chapter{Money}\label{money}}

\hypertarget{what-this-chapter-is-about-5}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-5}}

If you ask a bank to lend you money, they will probably charge you an interest rate. The interest rate is the price of money. This chapter is about the different types of interest rates, and the price of money in other currencies, the exchange rates.

\hypertarget{intended-learning-outcomes-5}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-5}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter

\begin{itemize}
\tightlist
\item
  Distinguish between the policy interest rate, the interbank rate, and the bank lending rate.
\item
  To express the price of currencies in terms of exchange rates and describe movements in exchange rates.
\end{itemize}

\hypertarget{interest-rates}{%
\section{Interest rates}\label{interest-rates}}

\hypertarget{the-basics-what-is-the-interest-rate}{%
\subsection*{The basics: What is the interest rate?}\label{the-basics-what-is-the-interest-rate}}
\addcontentsline{toc}{subsection}{The basics: What is the interest rate?}

If you ask a friend whether you can borrow 2 GBP today, it is likely, that you have repaid your debt once you've repaid these 2 GBP. However, if you ask your bank whether you can borrow 10,000 GBP, it is likely that they will require you to repay more than 10,000 GBP. If the bank asks you to repay 10,500 GBP, the bank charged you an interest of 5 percent rate. Or in other words, the interest rate, \(i\), on your bank loan is 5 percent:

\begin{align}
    i=\frac{\text{amount to repay}}{\text{amount borrowed}}-1=\frac{10,500}{10,000}-1=0.05
\end{align}

Why did you have to pay more to the bank than you borrowed? To be able to lend 10,000 GBP to you, the bank has to get 10,000 GBP from somewhere. Banks borrow and lend money on the \emph{money market} where they also pay an interest rate for lending money. Alternatively the bank could lend the money from another customer, but this other customer would expect to get something in return, an interest.

Why would the other customer expect an interest? The short answer: Money \emph{today} is costly. Would I rather have 100 GBP today or 100 GBP in two years? If you take 100 GBP today you could just keep the money in a safe place for two years. So money today should be at least as much worth today as in two years (everything else equal). Moreover over two years things might get more expensive. The amount of goods you can buy today for 100 GBP is probably larger than the amount of goods you can buy in two years because of the inflation. Moreover, you could also keep the 100 GBP today and invest them in stocks or bonds, and you might have more than 100 GBP in two years. So in sum, money today is typically more worth than money at a later point in time, and you have to pay a price for that, the interest rate.

Why are interest rates important in economics? Imagine that you have a business idea, and that you need some funding, say 10,000 GBP. You go to your bank and ask for 10,000 GBP today. They might answer, sure just promise to give us 10,050 GBP in ten years. That is an interest rate of 0.5 percent (\(=100*((10,500/10,000)-1)\)). Not a bad deal, and you might be inclined to accept it and start your own business. But imagine that the bank says, sure, just promise to give us 20,000 GBP in ten years. That is an interest rate of 100 percent (\(=100*((20,000/10,000)-1)\)). Unless you have no other (cheaper) options to borrow money and you are very certain of your business idea, you will probably reject this offer and not initiate your business idea. So the interest rate can affect the activity of the economy. A low interest rate means that it is cheap to borrow money. You can borrow money to start a new business, buy a new car, or renovate your house. Buying new cars affects the automobile industry and renovating the house might affect jobs for carpenters and bricklayers.

But a low interest rate might also discourage savings, because when interest rates are low, the return on saving money is low. If banks are offering loans for 0.5 percent they probably paid less than 0.5 percent to borrow the money themselves, so saving money is also less attractive. But what determines the interest rates? Chapter 10 in \citep{core} provides a nice introduction to the money and credit market. We will provide a brief and very simplified description of the different interest rates in the next section.

\hypertarget{three-interest-rates}{%
\subsection*{Three interest rates}\label{three-interest-rates}}
\addcontentsline{toc}{subsection}{Three interest rates}

Let us consider an extremely simplified version of the money market:

\begin{itemize}
\tightlist
\item
  The central bank controls the money supply and sets the interest rate. The interest rate set by the central bank is called the \emph{policy interest rate} or the base rate. Commercial banks can borrow money at these rates.
\item
  Commercial banks can also borrow and lend money to each other on the interbank lending market at the \emph{interbank rate}.
\item
  Commercial banks lend money to households and firms at the \emph{bank lending rate}.
\end{itemize}

So what happens when you ask your bank for a loan?

\begin{itemize}
\tightlist
\item
  If your bank has sufficient funds it will just provide you with a loan at their bank lending rate.
\item
  If the bank does not have sufficient funds it will try to borrow money on the money market, either from the central bank or from other banks.
\end{itemize}

You will most likely pay a higher interest rate than the bank is paying the central bank or other banks. Even though the interest rate you pay for a bank loan is not the same as the interest rate your bank pays on the interbank market, there is a relationship between these rates. When central banks lower the policy interest rates, it becomes cheaper for banks to borrow money and they can offer you a loan at a lower price. Given that there is competition in the commercial bank market, it is likely that they will lower the interest they charge you, if their costs are reduced. Figure \ref{fig:money1} shows a line chart of the policy interest rate and the commercial bank lending rate for the UK.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_money/ex4_2} 

}

\caption{Policy interest rates and bank interest rates for the UK. Source: Bank of England. Series: IUMABEDR and IUMTLMV.}\label{fig:money1}
\end{figure}

You clearly see in Figure \ref{fig:money1} that the policy interest rate by the Bank of England and the average interest rate charged by commercial banks (the bank lending rage) follow each other. When the price of money falls, ie. the policy interest rate falls, the price banks charge on mortgages also falls. However, note that after the financial crisis, the gap between these two interest rates increased. Figure \ref{fig:money2} shows the gap (in percentage points) over the same time period. After the financial crisis the gap increased from approximately two percentage points to four percentage points. Why do you think this is the case?

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_money/ex4_3} 

}

\caption{The Gap between the policy interest rate and bank interest rate for the UK. Source: Bank of England. Series: IUMABEDR and IUMTLMV.}\label{fig:money2}
\end{figure}

However, there is not only one commercial bank lending rate, there are many. The interest rate the bank charges you, not only depends on their direct costs, but also on the risk they are facing. Mortgages are secured in the property, such that if the loan is not repaid, the money lender can use the property as compensation, for example by selling the property. This means that mortgages have a relatively high degree of security for the lender. However, some loans have almost no security, for example overdraft loans or credit card loans.
Figure \ref{fig:money3} shows the average overdraft interest rate for the same period. There is no clear relationship between the interest rate on overdrafts and the interest rate and the policy interest rate. Why do you think this is the case?

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_money/ex4_1} 

}

\caption{The policy interest rate, the  bank interest rate (mortgages) for the UK and the overdraft interest rates. Source: Bank of England. Series: IUMABEDR, IUMODTL and IUMTLMV..}\label{fig:money3}
\end{figure}

In addition to risk, the timespan of the repayment also affects the interest rate. If you would like to repay your loan over a longer period, the bank is likely to charge a higher price. Some bank loans have a fixed interest rate and some have a flexible interest rate. With a fixed interest rate, you know exactly what price you are paying throughout the repayment period. With a flexible interest rate, the costs of the loan might change. Finally it is important to consider how frequently the interest rate is accumulated. On many overdraft loans, the interest is calculated on a daily basis. Interest rates usually refer to annual rates.

\hypertarget{summary-interest-rates}{%
\subsection{Summary: Interest rates}\label{summary-interest-rates}}

\emph{Definition}
* The price of money.
* The relative difference between what you pay compared to what you borrowed.

\emph{Interest rates}
* The Policy interest rate: Set by the central bank, also known as the base rate, or for the UK: BOEBR (Bank of England base rate).
* Interbank interest rate: The rate banks charge each other for loans. In the UK: LIBOR (London Inter-bank Offered Rate)
* Commercial bank lending rates.

\emph{Factors affecting the interest rate}

\begin{itemize}
\tightlist
\item
  The cost of obtaining money (i.e.~the base rate and the interbank interest rate).
\item
  The risk of the loan.
\item
  The time span of the loan.
\item
  Whether the interest rate is fixed or flexible.
\end{itemize}

\hypertarget{exchange-rates}{%
\section{Exchange rates}\label{exchange-rates}}

\hypertarget{definition-of-exchange-rates}{%
\subsection*{Definition of exchange rates}\label{definition-of-exchange-rates}}
\addcontentsline{toc}{subsection}{Definition of exchange rates}

Exchange rates describe the value of one currency relative to another currency. Specifically it says how many units of one currency we can buy from one unit of another currency. This causes a lot of confusion, because the ordering of the units gets mixed up. Importantly the currency that comes after the ``to the'' is always the currency that you consider one unit of. One way to remember this is to always add a ``buy one unit of'' between the ``to'' and the ``the'':

\begin{center}
    "An exchange rate of \emph{Y} \emph{currency a} to (buy one unit of) the \emph{currency b}."
\end{center}

An example:

\begin{center}
    An exchange rate of 1.39 US Dollar to  the British Pound.\vspace{12pt}\\
    means:\vspace{12pt}\\
    An exchange rate of 1.39 US Dollar to \emph{buy one unit of} the British Pound.\\
\end{center}

As with interest rates, there are several exchange rates. The exchange rate is determined by the foreign exchange market (FOREX). It is mostly large banks and financial institutions that buy and sell on FOREX. When we individuals buy or sell foreign currencies, we typically just go to our local bank or to businesses that specialize in exchanging currencies. We rarely pay the same exchange rate as on the FOREX, because we also pay a commission to the local bank or currency exchanger.

\hypertarget{ups-and-downs-appreciation-and-depreciation}{%
\subsection*{Ups and downs: appreciation and depreciation}\label{ups-and-downs-appreciation-and-depreciation}}
\addcontentsline{toc}{subsection}{Ups and downs: appreciation and depreciation}

When exchange rates go up or down we use the terms appreciation and depreciation. When a currency depreciates it loses value compared to the foreign currency. When a currency appreciates it gains value. Figure \ref{fig:money4} shows the price of 1 USD in EURO increased substantially at the beginning of 2015. In other words 1 EURO became less worth compared to the USD, so it depreciated. Vice versa in 2017, where the price of a USD in EURO went down, so that the EURO appreciated.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_money/ex5} 

}

\caption{Exchange rates: EURO, CHF, GBP to USD. Source: The IMF.}\label{fig:money4}
\end{figure}

\hypertarget{summary-exchange-ratess}{%
\subsection*{Summary: Exchange ratess}\label{summary-exchange-ratess}}
\addcontentsline{toc}{subsection}{Summary: Exchange ratess}

\emph{Definition}
* The value of one currency relative to another currency: \textbf{An exchange rate of Y currency a to (buy one unit of) the currency b}

\emph{Ups and downs}

\begin{itemize}
\tightlist
\item
  Appreciation: A currency's value increases relative to the foreign currency.
\item
  Depreciation: A currency's value decreases relative to the foreign currency.
\end{itemize}

\emph{Interbank and commercial exchange rates}
* Commercial exchange rates: The exchange rate you pay in the bank or the supermarket.
* Interbank exchange rate: The exchange rate your bank pay on the interbank market.

\hypertarget{linking-interest-rates-and-exchange-rates}{%
\section{Linking interest rates and exchange rates}\label{linking-interest-rates-and-exchange-rates}}

So we've talked about interest rates and exchange rates. Is there a link between these rates? We know that the interest rates are affected by national banks, that set national policy interest rates. But what determines the exchange rates? If a currency is free-floating, the exchange rate is determined on the market by supply and demand. If more people want to hold GBP, the price will increase.

Who invests in currencies? Mostly international investors. And these investors like high returns, so they want to hold assets that pay high returns. When the policy interest rate is lowered, the interest rate on the country's financial assets such as bonds goes down, making them less attractive. This will lower the demand for assets. And thus also for the currency, and ultimately, the asset will depreciate.

You can read much more about the link between exchange rates and interest rates in \citep[chapter 15 in][]{core}.

\hypertarget{further-readings-7}{%
\section{Further readings}\label{further-readings-7}}

\begin{itemize}
\tightlist
\item
  \href{https://www.bankofengland.co.uk/knowledgebank/what-are-interest-rates}{Bank of England on Interest rates}
\item
  \href{https://www.bankofengland.co.uk/knowledgebank/who-sets-exchange-rates}{Bank of England: Who sets Exchange Rates?}
\end{itemize}

\hypertarget{part-ii-data-sources-and-tools}{%
\chapter*{Part II: Data sources and tools}\label{part-ii-data-sources-and-tools}}
\addcontentsline{toc}{chapter}{Part II: Data sources and tools}

\hypertarget{where-data-comes-from}{%
\chapter{Where data comes from}\label{where-data-comes-from}}

\hypertarget{what-this-chapter-is-about-6}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-6}}

Data comes from somewhere. The data visualization author should know where the data comes from. The reader should know where the data comes from. Knowing the origin of the data allows us to replicate the visualization, modify the visualization and combine the data with other data. Knowing the origin also tells us something about whether we can trust the data: Does the data really represent what the visualization assumes it represents? Or is there a potential bias? How certain can we be?

In practice, the origin of the data has two levels. Firstly, where did we get the data from? Is that from the website of the Office for National Statistics or from the website of Eurostat, the statistical agency of the European Union? Secondly, where did the Office for National Statistics or Eurostat get the data from?

As the author of data visualizations it is not only our job to know where the data comes from, but it is also our job to clearly communicate to the reader where the data comes from. We typically only communicate where we got the data from. For example by writing ``Data source: Bank of England.
Series: IUMABEDR.'' The reader can then visit the website of the Bank of England to investigate how the data behind the series ``IUMABEDR'' was collected.

\hypertarget{intended-learning-outcomes-6}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-6}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  explain the different types of data sources: register, sample survey, census survey.
\item
  use publicly available data sources.
\end{itemize}

\hypertarget{data-source-types}{%
\section{Data source types}\label{data-source-types}}

\hypertarget{overview}{%
\subsection*{Overview}\label{overview}}
\addcontentsline{toc}{subsection}{Overview}

We distinguish between the following four ways to obtain data.

\begin{itemize}
\tightlist
\item
  \textbf{Simulated data}: Data that is generated based on a predefined data generating process using computer software or similar approaches.
\item
  \textbf{Survey data}: Information that is collected from a subsample of a population, often by means of questionnaires or interviews.
\item
  \textbf{Census data}: A systematic collection of information from the full population.
\item
  \textbf{Register and automatically generated data}: Data that is collected for administrative purposes or as a byproduct of other activity.
\end{itemize}

\hypertarget{simulated-data}{%
\subsection*{Simulated data}\label{simulated-data}}
\addcontentsline{toc}{subsection}{Simulated data}

While many economists never touch simulated data (for good reasons) it is important to emphasize that simulated data can be extremely useful. Economists often set up theoretical models and then use computers to simulate how data would look, if the theoretical model was true. Simulations also play a very important role in many quantitative methods. We will also conduct our own simulations later in this unit.

Simulated data are unfortunately also sometimes used in practice for dishonest purposes. A recent example is an academic study ``When contact changes minds: An experiment on transmission of support for gay equality'' \citep{lacour2014contact} published in the journal Science in December 2014. The study concluded that both straight and gay messengers had an immediate effect on opinions about same-sex marriage, but only gay messengers caused a lasting effect on the opinions. However, further investigations showed that the underlying data were made up and the study was retracted \citep{lacour} . Such cases are (to our knowledge) fortunately quite rare. When working with data it is important to be critical about where data comes from, and -- if possible -- to assess the raw data.

How do simulations work? We could ask a friend to give us some numbers. But that would not be a very good strategy. Maybe the friend really likes 6 and subconsciously gives us more 6s than all other numbers. That would not be useful. But the idea that each number is equally likely is also just an assumption. Maybe that is not what we want. When we simulate data, we typically first specify what \emph{distribution} each individual observation is drawn from. If each value is equally likely, the underlying assumption is \emph{uniform}. It is difficult for our friend to be loyal to the uniform distribution because she favours 6. We therefore ask the computer instead. Figure \ref{fig:source0} shows how we can ask Excel to simulate data from a uniform distribution. In that case Excel draws an integer between 0 and 10. Each number 1, 2, 3 \ldots{} 10 is as likely to appear. In practice I would never ask Excel to simulate data. This data is of course not useful to tell anything about unemployment rates.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./resources/chapter_sources/simulate} 

}

\caption{Simulating data in Excel.}\label{fig:source0}
\end{figure}

\hypertarget{sample-surveys}{%
\subsection*{Sample surveys}\label{sample-surveys}}
\addcontentsline{toc}{subsection}{Sample surveys}

The term ``survey'' comes from looking/examining/supervising (like surveillance). We typically mean a sample survey when we say survey, because we only include a ``sample'' (or subset) of the population. In a survey, a subset of the population (individuals, firms, institutions) are asked (or observed) questions about opinions (i.e.~towards a specific policy) or facts (gender, age, etc.).

While the design of surveys can almost be considered an academic discipline in itself, for this now it is sufficient to think of the following two aspects:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  who is asked and who responded?
\item
  how are questions asked or observed?
\end{enumerate}

When conducting surveys we are typically interested in inferring aspects for the full population, and we would therefore like the sample to represent the full population, or in other words to be \emph{representative}. We would therefore sample a representative subsample of the population. However, we typically cannot force subjects to respond. Even though we asked a representative sample, the set of subjects that responded to the questions might not constitute a representative subset. There are a number of approaches to tackle the issue of non-representative data, but it is not always perfectly solvable.

Responses to questions often depend on how questions are asked and in what order. Is it an open ended question like ``What do you think about x?'', or is restricted to a specific scale: ``On a scale from 1 (very good) to 5 (very bad) what do you think about x?'' Is the question asked after some information about x is revealed? Is the question leading to a specific answer?

Survey data can be collected in many ways. For example through written questionnaires, telephone interviews or online internet surveys. Figure \ref{fig:source1} shows an example of a sample survey where data is connected online using Google Forms.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./resources/chapter_sources/fig_survey} 

}

\caption{An example of a sample survey using an online questionnaire}\label{fig:source1}
\end{figure}

\hypertarget{census-survey}{%
\subsection*{Census survey}\label{census-survey}}
\addcontentsline{toc}{subsection}{Census survey}

A census survey looks a lot like a survey, but instead of asking a subset of the population, we systematically ask everyone in the population. We often just call a ``census survey'' a ``census''. The UK Office for National Statistics carries out a Census every tenth year. The first census in the UK was held in 1801 and the last one took place on 21st March, 2021. Every household in the UK receives a questionnaire that asks a number of questions about the household.

The use of censuses is quite old. According to the UK office for National Statistics, it dates back to the Babylonians in 4000 BC. They used the data collected to calculate the food needed to feed the population, to measure the size of the labor force and so on.

Figure \ref{fig:source2} shows an example of a Census survey schedule from the United States in 1870. The schedule asks about household members' names, occupation, age, gender, education and more.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_sources/fig_census} 

}

\caption{An example of a household census. The 1870 US Census Schedule. Source: US Census}\label{fig:source2}
\end{figure}

Censuses are not used in all countries today. One reason for this is that some countries have register data that enables them to obtain the same information. Register data is typically cheaper, more frequent and in some cases more precise than census data.

\hypertarget{register-data}{%
\subsection*{Register data}\label{register-data}}
\addcontentsline{toc}{subsection}{Register data}

As mentioned, not all data is collected directly for the purpose. Some data is just created by a system. When a country's inhabitants submit their annual tax statements (often third-party reported by employers), the tax authorities use these values to infer whether the individual paid too much or too little in taxes. These tax statements might potentially be used for research and in national statistics.

While register data is popular due to its precision (i.e.~not self-reported values and based on human memory), it is important to remember that register data might be biased. To take the example of income, tax evasion will lead to income not included in these statistics, and tax evasion might not be randomly distributed across the population.

Register data in a wider sense also includes a lot of data that is called ``big data''. Data is collected automatically through systems. An example is Google Trends, where search terms are saved in the system. We can then use all the saved search terms to obtain data on individuals' search behavior.

\hypertarget{comparison-of-data-sources}{%
\subsection*{Comparison of data sources}\label{comparison-of-data-sources}}
\addcontentsline{toc}{subsection}{Comparison of data sources}

The list below provides a brief comparison of data source types. Simulated data contain no actual information on a subject. We cannot use simulated data to show the unemployment rate in the UK today. But simulated data is very cheap and with simulated data we know exactly how it was created.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Simulated data}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \emph{advantage}: quick and cheap
\item
  \emph{disadvantage}: based on theory \& does not represent an empirical fact.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Sample survey}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \emph{advantage}: we can measure what we need.
\item
  \emph{disadvantage}: slow, potentially expensive, and risk of bias and unrepresentative respondents.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Census survey}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \emph{advantage}: we can measure what we need.
\item
  \emph{disadvantage}: very slow \& expensive.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Register}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \emph{advantage}: precise, covers actual behavior
\item
  \emph{disadvantage}: only what is registered or generated automatically.
\end{itemize}

Survey data can be very cheap (it can also be very expensive, depending on how large it is). another advantage of survey data is that we can decide on the variables (what to ask) and observations (who to ask). A disadvantage of survey data is that not everyone answers (the data might not represent the population we asked) and answers may not represent the truth (due to biased human memory, dishonesty or social desirability bias).

Census data shares many of the advantages and disadvantages of survey data, but it typically includes everyone (it is mandatory to answer). Because we ask everyone it is very expensive.

Data from systems are typically very cheap, because we do not need to explicitly collect them, but we can simply ask the system to give us the data. We are therefore also limited to variables and observations that are covered by the system. If there are incentives linked to the system, the variables might also be biased. This could for example be a tax record on incomes. There is an incentive not to report all income in order to pay less in taxes, but this means that the income variable from the tax system doesn't match the true income (this is of course not legal, but it may happen anyway).

\hypertarget{economic-data-sources}{%
\section{Economic data sources}\label{economic-data-sources}}

We will now go through a list of sources for economic data. This list is by means not a complete list of data sources. The list provides an introduction to some of the most prominent publicly available data sources for economists.

\hypertarget{data-from-statistical-offices}{%
\subsection*{Data from Statistical Offices}\label{data-from-statistical-offices}}
\addcontentsline{toc}{subsection}{Data from Statistical Offices}

The national statistical offices collect, clean, and provide data on important economic topics. Moreover they also typically engage in international networks to standardize measurement and share data through international statistical databases (described below). The Office for National Statistics (ONS) is the national statistical office of the United Kingdom.

The statistical offices often publish both raw data and small reports where they describe the data. The data is typically shared via a website. For the ONS, much of the material is accessible on their website \href{https://www.ons.gov.uk/}{ons.gov.uk}. The national statistical offices also play an important role in providing international organizations with data. Much of the data accessible through sources such as the OECD and Eurostat comes from the national statistical offices. However, in some cases definitions might be different. For example in terms of population: Eurostat typically provide population estimates for the start or the end of the year. The ONS provides mid-year estimates.

If you are able to understand the language on the national statistical websites it is often worth to getting the data directly from these sources. Some countries also provide English language versions of the website. While most countries organise all their data collection and dissemination through one agency, the United States has several agencies that cover these tasks. Population data is available at the US Census Bureau website \href{https://www.census.gov/}{census.gov}.

If we want to compare data across countries it is typically better to obtain the data from a source that provides data for all countries. This reduces the risk of using different definitions across the different countries (but we should still check that).

\hypertarget{downloading-data-from-statistical-offices}{%
\subsection*{Downloading data from Statistical Offices}\label{downloading-data-from-statistical-offices}}
\addcontentsline{toc}{subsection}{Downloading data from Statistical Offices}

As all statistical agencies organise their websites differently it is not possible to give a general description of how to download the data. However, we can provide some general guidance and an example for the ONS. First, some general advice

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{If the website of the statistical office provides access to a public ``database'', then use it.}

  \begin{itemize}
  \tightlist
  \item
    A database is a structured set of data. The structured approach allows us to download precisely the data we are interested in.
  \end{itemize}
\item
  \emph{Avoid using data from reports and notes}.

  \begin{itemize}
  \tightlist
  \item
    We should always attempt to get the data from a source that is as raw as possible.
  \end{itemize}
\item
  \emph{Note the location of the raw data and keep a copy of the raw data}.

  \begin{itemize}
  \tightlist
  \item
    Keeping a reference to the location of the data and a copy of the raw data makes it possible to replicate the data visualization and make adjustments.
  \end{itemize}
\end{enumerate}

The following animation shows an example of downloading data from the ONS website. The ONS website does not provide access to a ``public database''.

\includegraphics{./resources/chapter_sources/gettingpopdata.gif}
\#\#\# Central banks\{-\}

\hypertarget{bank-of-england}{%
\subsubsection*{Bank of England}\label{bank-of-england}}
\addcontentsline{toc}{subsubsection}{Bank of England}

The Bank of England is the Central Bank of the United Kingdom. It was established in 1694, and amazingly, they even provide data on interest back to 1694. The policy interest rate is decided by the Monetary Policy Committee (MPC). They meet eight times a year and decide on the interest rate. Their main objective is to keep inflation at 2 percent, so they will adjust the interest rate to achieve this target. As monetary and financial stability is a main objective of the bank, they collect a lot of data on these topics We can obtain access to their data on their website \href{https://www.bankofengland.co.uk}{bankofengland.co.uk}. Most countries' central banks provide similar data.

The animation below shows an example of downloading data from the Bank of England website. This website includes a nice database that allows us to select the series we want.

\includegraphics{./resources/chapter_sources/bankofengland.gif}

\hypertarget{the-us-fed}{%
\subsubsection*{The US FED}\label{the-us-fed}}
\addcontentsline{toc}{subsubsection}{The US FED}

Just like national statistical offices, most countries also provide data through their central banks. For example from the US, the FRED Economic data is a very good source of economic data. The data is available on the site \href{https://fred.stlouisfed.org/}{fred.stlouisfed.org/}

\hypertarget{international-organizations}{%
\subsection*{International organizations}\label{international-organizations}}
\addcontentsline{toc}{subsection}{International organizations}

\hypertarget{the-imf}{%
\subsubsection*{The IMF}\label{the-imf}}
\addcontentsline{toc}{subsubsection}{The IMF}

The International Monetary Fund (IMF) is the bank of the central banks. They have a very rich database of financial statistics and key economic indicators that covers many countries. Their database is very useful for obtaining comparable financial data across countries. We can download their data from \href{https://www.imf.org/en/Data}{imf.org/en/Data}. This is

\hypertarget{the-oecd}{%
\subsubsection*{The OECD}\label{the-oecd}}
\addcontentsline{toc}{subsubsection}{The OECD}

The Organisation for Economic Co-operation and Development (OECD) is an international organization based in Paris, France. The OECD has a very rich database of economic variables for the member countries. The advantage of data from the OECD is that it is typically made comparable across countries. For example for unemployment rates, the OECD will typically ensure that they are harmonized. That means, that the OECD data on unemployment might not give you the exact same number as the national statistical offices, because they use different definitions. However, by using data from the OECD (or similar international organizations), we can ensure that definitions are comparable across countries.
The OECD data is accessible on the website \href{https://stats.oecd.org}{stats.oecd.org}. The animation below shows an example of downloading data from the OECD. This website includes a nice database that allows us to select exactly the series we want.

\includegraphics{./resources/chapter_sources/oecd.gif}

\hypertarget{eurostat}{%
\subsubsection*{Eurostat}\label{eurostat}}
\addcontentsline{toc}{subsubsection}{Eurostat}

The statistical office of the European Union provides a rich database of statistics on economic, environmental and social topics. Just like data from the OECD, most of these measures are standardized and we almost don't have to worry about consistent measures across countries. Their data is available here: \href{https://ec.europa.eu/eurostat/web/main/home}{ec.europa.eu/eurostat}. The animation below shows an animation of downloading data from Eurostat. This website includes a nice database that allows us to select exactly the series we want.

\includegraphics{./resources/chapter_sources/eurostat.gif}

\hypertarget{the-un}{%
\subsubsection*{The UN}\label{the-un}}
\addcontentsline{toc}{subsubsection}{The UN}

The United Nations collects and hosts a wide range of data. Many of its datasets are available from partner organisations, regional offices and sub-organisations, such as the United Nations Development Programme (UNDP), the UNESCO Institute for Statistics and the World Health Organization (WHO). The United Nations provides a common platform for these sources here: \href{http://data.un.org/Default.aspx}{data.un.org}.

\hypertarget{the-world-bank}{%
\subsubsection*{The World Bank}\label{the-world-bank}}
\addcontentsline{toc}{subsubsection}{The World Bank}

The World Bank is a partner organisation of the United Nations, but their database deserves an explicit presentation. The World Bank actually hosts several databases. They host more than 18 thousand time series covering a wide range of topics. Many of their time series cover the period back to the 1960ies for a lot of countries around the world. You can access their databank here: \href{http://worldbank.org}{worldbank.org}. The animation below shows an example of downloading data from the World Bank Website This website includes a nice database that allows us to select exactly the series we want.

\includegraphics{./resources/chapter_sources/wb.gif}

\hypertarget{topic-specific-databases}{%
\subsection*{Topic specific databases}\label{topic-specific-databases}}
\addcontentsline{toc}{subsection}{Topic specific databases}

\hypertarget{our-world-in-data}{%
\subsubsection*{Our World in Data}\label{our-world-in-data}}
\addcontentsline{toc}{subsubsection}{Our World in Data}

Our World in Data, accessible here \href{http://www.ourworldindata.org}{ourworldindata.org}, is a digital publication on global development. The website includes articles dedicated to specific topics with in-depth descriptions of methods and sources. Most of their data is taken from other sources, but it is a good starting point for economic data on global development. Especially because they also includes some more specific datasets, that are not from the international organizations.

\hypertarget{gapminder}{%
\subsubsection*{Gapminder}\label{gapminder}}
\addcontentsline{toc}{subsubsection}{Gapminder}

Gapminder is also a web publication on Global Development. They collect various international datasets on global development, but just like the Our World In Data, they also collect data from more specialized sources, such as academic publications. Their data is available here:
\href{https://www.gapminder.org/data/}{www.gapminder.org}.

\hypertarget{the-world-inequality-database}{%
\subsubsection*{The World Inequality Database}\label{the-world-inequality-database}}
\addcontentsline{toc}{subsubsection}{The World Inequality Database}

The WOrld Inequality database contains unique data on income and wealth inequality for countries around the world. The data is available here: \href{https://wid.world/data}{https://wid.world/data/}.

\hypertarget{publicly-available-data-an-overview}{%
\subsection*{Publicly available data: An overview}\label{publicly-available-data-an-overview}}
\addcontentsline{toc}{subsection}{Publicly available data: An overview}

\hypertarget{downloading-datasets}{%
\subsubsection*{Downloading datasets}\label{downloading-datasets}}
\addcontentsline{toc}{subsubsection}{Downloading datasets}

All the links listed in this document provide access to websites with rich datasets. Unfortunately, each website is different, and there is not one single rule for how to find and access the data we need, but here are some suggestions:

\begin{itemize}
\tightlist
\item
  Search for ``databases'' instead of ready made tables. Databases enable you to select exactly the series you need.
\item
  Download the dataset in a flexible format. I personally prefer ``.csv'' files because we can open them both in Excel and R.
\item
  Save a copy of the raw file, and edit the data in a different file.
\item
  Expect delays. Some websites are slow.
\end{itemize}

\hypertarget{selecting-the-appropriate-source}{%
\subsubsection*{Selecting the appropriate source}\label{selecting-the-appropriate-source}}
\addcontentsline{toc}{subsubsection}{Selecting the appropriate source}

\begin{itemize}
\item
  Need to compare countries \(\rightarrow\) data from an internal organization.
\item
  Data for EU countries only \(\rightarrow\) consider using Eurostat. Eurostat often provides very good metadata (especially compared to the OECD).
\item
  Data for countries outside the EU

  \begin{itemize}
  \tightlist
  \item
    On labor market topics \(\rightarrow\) consider using OECD data.
  \item
    On development topics \(\rightarrow\) consider using data from The World Bank or the United Nations.
  \item
    On financial topics \(\rightarrow\) consider using data from the IMF.
  \end{itemize}
\item
  Data on a regional level (subnational) \(\rightarrow\) consider using Eurostat data or national statistical offices.
\item
  Historical data \(\rightarrow\) consider using national statistical offices.
\end{itemize}

\hypertarget{using-apis}{%
\subsection*{Using APIs}\label{using-apis}}
\addcontentsline{toc}{subsection}{Using APIs}

We can actually also standardize the updating of the raw data. Instead of downloading the data manually from the website, we can ask the software to directly download the data using an application programming interface (API). An API is a fairly advanced concept, but what we need to know for this unit, is that many websites and services have an API that is able to receive a request and return a response. A very common analogue to an API is a waiter in a restaurant. You tell the waiter what you would like to eat. The waiter goes to the kitchen and delivers the request, and the waiter returns with the food.

Many statistical offices have an API that you can use. You can use R to send a request to the UK Office for National Statistics, and you will get a data series in return. In Excel, this is slightly complicated, but in R this is fairly straightforward.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

We have discussed the following topics

\textbf{Data source types}
1. Simulated data
2. Sample survey data
3. Census survey data
4. Register and automatically generated data

\textbf{Public data sources}

\begin{itemize}
\tightlist
\item
  The Office for National Statistics for the United Kingdom (ONS)
\item
  The United States Census Bureau.
\item
  The Bank of England.
\item
  Federal Reserve Economic Data (FRED).
\item
  The International Monetary Fund.
\item
  The OECD
\item
  Eurostat.
\item
  The United Nations.
\item
  The World Bank.
\item
  Our World in Data.
\item
  Gapminder.
\item
  The World Inequality Database.
\end{itemize}

\hypertarget{how-data-is-stored}{%
\chapter{How data is stored}\label{how-data-is-stored}}

\hypertarget{what-this-chapter-is-about-7}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-7}}

This chapter is about how data gets into the computer. Once we have collected our dataset how do we store it? Why should you care about how a computer counts and stores data as an economist? Knowing how a computer counts allows you to estimate the size of datasets and how to optimally store data.

Economists often work with datasets with millions (or billions) of observations and thousands of variables. Such a dataset can take hours or even days to open. Moreover, understanding how data is saved is important when the data looks different to what you expected. For example when the sentence ``Thomas Mller plays for Bayern Mnchen'' looks like ``Thomas Mller plays for Bayern Mnchen'', what went wrong?

\hypertarget{intended-learning-outcomes-7}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-7}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter you should be able to

\begin{itemize}
\tightlist
\item
  Use binary counting (base 2 counting)
\item
  Explain how computers store information (What is a bit?)
\item
  Explain what bits, bytes, kilobytes, megabytes and gigabytes are
\item
  Explain what decoding and encoding are.
\item
  Estimate the size of a dataset
\item
  Use the tidy data principles
\end{itemize}

\hypertarget{how-computers-work}{%
\section{How computers work}\label{how-computers-work}}

\hypertarget{or-0}{%
\subsection*{1 or 0}\label{or-0}}
\addcontentsline{toc}{subsection}{1 or 0}

More or less everything you do on a computer is based on binary numbers. Binary numbers are numbers that only can take two values. We often think of them as 0 or 1. But it could also be true or false, low or high and so on. When you are reading these chapters, reading a news story, playing a computer game or watching a movie, you are essentially looking at a very long list of zeros and ones, just like the list below. Your computer or mobile device is just transforming these values into interpretable content.

A very simplified description of how computers work is that they receive an electronic signal or they do not receive a signal. These two states correspond to the binary states, which we often call zero and one. Students at the Massachusetts Institute of Technology (MIT) created the video below to illustrate how computers work, where the binary signal is set by manual switches. You can watch it here:

\begin{figure}

{\centering \href{https://www.youtube.com/embed/8cVsgFN3hSM}{\includegraphics[width=0.7\linewidth]{11_data_storage_files/figure-latex/store1-1} }

}

\caption{How Computers Compute (Science Out Loud S2 Ep5). Source: MITK12Videos}\label{fig:store1}
\end{figure}

\hypertarget{from-0-and-1-to-interpretable-content.}{%
\subsection*{From 0 and 1 to interpretable content.}\label{from-0-and-1-to-interpretable-content.}}
\addcontentsline{toc}{subsection}{From 0 and 1 to interpretable content.}

How do we get from zeros and ones to letters, colors and movies? To understand how this works, we have to understand binary counting. You probably learned binary counting at some point, but we are all more used to decimal (or ``base ten'') counting, where we use ten different symbols to count. The numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9. Binary counting is not very complicated. In fact, the key difference is that we only use two symbols, 0 and 1, and it is thus a ``base two'' system. To understand how it works, let us briefly recap how the decimal counting you use every day works.
Consider the number 123:

\begin{itemize}
\tightlist
\item
  The 1. number from the right denotes how many ``\(10^0=1\)''s: 3
\item
  The 2. number from the right denotes how many ``\(10^1=10\)''s: 2
\item
  The 3. number from the right denotes how many ``\(10^2=100\)''s: 1
\item
  The sum of the above is thus: \(3 \times 1+2\times 10+1\times 100\)
\end{itemize}

So when we say 123 we are essentially saying 1 times one hundred, two times ten, and three times one.

Note that every time we moved to the left we multiply the value of the number by ten. The rightmost number represents ones, moving one step to the left we get the tens, and one more gives the hundreds. If we had an even larger number, we could continue to thousands, ten-thousands etc. This is because it is a base 10 system. If we instead of multiplying by ten multiply by two, we have the base 2 system. The rightmost number again denotes the number of ones, and the second number from the left now denotes the number of twos (\(2\times 1\)), the third number the number of fours (\(2\times 2\)), the third number the number eights (\(2\times 4\)), and so on. Let us try to write the same number as above (123 in base 10) using base two:

\begin{itemize}
\tightlist
\item
  The 1. number from the right denotes how many ``\(2^0=1\)''s=1
\item
  The 2. number from the right denotes how many ``\(2^1=2\)''s=1
\item
  The 3. number from the right denotes how many ``\(2^2=4\)''s=0
\item
  The 4. number from the right denotes how many ``\(2^3=8\)''s=1
\item
  The 5. number from the right denotes how many ``\(2^4=16\)''s=1
\item
  The 6. number from the right denotes how many ``\(2^5=32\)''s=1
\item
  The 7. number from the right denotes how many ``\(2^6=64\)''s=1
\item
  The 8. number from the right denotes how many ``\(2^7=128\)''s=0
\item
  The sum of the above is thus: \(1 \times 1+1\times 2+0\times 4 +1\times 8 +1\times 16 +1\times 32 +1\times 64 +0\times 128.\)
\end{itemize}

Which is equivalent to the decimal above. So 123 in decimal numbers, expressed in terms of binary numbers is: 01111011. How did we figure out the combination that lead to 123? we started backwards and asked: How many 128s can be included? Zero. How many 64s can be included? And so on.

\hypertarget{from-signals-to-bits-and-bytes.}{%
\subsection*{From signals to bits and bytes.}\label{from-signals-to-bits-and-bytes.}}
\addcontentsline{toc}{subsection}{From signals to bits and bytes.}

We can thus count to any number using just a binary signal, as long as we have enough signals. But why did I include eight signals above, when only seven were needed? Recall from above, that a computer counts by receiving signals. The signal is that either there is a signal or there is no signal. Such a signal is called a ``bit''. We typically measure data sizes in terms of ``bytes''. A byte simply corresponds to eight bits. The string of eight values above therefore easily converts into the language you are used to when talking about file sizes on a computer.

If you have a (very small) file that is ``1kb'' big it means that it contains 1024 bytes or \(1024\times 8= 8192 bits\). Such a file therefore contains 8192 zeros or ones and in principle we would be able to continue the list above to have 8192 rows and write a very large number:

\begin{itemize}
\tightlist
\item
  The 1. number from the right denotes how many ``\(2^0=1\)'' we have.
\item
  The 2. number from the right denotes how many ``\(2^1=2\)'' we have.
\item
  The 3. number from the right denotes how many ``\(2^2=4\)'' we have.
\item
  \(\vdots\)
\item
  The 8192. number from the right denotes how many ``\(2^{8191}=..?\) (a very large number!) we have''
\end{itemize}

We wrote in ``principle'', because this is not how the computer would save such a number. Take for example the number 128. Using just 1 byte, the computer could save this number as ``01000000''. However, if you create a new empty file on your computer, you will discover, that this is not what happens. Instead it is likely that the file content will contain three bytes and look like the following:

\begin{verbatim}
00110001 00110010 00111000
\end{verbatim}

Let us try to translate this.

\begin{itemize}
\tightlist
\item
  The first byte is \(1 \times 1+0\times 2+0\times 4 +0\times 8 +1\times 16 +1\times 32 +0\times 64 +0\times 128=49\)
\item
  The second byte is: \(0 \times 1+1\times 2+0\times 4 +0\times 8 +1\times 16 +1\times 32 +0\times 64 +0\times 128=50\) * The third and last byte is: \(0 \times 1+0\times 2+0\times 4 +1\times 8 +1\times 16 +1\times 32 +0\times 64 +0\times 128=56\)
\end{itemize}

So somehow 49, 50 and 56 translate into 128. Computers use a set of rules to translate the signals into letters, numbers or pictures. The set of rules is defined by the ``encoding scheme''. The document created above was saved using the 128 encoding scheme. According to this scheme a 49 is translated to a 1, 50 to 2 and 56 to 8. We will return to the encoding schemes below, but let us first try to shed some more light on bits and bytes.

\hypertarget{a-never-ending-confusion-1000-or-1024}{%
\subsection*{A never ending confusion 1000 or 1024?}\label{a-never-ending-confusion-1000-or-1024}}
\addcontentsline{toc}{subsection}{A never ending confusion 1000 or 1024?}

If you ever bought a 1GB memory stick and checked the capacity on a computer, you might have discovered that the computer says the capacity is less than 1 GB. Why is that? Basically it is a confusion between decimal and binary counting. \(2^{10}=1024\) is very close to the number 1000, which we call ``kilo'', \(2^{20}=1,048,576\) is close to 1,000,000 which we call ``mega'' and \(2^{30}=1,073,741,824\) is close to 1,000,000,000 which we call ``giga''. If you say 1GB (1 gigabyte) you might therefore refer to 1,073,741,824 bytes or 1,000,000,000 bytes. Not all systems use the same aggregation (Linux/Unix systems may for example differ from Windows systems).

\hypertarget{how-fast-is-your-internet-connection}{%
\subsection*{How fast is your Internet connection?}\label{how-fast-is-your-internet-connection}}
\addcontentsline{toc}{subsection}{How fast is your Internet connection?}

Another source of confusion when talking about bytes and bits is the ``B'' vs ``b''. The former relates to bytes, the latter to bits. If we are talking about 1GB we mean 1 gigabyte. If we are talking 1Gb we are talking about 1''gigabit''. If you have an Internet connection with an advertised speed up to ``50 Mbps'' it means that it is able to receive up to 50 megabits per second. So remember that 1 byte is 8 bits, and 50Mbps therefore means that you should be able to download \(50/8=6.25\) megabytes per second.

To recap, after reading this section you should be able to:
* Distinguish between decimal and binary counting.
* Explain how a computer saves information in terms of sequences of binary signals.

\hypertarget{encoding}{%
\section{Encoding}\label{encoding}}

\hypertarget{how-encoding-and-decoding-works}{%
\subsection*{How encoding and decoding works}\label{how-encoding-and-decoding-works}}
\addcontentsline{toc}{subsection}{How encoding and decoding works}

We now know that a computer stores information by means of binary signals. We can translate these signals into numbers, but it is not yet clear how to translate these signals into letters and symbols. To achieve this, computers use rules where a number is translated into a numerical value, a letter or a symbol. So the computer has a set of bytes: \emph{00110001 00110010 00111000}, in decimal terms this corresponds to 49, 50 and 56. The computer then looks up in a large table which says that: 49=1, 50=2, 56=126. So the list of bytes represents the number 128. going from 49, 50 and 56 to 128 is called decoding, which is what the computer does when you open a document. When you save a document the computer encodes the content from letters and symbols to first a decimal number (using the big table) and then to sequences of bytes.

To get terms straight: We say that we encode something when we convert something into a coded form, so if you take something in readable form and convert it into code, you are encoding it. You are decoding a piece of code if you are converting the code into readable form. \}

\hypertarget{where-does-the-big-table-come-from}{%
\subsection*{Where does the big table come from?}\label{where-does-the-big-table-come-from}}
\addcontentsline{toc}{subsection}{Where does the big table come from?}

So where is the big table that the computer uses to look up numbers? One of the most famous tables, i.e.~set of rules to translate the number derived from a sequence of bits is the ``American Standard Code for Information Interchange'' also known as ASCII. ASCII contains a list of 128 numbers and the corresponding symbol. The full list is available \href{https://ascii.cl/}{here}, but a small excerpt of the full list is reported here:

\begin{longtable}[]{@{}ll@{}}
\caption{\label{tab:storet1} The ASCII code table}\tabularnewline
\toprule
Decimal number & Symbol \\
\midrule
\endfirsthead
\toprule
Decimal number & Symbol \\
\midrule
\endhead
48 & 0 \\
49 & 1 \\
50 & 2 \\
51 & 3 \\
\ldots{} & \ldots{} \\
65 & A \\
66 & B \\
67 & C \\
\bottomrule
\end{longtable}

So a file with the binary code ``01000001'' would show an ``A'' if the ASCII encoding scheme was applied. This happens as follows:

\begin{itemize}
\tightlist
\item
  Step 1: The computer receives eight signals, corresponding to a byte: \texttt{01000001}.
\item
  Step 2: This translates into the decimal number \(1 \times 1+0\times 2+0\times 4 +0\times 8 +0\times 16 +0\times 32 +1\times 64 +0\times 128=65\).
\item
  Step 3: The computer looks in the ASCII codebook (Table @ref\{tab:store2\}) and realizes that if it sees a number binary number that corresponds to the decimal number 65 it should print the symbol A.
\end{itemize}

When you are writing a text document the reverse happens. You enter an A, the computer looks up the table, notes that this corresponds to the decimal number 65 and converts it into a binary number and saves it as a string of signals.

The basic ASCII codebook contains 95 symbols that we can read and 28 instructions that we cannot directly read, such as whitespace, tab, backspace and so on. But because it only contains 128 symbols, which can be saved using seven bits, the first bit in a byte will always be zero using the ASCII encoding. This is basically a waste of resources.

\hypertarget{there-are-many-codebooks.-what-a-mess}{%
\subsection*{There are many codebooks. What a mess!}\label{there-are-many-codebooks.-what-a-mess}}
\addcontentsline{toc}{subsection}{There are many codebooks. What a mess!}

This all sounds straightforward. Unfortunately 128 symbols aren't sufficient to show all symbols of all languages in the world. This creates the issue where ``Thomas Mller plays for Bayern Mnchen'' looks like ``Thomas Mller plays for Bayern Mnchen''. There are many encoding schemes, and if a file on the computer is encoded using one scheme, but the computer decodes the binary codes using a different scheme, the symbols will look odd.

\hypertarget{encoding-and-decoding-what-you-should-know-and-do}{%
\subsection*{Encoding and decoding: What you should know and do?}\label{encoding-and-decoding-what-you-should-know-and-do}}
\addcontentsline{toc}{subsection}{Encoding and decoding: What you should know and do?}

Should you know the code tables? Certainly not. You should know that they exist and that there are many versions of them. It is also worth knowing that the most popular encoding schemes are ASCII and UTF-8. We will return to that.

If things look fine: do not worry. Luckily, in most cases you do not need to worry about the encoding and decoding schemes. Most files contain some instructions to the computer on what scheme to use.

When you navigate on websites, they will typically report the coding scheme to the browser (i.e.~Google chrome, Firefox, Safari, Internet Explorer), and the browser makes the correct interpretation. Even if websites do not include information about which scheme to use to translate information, browsers are typically able to guess the encoding scheme quite well.

What you need to know is that if something looks wrong, it is most likely due to the encoding and decoding gone wrong. You should also know that the encoding can affect the file size, we will return to that later.

Let us consider an example where things have gone wrong: The pictures below show screenshots from the online version of the New York Times. It is the same frontpage, but in the first version, some text is garbled. For example the headline ``Trump Offers a Steel Barrier, but Democrats Are Unmoved'' should be ``Trump Offers a `Steel Barrier,' but Democrats Are Unmoved'', as illustrated by the lower picture. What happened?

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./resources/chapter_storing/nytimes_western_encoding} \includegraphics[width=0.5\linewidth]{./resources/chapter_storing/nytimes_utf8_encoding} 

}

\caption{Screenshot from the New York Times website on January 7 2019.Left: Western (Windows 1252) encoding. Right: Unicode UTF-8 encoding.}\label{fig:store3}
\end{figure}

What went wrong? I instructed the browser that the document it was showing was encoded using the ``Western (Windows1252)'' encoding scheme, but if you look at the source code of the website, you will find the element:

``

''

which instructs the browser to use the UTF-8 encoding scheme, which is the scheme used in the lower picture. So what went wrong is simply that we decoded using the wrong ``coding scheme''.

Garbled websites are rarely a real issue, but here are some examples where encoding errors are problematic

\begin{itemize}
\item
  \textbf{Encoding issues in data}

  Imagine that you would like to investigate the average income across German cities. You have a large dataset, with a variable stating individual income and another variable stating ``city''. You realize that the variable city has several values representing the same city. For the city Mnchen, you observe the values ``Mnchen'' and ``Munich'', so to get the average for Mnchen you compute the average across all individuals with the city being either ``Mnchen'' or ``Munich''. This is all fine and good. But if there is an encoding error, some observations might have the value ``Mnchen'', which you do not include in your average. Your average is therefore wrong.
\item
  \textbf{Encoding issues in scripts and codes.}
  In a recent update of the popular statistical software Stata, the encoding support was changed. Version 14 of Stata of the software was the first version to fully support unicode UTF-8 encoding. This means that if you open Stata files created in version 12 or 13 in version 14, they will look garbled and instructions might not work.
\end{itemize}

\hypertarget{the-unicode-encoding-scheme}{%
\subsection*{The unicode encoding scheme}\label{the-unicode-encoding-scheme}}
\addcontentsline{toc}{subsection}{The unicode encoding scheme}

While ASCII used to be the most popular scheme, the unicode schemes are by far the most popular schemes today. The full unicode scheme consists of a table of 1,114,112 code points (or symbols). We call them code points, because the table is somewhat more complex than for the ASCII. Instead of providing a mapping between a binary code and a symbol, there is a mapping between a binary code and a code point, and a mapping between the code point and the symbol. These details are not important, and in fact the unicode code point 65 corresponds to the symbol ``A''. Does that sound familiar? It should, because there is a 1:1 mapping from ASCII to UTF-8 unicode encoding, and 65 is the decimal number for the binary sequence representing A. So if a document was saved using ASCII encoding, but you instruct the computer to use UTF-8 encoding, you should not worry. You can think of ASCII as a subset of UTF-8

\hypertarget{utf-8-utf-16-utf-32}{%
\subsubsection{UTF-8, UTF-16, UTF-32}\label{utf-8-utf-16-utf-32}}

But how does UTF-8 relate to unicode? Unicode is the full set of code-points, while UTF-8 is a specific encoding scheme. There is also UTF-32 which uses 32 bits. 32 bits per symbol gives a lot of flexibility, but it will often take up a lot of space. UTF-8 is a flexible encoding scheme, because it uses the number of bytes necessary to show the information. Another encoding format is UTF-16, which is also flexible in length, but in contrast to UTF-8 it uses two bytes as a minimum (UTF-8 uses one byte). Documents saved using UTF-16 encoding will therefore typically be larger than documents saved with UTF-8 encoding. As the example shows, these differences can be substantial (almost twice the size), without being visible to the reader. So the encoding scheme is important because it determines whether the information is read correctly, and because affects the file size. In the next subsection, we will talk more about file sizes.

\hypertarget{if-encoding-and-decoding-go-wrong-what-can-you-do}{%
\subsection*{If encoding and decoding go wrong, what can you do?}\label{if-encoding-and-decoding-go-wrong-what-can-you-do}}
\addcontentsline{toc}{subsection}{If encoding and decoding go wrong, what can you do?}

If you discover an encoding and decoding scheme, there are a number of options to sort out the issue.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Instruct the software you are using to save the content to use a different encoding scheme.
\item
  Instruct the software you are using to read the content to use a different decoding scheme.
\item
  Manually correct the decoding errors in the software that you are using to read the data.
\end{enumerate}

\hypertarget{encoding-what-you-shouldnt-do}{%
\subsection{Encoding: What you shouldn't do!}\label{encoding-what-you-shouldnt-do}}

Let's end this discussion on encoding with a small warning. If you open a document that is decoded using a different codebook than was used for encoding, there is usually no problem. You discover the error, you ignore it or you solve the problem as above.

However, what you should avoid doing is overwriting the encoding scheme. Consider the following example:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Your friend writes a document and saves it using encoding scheme X.
\item
  You open the document and your software assumes it is encoded using encoding scheme Y. You ignore that some symbols clearly are garbled, make some changes and save the document using encoding scheme Z.
\item
  Another friend opens the dataset and everything looks like a mess.
\end{enumerate}

In the example above, it would require a lot of work to sort out the mess. To see why, let's consider what happened.

\begin{itemize}
\tightlist
\item
  In encoding scheme X an ``'' is saved as the decimal number 5: Binary code \emph{00000101}.
\item
  You use scheme Y to decode \emph{00000101}, which gives an ``''.
\item
  You now decode the symbols using scheme Z, where the ``'' has the decimal number 7. So the binary code now becomes \emph{00000111}
\item
  To get back to the original ``'' we would need to know that some symbols should first be decoded using scheme Z, then encoded using scheme X.
\end{itemize}

\hypertarget{estimating-file-size-and-memory-use}{%
\section{Estimating file size and memory use}\label{estimating-file-size-and-memory-use}}

\hypertarget{variable-types}{%
\subsection*{Variable types}\label{variable-types}}
\addcontentsline{toc}{subsection}{Variable types}

When we store data on the computer we often ignore how the computer stores the variable. However, when you store large datasets, this can become very important, as a dataset might take up more space than necessary, because the type of the format of the variable is not aligned to the content.
The specific list of potential variable formats varies depending on how you save the data (i.e.~what software you use to save the data), but as a minimum, you should know the following types:

\begin{itemize}
\item
  \textbf{Boolean}

\begin{verbatim}
- A boolean variable can only contain two possible values. True or false (0 or 1). You could for example have saved a variable with the content       "female" as a boolean variable, where "true" would correspond to the case where the observation represents a female individual, and false          otherwise. 
- Minimum size requirement: 1 bit.
\end{verbatim}
\item
  \textbf{Integer}

\begin{verbatim}
- Integer variables contain only whole numbers in a pre-specified range. The range depends on the size of the variable, if the variable is a         byte, it   will typically allow you to save values in the range from -128 to +127.
- Typical size requirement: 1 byte (8 bits) (for values -128 to 127).
\end{verbatim}
\item
  \textbf{Floating point numbers}

\begin{verbatim}
- Floating point variables can take almost any numerical value. However, in practice the range and the precision is limited. The limit depends       on the   space allocated to the variable, but unless you work with very large or small values or very precise values, you do not need to           worry about this.
- Typical  size requirement: 8 bytes (64 bits).
\end{verbatim}
\item
  \textbf{Characters}

\begin{verbatim}
 - Character values contain text, and can include all symbols that are defined in the applied encoding scheme.
 - Size requirement depends on encoding, 1 byte per character at least for UTF-8 encoded strings.
\end{verbatim}
\end{itemize}

Note that I ranked the variable types above according to their approximate size rank. Boolean variables can be saved using only very little space, while characters and floating point variables require much more computer memory. The specific ranking depends on how the variables are saved. We will return to this issue in the next chapter.

What is important for now is that the variable format type is important. Imagine that you save the foot size as a boolean variable. In that case you will throw away a lot of information, because the foot size can then only take 2 values. On the other hand, if you save the variable ``female'' as a floating point variable you will waste a lot of resources, because it uses more space than actually required.

\hypertarget{file-size}{%
\subsection*{File size}\label{file-size}}
\addcontentsline{toc}{subsection}{File size}

We now know what we need to approximate the file size.
Let us now try to estimate the size of a dataset. Our dataset contains 10 variables and 20 observations. If all these observations are stored as floating-point numbers, the approximate file size is:

\begin{align}
10\times20\times8&=1600\text{ bytes} \nonumber\\
&=1600/2^{10}=1.56 \text{KB}\nonumber
\end{align}

In most programs the data will be stored the in the RAM of the computer you are working on. 1.56 KB is not an issue in terms of RAM capacity for any modern computer.

But let's consider another dataset, a dataset covering 6 million individuals over 30 years and 250 variables:

\begin{align}
6,000,000\times 30 \times250 \times8&=360,000,000,000\text{ bytes} \nonumber\\
&=360,000,000,000/2^{20}= 343,323 \text{MB}\nonumber\\
&=360,000,000,000/2^{30}= 335 \text{GB}\nonumber
\end{align}

Our normal computers will not be able to handle this dataset in the RAM and loading this data will cause problems. Such datasets are not uncommon. If you are working with administrative data on an individual level, you often have sample sizes like that.

So what could we do? First, we should try to split the dataset up in smaller elements: fewer years and/or fewer variables. Second, we should try to save variables more efficiently. Do all 250 variables need floating point precision? How big would this dataset be, if all variables were saved as integers? Recall that an integer usually takes up one byte. The floating point precision number is thus eight times larger, and the same observations and variables saved as integers would then take up \(335/8\approx 42\)GB.

\hypertarget{what-happens-if-we-use-the-wrong-variable-format}{%
\subsection*{What happens if we use the wrong variable format?}\label{what-happens-if-we-use-the-wrong-variable-format}}
\addcontentsline{toc}{subsection}{What happens if we use the wrong variable format?}

So what if we converted our large dataset from floating point variables to integers and some of the variables actually included values that were floating points? Well it depends on the software you use to convert the variables, but the most likely outcome is that the value will be saved as ``missing'' if it is not covered by the used format.

\hypertarget{estimates-are-estimates}{%
\subsection*{Estimates are estimates}\label{estimates-are-estimates}}
\addcontentsline{toc}{subsection}{Estimates are estimates}

You will probably discover, that the file size estimates using the approach presented here tends to underestimate the actual file size. The main reason for this is that files include some ``overhead''. The overhead might include information on the encoding type, but also information on the file format, which the software that reads the file uses.

\hypertarget{the-tidy-data-principles}{%
\section{The tidy data principles}\label{the-tidy-data-principles}}

Ideally we would like all raw datasets to be alike. As the R scientist Hadley Wickham puts it: \emph{``Like families, tidy datasets are all alike but every messy dataset is messy in its own way''}\footnote{This is a reference to a famous Leo Tolstoy quote. Try to find it!} \citet{wickham2014tidy}.

Why would we like all datasets to be alike? Having a standardized way of tidying data allows us to apply methods on various datasets, without bothering about the data structure. Imagine that you first created a very nice graph using one dataset. You would now like to create the same graph using a different dataset. Ideally, you would not have to change anything but the data source. This requires that the two datasets are organized in the same way.

To achieve a standardized way of storing datasets, a set of principles for ``tidy data'' have been set up:

\begin{itemize}
\tightlist
\item
  Each variable forms a column.
\item
  Each observation forms a row.
\item
  Each type of observational unit forms a table.
\end{itemize}

Figure \ref{fig:store4} shows an example of a messy dataset. Why is it messy? Let's first note the variables in this dataset:

\begin{itemize}
\tightlist
\item
  GDP
\item
  Country
\item
  GNI
\item
  Year
\end{itemize}

This dataset has four variables, but the dataframe in Figure \ref{fig:store4} has seven columns. That clearly violates the first criteria above: the number of columns should be the same as the number of variables.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./resources/chapter_storing/messy} 

}

\caption{A messy dataset.}\label{fig:store4}
\end{figure}

Let's try to make it tidy. We tidy it by first creating new variables corresponding to those we listed above. The column Country already existed, but GDP, GNI and Year are created by separating the existing columns. The tidy version of this dataset is shown in Figure \ref{fig:store4}.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./resources/chapter_storing/tidy} 

}

\caption{A tidy dataset.}\label{fig:store5}
\end{figure}

Most statistical software (for example Excel and R) are designed for tidy datasets. You will see this in Excel when you create Pivot tables and in R when you create charts with ggplot.

\citep{wickham2014tidy} also provides the following list of the most common issues with data:

\begin{itemize}
\tightlist
\item
  Column headers are values, not variable names.
\item
  Multiple variables are stored in one column.
\item
  Variables are stored in both rows and columns.
\item
  Multiple types of observational units are stored in the same table.
\item
  A single observational unit is stored in multiple tables.
\end{itemize}

\hypertarget{summary-1}{%
\section{Summary}\label{summary-1}}

In this chapter we covered the following topics

\begin{itemize}
\tightlist
\item
  Binary counting (base 2 counting)
\item
  How computers store information (What is a bit?)
\item
  Bits, bytes, kilobytes, megabytes and gigabytes.
\item
  Encoding (ASCII and Unicode UTF-8)
\item
  Estimating dataset size.
\item
  Tidy data principles
\end{itemize}

\hypertarget{describing-data}{%
\chapter{Describing Data}\label{describing-data}}

\hypertarget{what-this-chapter-is-about-8}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-8}}

Now that we have shown the data, we also need to be able to be able to describe the data. In this chapter we will discuss a number of tools and concepts that are useful when describing changes. We will first go through concepts to describe changes. We will then go through a method for decomposing changes, and finally we will address the issue of removing noise from time series.

\hypertarget{intended-learning-outcomes-8}{%
\subsection*{Intended learning outcomes}\label{intended-learning-outcomes-8}}
\addcontentsline{toc}{subsection}{Intended learning outcomes}

After reading this chapter you should be able to.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  describe differences across time and groups using indexes, relative changes, and average growth rates.
\item
  decompose changes in variables in changes in their underlying variables.
\item
  apply moving averages and understand the intuition behind seasonal adjustments.
\end{enumerate}

\hypertarget{the-objective-guide-the-reader}{%
\section{The objective: Guide the reader}\label{the-objective-guide-the-reader}}

\hypertarget{support-charts-and-tables}{%
\subsubsection*{Support charts and tables}\label{support-charts-and-tables}}
\addcontentsline{toc}{subsubsection}{Support charts and tables}

Charts and tables should always be supported by a guide for the reader. Nevertheless, it is not uncommon that newspaper articles include a graph without any reference to the message the reader should take away from this graph. In many cases, the title of the graph or table (also called the caption) can be sufficient to guide the reader. For the author of the article or the policy report it often seems obvious why a specific graph or table is included. But in practice, only a few (very good) charts and tables tell the story without support.

Consider as an example Figure \ref{fig:desc1}. Without any further guidance, there are many takeaways the reader could get from this graph. Let us consider a few

\begin{itemize}
\tightlist
\item
  The unemployment rate continues to fall.
\item
  The unemployment rate was highest in the mid 1980ies.
\item
  The unemployment rate is at its lowest level 1970ies.
\item
  The unemployment rate is below the pre Great Recession Levels.
\item
  The decline in the unemployment rate is starting to flatten out.
\end{itemize}

All of these conclusions are perfectly right, but without any further guidance, the reader will have to guess what the main message of the graph should be. This could be in terms of a title, but it is can often be much more.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_describe/ex} 

}

\caption{Unemployment in the UK. Source: The UK Office for National Statistics}\label{fig:desc1}
\end{figure}

\hypertarget{how-to-guide-the-reader}{%
\subsection*{How to guide the reader}\label{how-to-guide-the-reader}}
\addcontentsline{toc}{subsection}{How to guide the reader}

When guiding the reader, we should help the reader. Helping the reader means that our description should make it easier for the reader to identify and remember the main takeaways from the visualization. This means that we should leave out unimportant details and focus on the main point. Let us consider two examples of descriptions of Figure \ref{fig:desc1}.

\hypertarget{example-1}{%
\subsubsection*{Example 1}\label{example-1}}
\addcontentsline{toc}{subsubsection}{Example 1}

\begin{quote}
Figure \ref{fig:desc1} shows the unemployment rate for the UK for the period 1971 to 2018. In 1971 the unemployment rate was about 4 percent. It then increased slightly, before it dropped again around 1975. Around 1976 it started to increase again to above five percent. It maintained the level of about five percent until 1981, when the unemployment started to increase a lot and peaked at about 12 percent around 1985. A few years later it dropped again to about seven percent in 1991. The unemployment rate started to increase again to above 10 percent, before a long period of decline started. The decline lasted until around 2006, where the unemployment rate was about five percent. The unemployment rate then increased to above eight percent again and maintained this level until around 2014, when it started to decline. It has been declining since 2014 and in 2018 it was around four percent.
\end{quote}

\hypertarget{example-2}{%
\subsubsection*{Example 2:}\label{example-2}}
\addcontentsline{toc}{subsubsection}{Example 2:}

\begin{quote}
Figure \ref{fig:desc1} shows the unemployment rate for the UK for the period 1971 to 2018 based on data from the ONS. The unemployment rate was lowest in the early 1970ies at about four percent, and highest in the mid 1980ies at about 12 percent. We can divide the period into three periods with high unemployment and two periods with low unemployment. High unemployment periods were the mid 1980ies, the early 1990ies, and around 2010. Low unemployment periods were the 1970ies as well as the end of the 1990s to the early 2000s. The last part of the chart, since about 2014, also show a sharply declining unemployment rate, suggesting that the current period will establish itself as another low unemployment period.
\end{quote}

\hypertarget{explaining-charts-dont-take-the-reader-on-a-roller-coaster-ride}{%
\subsubsection*{Explaining charts: Don't take the reader on a roller coaster ride!}\label{explaining-charts-dont-take-the-reader-on-a-roller-coaster-ride}}
\addcontentsline{toc}{subsubsection}{Explaining charts: Don't take the reader on a roller coaster ride!}

So which description was best? Example 1 takes the reader through the chart from left to right. Example 2 summarizes some general patterns for the reader. Recall that we use charts to communicate patterns. It is not important that the unemployment rate declined slightly from 1972 to 1973. If that was the key point, we would provide the numbers for these two years in a Table. The goal of the chart is to show overall patterns. Moreover: it is much easier for the reader to remember the overall pattern.

When we guide the reader through a chart we should remember that we would like to communicate the patterns in the data, and not every up and down. A reader, who reads example 1 above will feel like an elevator: it goes up and down all the time, but it is difficult to understand the big picture and any general conclusions from the text.

Here are some tricks to explaining patterns:

\begin{itemize}
\tightlist
\item
  Explain patterns, not details.
\item
  Don't take the reader on an elevator-tour and explain every up and down from left to right.
\item
  Focus on the endpoints. Has the value of interest been increasing or decreasing?
\item
  Group observations: For example group countries together with similar patterns.
\item
  Divide the chart into smaller parts: For example in periods of up and downturns.
\end{itemize}

\hypertarget{explaining-tables}{%
\subsubsection*{Explaining tables}\label{explaining-tables}}
\addcontentsline{toc}{subsubsection}{Explaining tables}

We use tables to communicate precise values and often to compare values across groups. When guiding the reader through a table, we should have this in mind: Which values should the reader have in mind, and which comparisons should the reader make?

\begin{itemize}
\tightlist
\item
  What are the relevant values?
\item
  What are the relevant comparisons?
\end{itemize}

In the rest of this chapter we discuss various tools that we can use to guide the reader through visualizations and also provide them with information that is difficult to grasp from the charts only. These tools should complement the visualization of data and not substitute the data visualizations. Some of these tools also involve transforming the data. In other words, to change the data in a way to better communicate the main takeaways.

\hypertarget{describing-differences}{%
\section{Describing differences}\label{describing-differences}}

In this section we will go through various methods to describe differences. These differences could be differences across groups, for example the difference in the unemployment rate among men and women. Or it could be differences in terms of changes over time, for example the change in unemployment in the UK from October 2008 (6.2 percent) to October 2011 8.2 percent.

\hypertarget{differences-in-absolute-terms}{%
\subsection*{Differences in absolute terms}\label{differences-in-absolute-terms}}
\addcontentsline{toc}{subsection}{Differences in absolute terms}

When we talk about ``in absolute terms'' we mean by itself without comparison to values or units. Examples are: changes in the UK Gross Domestic Product in pounds, increase in average age in years, changes in migration in the number of people, and changes in the unemployment rate in percentage points.

So when we talk about differences in absolute terms we should in principle always include the unit of measurement to avoid confusion: is the change in GDP in Pounds or Euros?, is the difference in the average age in years or months?

It is straightforward to compute the absolute change. We are simply subtracting one number from the other:

\begin{align}
  difference_{abs}=Value_2-Value_1
\end{align}

How would we use absolute changes? Consider Figure @ref\{fig:desc2\}, which uses the same data as Figure \ref{fig:desc1}, but only shows the last 12 years. We might want to focus on the great recession and provide statements such as ``the unemployment rate increased by 3.3 percentage points from pre-recession level to the peak level of 8.5 percent.'' or the unemployment rate in October 2018 was 4.5 percentage points lower than at the peak of the great recession at a level of 4 percent.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./resources/chapter_describe/ex4} 

}

\caption{Unemployment in the UK from 2006 to 2018. Source: The ONS with value labels. Source: The UK Office for National Statistics}\label{fig:desc2}
\end{figure}

\hypertarget{relative-differences}{%
\subsection*{Relative differences}\label{relative-differences}}
\addcontentsline{toc}{subsection}{Relative differences}

The contrast to absolute changes is relative changes. With relative changes we are always \emph{relating} the difference to something else. The most natural value to relate a change to is the point of departure of the difference. So if we are interested in the relative difference from year 1 to year 2, we would relate the size of the absolute difference from year 1 to year 2 to the value in year 2.

The relative change is typically measured in percent and calculated as follows:

\begin{align}
  difference_{rel}&=100\times \frac{Value_2-Value_1}{Reference \text{ } Value}\nonumber\\
  difference_{rel}&=100\times \frac{Value_2-Value_1}{Value_1}\nonumber
\end{align}

So let us consider the increase in the unemployment rate from 5.2 to 8.5 percent:

\begin{align}
    difference_{rel}=100\times \frac{8.5-5.2}{5.2}=63\%\nonumber
\end{align}

So the unemployment increased by 63 percent from pre crisis level to the crisis peak. What does that mean? It means that if we took the original level and considered 63 percent of that level and added that to the level, we would get to the peak level. In these terms, an increase of 100 percent corresponds to doubling the number.

\hypertarget{percentage-point-vs-percent}{%
\subsection*{Percentage point vs percent}\label{percentage-point-vs-percent}}
\addcontentsline{toc}{subsection}{Percentage point vs percent}

Note that in the examples above, we mentioned ``percentage point'' and ``percent''. So when we talk about absolute changes we are more explicit about the unit of measurement when the unit of measurement is percent. We say percentage points and not percent.

When unemployment increases from 4.2 to 6.2 percent, the change is 2 percentage points or 48 percent (100 \(\times\) (6.2-4.2)/4.2). These are two very different numbers, but nevertheless you will often hear someone saying that unemployment has increased by 2 percent, when they mean 2 percentage points. A 2 percent increase would be an increase from 4.2 percent to 4.284 percent. In other words an increase of 0.084 percentage points.

\begin{itemize}
\item
  Percentage point change: Refers to the \emph{absolute} change stated in the unit used, just like pounds, miles, or kilograms.
\item
  Percent change: Refers to the \emph{relative} change stated in percent (out of 100).
\end{itemize}

\hypertarget{calculating-compound-growth-rates}{%
\section{Calculating compound growth rates}\label{calculating-compound-growth-rates}}

Another common mistake is ignoring the compound growth rate. Let's illustrate the mistake by an extreme example. The price of a Bitcoin increased from 781 USD to 19,343 USD from December 16 2016 to December 16 2017. This is an increase of about 2,400 percent. What is the daily increase then? Let us take a very wrong approach: we just divide the total relative change by the number of days: \(2,400percent/365days\approx 6.5\) percent/day? So the first day the price is 781 USD, the next day the price would then be \(781\times1.065=831\) USD, the following day the price would be \(831\times1.065=885\) and so on. If we continue like that, the price of Bitcoins would be above 20,000 USD by the end of February, and by the end of December the price would be 78,38,759,397,922 USD. This is clearly wrong. Figure \ref{fig:desc3} illustrates how wrong.

What went wrong is that we've ignored that on the third day the growth rate is applied to the initial value plus the increase in value from day one to day two (the compound growth). If we instead applied the initial increase in absolute terms 365 times we would actually end up with the right value: \((831-781)\times 365 \approx 18,562\) which exactly corresponds to the increase (18,562+781=19,434 USD).

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_describe/bitcoin} 

}

\caption{The development of the Bitcoin price, and imputed price using average daily price increases. Data source: [coindesk.com](https://www.coindesk.com/price/)}\label{fig:desc3}
\end{figure}

How do we get the right average growth rate? If the price on December 16, 2016 was \(P_{t0}\) then the price on December 17 2016 will be \(P_{t1}=P_{t0}\times (1+r)\) where \(r\) is the average daily increase in the price. On December 18 2016, the price will be \(P_{t2}=P_{t1}\times (1+r)\) and so on. What happens after a year?

\begin{align}
  P_{t365}&=P_{t364}\times (1+r)\nonumber\\
  \Rightarrow P_{t365}&=P_{t363}\times (1+r)\times (1+r)\nonumber\\
  \Rightarrow P_{t365}&=P_{t362}\times (1+r)\times (1+r)\times (1+r)\nonumber\\
  \vdots\nonumber\\
  \Rightarrow P_{t365}&=P_{t0}\overbrace{\times(1+r)\times(1+r)\times\dots\times(1+r)}^{\text{number of periods, }n}\nonumber\\
  \Rightarrow P_{t365}&=P_{t0}\times(1+r)^n\nonumber
\end{align}

We can now isolate \(r\) to get an expression for the average daily growth:

\begin{align}
   P_{t365}&=P_{t0}\times(1+r)^{365}\nonumber\\
   \Rightarrow
   (1+r)^365&=\frac{P_{t365}}{P_{t0}}\nonumber\\
   (1+r)&=\left(\frac{P_{t365}}{P_{t0}}\right)^{(1/365)}\nonumber\\
   r&=\left(\frac{P_{t365}}{P_{t0}}\right)^{(1/365)}-1
\end{align}

or in more general terms:

\begin{align}
   r&=\left(\frac{P_{N}}{P_{0}}\right)^{(1/N)}-1
\end{align}

where \(N\) is the number of periods, e.g.~seconds, minutes, hours, days or years.

We can use this formula whenever we want to obtain average growth rates from a total growth rate. The difference between the correct and the wrong way to calculate average growth is larger, the larger the total growth. Note that \(r\) is the rate, which we have to multiply by 100 to get the average percentage growth.

\hypertarget{using-indexes}{%
\subsection*{Using indexes}\label{using-indexes}}
\addcontentsline{toc}{subsection}{Using indexes}

When we are interested in the relative development of a value over time, we can index the series to a reference point. For annual time series, we typically select a base year, where the value is set to 100. All other values are set relative to this base year.

Imagine that we want to show the development of the population of a country over ten years. In the first year, the population is measured to be 5 million. We plot this as 100 in the graph. The next year, the index value should be calculated relative to the base year. If the population is 5.5 million the index value will be \((5.5/5.0)\times 100=110\), and so on. In general, we can use the following formula to calculate the index value.

\begin{align}
  \text{Index\_value}=100\times \frac{\text{Value}}{\text{Base Year Value}}
\end{align}

An index is very helpful if we want to compare the development of several variables, that have very different scales. For example if we want to compare the development of the population of Wales with the development of the population of England. The index will tell us how the variable has developed \emph{relative} to the reference point. Therefore, even though the population of England is much greater than the population of Wales, we can show the development in the same graph, because we are looking at the development relative to the reference point, and \emph{not the levels}.

\hypertarget{decomposing-changes}{%
\section{Decomposing changes}\label{decomposing-changes}}

Describing in terms of their relative size or average relative size can provide good guidance for the reader. There are, however, several ways to dig one level deeper and provide more insights not only on the size of the change, but also on the mechanisms behind observed growth. One useful approach to improve our understanding of a change in a variable is to decompose the change keeping one aspect of change constant. This approach is actually very simple. Let us start with an example.

Imagine that we observe, that the number of children born in the UK is decreasing (that is our \(X\)). The number of children born is a function of the number of children born per woman, also known as the General Fertility Rate (GFR). We denote the number of women (that is \(Y\)), such that the general fertility rate is \(X/Y\), the number of children born per woman. Let now write down the change in the number of children born from period 0 to period 1:

\begin{align}
   X_1-X_0=Y_1\frac{X_1}{Y_1}-Y_0\frac{X_0}{Y_0}
 \end{align}

Now let's do some trivial and silly adding and subtraction. First, add and subtract the term \(Y_0\frac{X_1}{Y_1}\) and rearrange:

\begin{align}
   X_1-X_0=&Y_1\frac{X_1}{Y_1}-Y_0\frac{X_0}{Y_0}+Y_0\frac{X_1}{Y_1}-Y_0\frac{X_1}{Y_1}\nonumber\\
        =&Y_1\frac{X_1}{Y_1}-Y_0\frac{X_0}{Y_0}+Y_0\frac{X_1}{Y_1}-Y_0\frac{X_1}{Y_1}\nonumber\\
        =&\overbrace{Y_0\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)}^{\text{A}}+\overbrace{(Y_1-Y_0)\frac{X_1}{Y_1}}^{\text{B}}\nonumber
\end{align}

The first term of this expression (A) is the change in \(X\) if \(Y\) stayed constant at the initial level, but the rate \(X/Y\) changed. In terms of our births example above, this expression gives us the change in births if the number of women stays constant, but the fertility rate changes. The second term above gives us the opposite. What would the change in births be if we kept the fertility rate constant, but changed the number of women in the population? So with this simple exercise we can decompose a change in \(X\) into the changes in two underlying factors. However, there is one problem with this equation. We are keeping \(Y\) constant at the initial level and the ratio \(X/Y\) constant at the new level. Could we somehow keep both constant at the initial level? Yes. Let us add and subtract \((Y_1-Y_0)\frac{X_0}{Y_0}\):

\begin{align}
   X_1-X_0=&Y_0\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)+(Y_1-Y_0)\frac{X_1}{Y_1}+(Y_1-Y_0)\frac{X_0}{Y_0}-(Y_1-Y_0)\frac{X_0}{Y_0}\nonumber\\
&=\overbrace{Y_0\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)}^{A}+\overbrace{\left(Y_1-Y_0\right)\frac{X_0}{Y_0}}^{B}+
  \overbrace{\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)\left(Y_1-Y_0\right)}^{C}
 \end{align}

By adding and subtracting terms, we now have an expression for the change in \(X\) based on three terms.

\begin{itemize}
\tightlist
\item
  Term A is as before: The change in X as a result of keeping \(Y\) constant at the initial level, but changing the ratio \(X/Y\)
\item
  Term B is as new: The change in X as a result of keeping the ratio \(X/Y\) constant at the initial level, but changing \(Y\).
\item
  The term C is new: A composite effect. This term captures the effect that a different level of \(Y\) is exposed to a different level \(X/Y\).
\end{itemize}

Why is this helpful? By decomposing changes we can make statements such as: ``The number of live births did not only increase because fertility increased, but also because the number of women in childbearing ages increased.'' Another area where decompositions are often used is in labor supply. The total labor supply in the number of hours is a function of the number of people working, and how many hours these people work. We could for example imagine, that we observe a drop in labor supply, without observing any changes in the number of people working, simply because people start working less. \citep{csr} provides more details on how to decompose changes, including how to recompose changes of variables with more than two underlying factors.

\hypertarget{removing-noise}{%
\section{Removing noise}\label{removing-noise}}

Figure \ref{fig:desc4} shows the monthly unemployment for the UK, just like Figures \ref{fig:desc1} and \ref{fig:desc2}. But the chart in Figure \ref{fig:desc4} looks different, it fluctuates much more. The key difference is that while Figures \ref{fig:desc1} and \ref{fig:desc2} were seasonally adjusted, Figure \ref{fig:desc4} shows the ``raw'' unadjusted unemployment rate.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_describe/ex2_1} 

}

\caption{Monthly unemployment in the United Kingdom. Source: OECD, Short-Term Labour Market Statistics, Harmonised Unemployment rate. Not seasonally adjusted. Y-Axis truncated at 4 percent.}\label{fig:desc4}
\end{figure}

What does seasonally adjusted mean? Many aspects of the economy have seasons. Private consumption is for example often very high in December, there are relatively few people starting new jobs in the summer months, and so on. When looking at changes in unemployment from month to month we are often not interested in the changes that are caused by changes in seasons.

Statistical agencies have developed very sophisticated methods for identifying and removing seasonal effects. It is typically possible to directly obtain the seasonally adjusted series directly from the statistical offices. So often, we won't have to seasonally adjust our series manually. Nevertheless, it is important to understand the intuition behind seasonal adjustments. We will therefore go through a simplified version the seasonal adjustment procedure, which we can apply to our own data.

\hypertarget{moving-averages}{%
\subsection*{Moving averages}\label{moving-averages}}
\addcontentsline{toc}{subsection}{Moving averages}

Before we turn to the seasonal adjustment algorithm, let us consider the simple, but powerful concept of a moving average. Moving averages can be useful in itself, but they are also useful on their own. In Figure \ref{fig:desc4} we use data from the Organisation for Economic Cooperation and Development (OECD). As you can see from this graph, the unemployment rate fluctuates a lot from month to month. However, often we want to ignore these fluctuations that are caused by seasonality. What can we do? If you took a pen, you could draw a smooth line over Figure \ref{fig:desc4} and you would have a line that would be much more readable. How can we obtain the same in a more formal approach?

In Figure \ref{fig:desc5} we added the \emph{moving average} of the series shown in Figure \ref{fig:desc4}. With a moving average we compute averages of unemployment rates across five months and then move one month ahead and do the same and so on. In other words the shown unemployment rate in May is the average of the unemployment rate for March, April, May (center), June, and July. In that way we obtain a much more smooth unemployment rate, as the blue line. The moving average of the variable \emph{x} is then defined as:

\begin{align}
    ma_{5}(x)=\frac{x_{-2}+x_{-1}+x_{0}+x_{+1}+x_{+2}}{5}
  \end{align}
\textbackslash begin\{figure\}{[}!ht{]}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_describe/ex2_2} 

}

\caption{Monthly unemployment in the United Kingdom. Source: OECD, Short-Term Labour Market Statistics, Harmonised Unemployment rate.  Y-Axis truncated at 4 percent.}\label{fig:desc5}
\end{figure}

It will often be ``sufficient'' just to apply the moving average to a time-series. The moving average removes a lot of short-run fluctuations. However, we might actually have removed too much. That is why we need a more formal approach to cleaning the series.

\hypertarget{seasonally-adjustment}{%
\subsection*{Seasonally adjustment}\label{seasonally-adjustment}}
\addcontentsline{toc}{subsection}{Seasonally adjustment}

\hypertarget{decomposing-a-series}{%
\subsubsection*{Decomposing a series}\label{decomposing-a-series}}
\addcontentsline{toc}{subsubsection}{Decomposing a series}

Let us now consider the idea of identifying and removing seasonal effects. Let us assume that we can write the data series in additive terms, as follows:

\begin{align}
  Y_t=S_t+T_t+E_t
\end{align}

\begin{itemize}
\tightlist
\item
  The seasonal component \(S\)
\item
  The trend component \(T\)
\item
  The error component \(E\)
\end{itemize}

where \(Y_t\) is the aggregate raw series, \(S_t\) is the seasonal component, \(T_t\) is the trend component and \(E_t\) is the irregular (or error) component.\footnote{Note that it is common to also include \(C_t\), a cyclical component.} We want to remove \(S_t\) from the series. Before we move on, we should note that we assumed that an \emph{additive} decomposition was reasonable. It could also be the case that the terms should be included \emph{multiplicatively}. If for example the size of the seasonal component depends on the trend level, a multiplicative specification would be more appropriate.

Our goal is now to identify the seasonal effect and remove the seasonal effect from the original series. Most statistical offices apply advanced algorithms called X11ARIMA or X12ARIMA to identify the seasonal term. For this unit there is no need to understand the details behind these algorithms, but you should understand the intuition behind the X11 algorithm, which is the backbone of many advanced algorithms. The point of departure for the X11-algorithm is the moving average. Let us now go through a simplified explanation of the X11-algorithm.

\hypertarget{step-1-identify-the-trend-level}{%
\subsubsection*{Step 1: Identify the trend level}\label{step-1-identify-the-trend-level}}
\addcontentsline{toc}{subsubsection}{Step 1: Identify the trend level}

The first step of the X11-algorithm is to identify the trend level. We do that by removing the seasonal term and the error term (and the cyclical term) from the original series by means of a moving average, this leaves us with the trend level. So the blue series in Figure \ref{fig:desc5} correspond to \(T_t\) in the decomposition equation above.

\hypertarget{step-2-subtract-the-trend-level-from-the-raw-series-to-obtain-a-series-containing-the-seasonal-and-irregular-components.}{%
\subsubsection*{Step 2: Subtract the trend level from the raw series to obtain a series containing the seasonal and irregular components.}\label{step-2-subtract-the-trend-level-from-the-raw-series-to-obtain-a-series-containing-the-seasonal-and-irregular-components.}}
\addcontentsline{toc}{subsubsection}{Step 2: Subtract the trend level from the raw series to obtain a series containing the seasonal and irregular components.}

We now have two series. We have the original series \(Y_t\) and the trend series \(T_t\). If we subtract \(T_t\) from \(Y_t\) we get a series that contains the seasonal term and the error term. Applying this to the unemployment series from Figure @ref\{fig:desc4\} leads to the series shown in Figure \ref{fig:desc6}.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_describe/ex2_4} 

}

\caption{The residual series: The raw unemployment rate minus the five month moving average. November and December are marked with red. Green crosses show the three period moving average of the December residual. Source: OECD, Short-Term Labour Market Statistics, Harmonised Unemployment rate.}\label{fig:desc6}
\end{figure}

\hypertarget{step-3-apply-the-moving-for-each-reoccurring-period-to-obtain-estimates-of-the-seasonal-component-of-that-period.}{%
\subsubsection*{Step 3: Apply the moving for each reoccurring period to obtain estimates of the seasonal component of that period.}\label{step-3-apply-the-moving-for-each-reoccurring-period-to-obtain-estimates-of-the-seasonal-component-of-that-period.}}
\addcontentsline{toc}{subsubsection}{Step 3: Apply the moving for each reoccurring period to obtain estimates of the seasonal component of that period.}

The residual series shown in Figure \ref{fig:desc6} includes both the seasonal effect and the error component. How can we remove the seasonal effect? Seasonal effects are effects that occur because of the specific season. So it is an ``effect'' that happens every December or every July. In other words, we would like to identify the effect that is common across the Decembers and Julys in our series. As each December or July also include the error components, we apply a new average but this time only across the specific months. The green crosses in Figure \ref{fig:desc4} show the three period moving average of the residual. The moving averages are our estimates of the seasonal component for December. We can do this for all months to obtain a series of estimates of the monthly seasonal component.

\hypertarget{step-4-subtract-the-seasonal-components-from-the-raw-data-to-obtain-a-first-estimate-of-the-seasonally-adjusted-series.}{%
\subsubsection*{Step 4: Subtract the seasonal components from the raw data to obtain a first estimate of the seasonally adjusted series.}\label{step-4-subtract-the-seasonal-components-from-the-raw-data-to-obtain-a-first-estimate-of-the-seasonally-adjusted-series.}}
\addcontentsline{toc}{subsubsection}{Step 4: Subtract the seasonal components from the raw data to obtain a first estimate of the seasonally adjusted series.}

We are now ready to obtain a first estimate of the seasonally adjusted unemployment rate by taking the raw series and subtracting our series of estimated monthly seasonal components.

\hypertarget{step-5-repeat}{%
\subsubsection*{Step 5: Repeat!}\label{step-5-repeat}}
\addcontentsline{toc}{subsubsection}{Step 5: Repeat!}

We are not done yet, in fact we will apply the same procedure again, at least once. Moreover it is also very common to use weighted moving averages (Such as the Henderson Filter) to obtain estimates of the moving averages. In the example above we used a five period moving average for the first step, and 3 period moving averages for the second step. Most statistical agencies apply moving averages of the length corresponding to the frequency of the seasonal component, that is, for a quarterly series we will apply a four period moving average and for a monthly series we will apply a twelve period moving average.

\hypertarget{the-resulting-seasonally-adjusted-series}{%
\subsubsection*{The resulting seasonally adjusted series}\label{the-resulting-seasonally-adjusted-series}}
\addcontentsline{toc}{subsubsection}{The resulting seasonally adjusted series}

Figure \ref{fig:desc7} adds the seasonally adjusted unemployment rate from the OECD data to the graph. Note that the seasonally adjusted line is more smooth than the raw data, but less smooth than the moving average.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_describe/ex2_3} 

}

\caption{Monthly unemployment in the United Kingdom. Source: OECD, Short-Term Labour Market Statistics, Harmonised Unemployment rate.  Y-Axis truncated at 4 percent.}\label{fig:desc7}
\end{figure}

The X11 algorithm was introduced by the US Bureau of the Census. It is still used by many statistical offices, although newer and more advanced methods are also in use today. One extension is the X11 ARIMA, which uses an Auto Regressive Moving Average to predict beyond the start and end of the time series, which is necessary to compute moving averages.

\hypertarget{data-processing}{%
\section{Data processing}\label{data-processing}}

When we talk about working with data we often talk about processing data, cleaning data, and tidying data. A recommended work-flow is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Obtain the raw file and save it (in a separate document, worksheet etc).
\item
  Process the data (clean the data).

  \begin{itemize}
  \tightlist
  \item
    Check whether all variables have titles, labels. etc.
  \item
    Check for obviously erroneous values.
  \item
    Make sure the data follows the tidy data principle.
  \item
    Create new variables based on the existing variables (sometimes also done in step 3).
  \end{itemize}
\item
  Analyze and visualize the data.
\end{enumerate}

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

In this chapter we covered the following topics

\begin{itemize}
\tightlist
\item
  How to describe graphs and tables.
\item
  Describing differences in terms of absolute and relative changes.
\item
  Computing average growth rates.
\end{itemize}

\begin{align}
   r&=\left(\frac{P_{tN}}{P_{t0}}\right)^{(1/N)}-1\nonumber
\end{align}

\begin{itemize}
\item
  Decomposing changes

  \begin{align}
  \Delta X=Y_0\left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)+\left(Y_1-Y_0\right)\frac{X_0}{Y_0}+
  \left(\frac{X_1}{Y_1}-\frac{X_0}{Y_0}\right)\left(Y_1-Y_0\right)\nonumber
  \end{align}
\item
  Creating and using an index.
\item
  Removing noise.
\end{itemize}

\hypertarget{data-visualization-basics}{%
\chapter{Data visualization basics}\label{data-visualization-basics}}

\hypertarget{what-this-chapter-is-about-9}{%
\section{What this chapter is about}\label{what-this-chapter-is-about-9}}

This chapter provides a brief introduction to good data visualization. We first go through an example to illustrate that ``How we show data matters''. We then describe principles for producing good data visualizations. The chapter is inspired by the following resources on data visualization.

\begin{itemize}
\tightlist
\item
  ``Show me the numbers'' \citep{few2012show}
\item
  ``Data visualization: a practical introduction'' \citep{healy2018data}
\item
  ``The truthful art: data, charts, and maps for communication'' \citep{cairo}
\item
  ``Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures'' \citep{wilke2019fundamentals}
\item
  ``The visual display of quantitative information'' \citep{tufte2001visual}
\end{itemize}

\hypertarget{how-we-show-data-matters}{%
\section{How we show data matters}\label{how-we-show-data-matters}}

\hypertarget{illustration-the-anscombe-quartet}{%
\subsection*{Illustration: The Anscombe quartet}\label{illustration-the-anscombe-quartet}}
\addcontentsline{toc}{subsection}{Illustration: The Anscombe quartet}

Once we've obtained the data we can start working with the data. A crucial principle in working with data is the simple principle represented by a famous quote by Edward Tufte: ``Above All Else Show the Data''. To illustrate why showing the data, and how we show the data is important, we can use an example from Edward Tufte's book, known as the Anscombe's quartet (Francis John Anscombe was an English statistician) \citep{tufte2001visual}. Consider the four datasets shown in Table \ref{tab:viz1}, what do you learn from this table (X1 and Y1 are one dataset, X2 and Y2 are another dataset, and so on)? Hard to say?

It is difficult to tell anything about these datasets based on a table. This is one of the downsides of a table. A table is very useful for showing precise numbers, but once there are too many numbers we start to lose the overview (this table has 88 numbers!).

\begin{longtable}[]{@{}cccccccc@{}}
\caption{\label{tab:viz1} Anscombe's quartet: raw data. What do we learn from this table?}\tabularnewline
\toprule
Dataset 1 & & Dataset 2 & & Dataset 3 & & Dataset 4 & \\
\midrule
\endfirsthead
\toprule
Dataset 1 & & Dataset 2 & & Dataset 3 & & Dataset 4 & \\
\midrule
\endhead
X1 & Y1 & X2 & Y2 & X3 & Y3 & X4 & Y4 \\
10.00 & 8.04 & 10.00 & 9.14 & 10.00 & 7.46 & 8.00 & 6.58 \\
8.00 & 6.95 & 8.00 & 8.14 & 8.00 & 6.77 & 8.00 & 5.76 \\
13.00 & 7.58 & 13.00 & 8.74 & 13.00 & 12.74 & 8.00 & 7.71 \\
9.00 & 8.81 & 9.00 & 8.77 & 9.00 & 7.11 & 8.00 & 8.84 \\
11.00 & 8.33 & 11.00 & 9.26 & 11.00 & 7.81 & 8.00 & 8.47 \\
14.00 & 9.96 & 14.00 & 8.10 & 14.00 & 8.84 & 8.00 & 7.04 \\
6.00 & 7.24 & 6.00 & 6.13 & 6.00 & 6.08 & 8.00 & 5.25 \\
4.00 & 4.26 & 4.00 & 3.10 & 4.00 & 5.39 & 19.00 & 12.50 \\
12.00 & 10.84 & 12.00 & 9.13 & 12.00 & 8.15 & 8.00 & 5.56 \\
7.00 & 4.82 & 7.00 & 7.26 & 7.00 & 6.42 & 8.00 & 7.91 \\
5.00 & 5.68 & 5.00 & 4.74 & 5.00 & 5.73 & 8.00 & 6.89 \\
\bottomrule
\end{longtable}

There are a few things we could do to improve the readability of Table \ref{tab:viz1}, for example sort all series by their x values, but it would still be difficult to identify the patterns in the data. Another strategy is to calculate some simple statistics for these four datasets, and include them in a Table. Table \ref{tab:viz2} shows the arithmetic mean for every variable, the Pearson correlation coefficient between each X and Y variable, the slope and the intercept and the R-squared of the fitted regression line. These statistics all look very similar across the four datasets. Note how important the way we show the data is. If we had only seen Table \ref{tab:viz2} we would be inclined to conclude that these four datasets are very similar. If we had only seen Table \ref{tab:viz1}, we would probably conclude that the datasets are quite different.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0968}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}
  >{\centering\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1290}}@{}}
\caption{\label{tab:viz2} Anscombe's quartet: Simple descriptive statistics suggest that the datasets are very similar.}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Dataset 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Dataset 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dataset 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} \\
\midrule
\endhead
X1 & Y1 & X2 & Y2 & X3 & Y3 & X4 & Y4 \\
Mean & 9.0 & 7.5 & 9.0 & 7.5 & 9.0 & 7.5 & 9.0 \\
Pearson's r & 0.82 & & 0.82 & & 0.82 & & 0.82 \\
Regression line (OLS) & & & & & & & \\
Intercept & 3.00 & & 3.00 & & 3.00 & & 3.00 \\
Slope & 0.50 & & 0.50 & & 0.50 & & 0.50 \\
R\(^{2}\) & 0.67 & & 0.67 & & 0.67 & & 0.67 \\
\bottomrule
\end{longtable}

Finally, let's look at the data using charts. Figure \ref{fig:viz3} shows the same four datasets by means of scatterplots. By means of these scatterplots you immediately see the difference between the four datasets. We also note that the fitted line is the same in the four datasets (as suggested by the coefficients in Table \ref{tab:viz2}, although the underlying relationship between the Y and the X variables are very different.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./resources/chapter_viz/ex1_1} \includegraphics[width=0.5\linewidth]{./resources/chapter_viz/ex1_2} \includegraphics[width=0.5\linewidth]{./resources/chapter_viz/ex1_3} \includegraphics[width=0.5\linewidth]{./resources/chapter_viz/ex1_4} 

}

\caption{scatterplots of Anscombe's quartet. The dashed line is fitted using Ordinary Least Squares. Upper left: Dataset 1. Upper right: Dataset 2. Lower left: Dataset 3. Lower right: Dataset 4.}\label{fig:viz3}
\end{figure}

The takeaway from this example is that the way we represent data is important. It is not always the most complicated or advanced method that is the best. In this example, presenting regression coefficients and several moments of the data would give the misleading message that the four datasets are very similar, when in fact they are very different. So let us consider some simple rules for visualizing data.

\hypertarget{tables-vs-charts}{%
\section{Tables vs charts}\label{tables-vs-charts}}

\hypertarget{the-goal-of-the-visualization}{%
\subsection*{The goal of the visualization}\label{the-goal-of-the-visualization}}
\addcontentsline{toc}{subsection}{The goal of the visualization}

So we know that how we show data matters, and that the objective of the optimal data visualization method depends on the purpose of the visualization. Let us now start thinking about how we would like to show our data. At this point it is useful to take a step back and think about the how graphs and tables work:

\begin{itemize}
\tightlist
\item
  A \textbf{chart} typically contains at least one axis, the *\textbackslash textbf\{\textbf{ values are represented in terms of visual objects} (dots, lines, areas, bars) and axes typically have scales or labels.
\item
  A \textbf{table} on the other hand typically contains rows and columns, and the \textbf{values are represented by text}.
\end{itemize}

Because tables use text to represent values, showing thousands of values implies that the reader is expected to read thousands of values and remember how they relate to each other, and their exact values. This is clearly not optimal. It is a quite demanding task. On the other hand, if we use a chart, the reader has to read visual aspects such as the position of objects, the size of objects, or the colour of objects. This is somewhat easier with thousands of observations, compared to a chart. For example, if we move from left to right on the horizontal axes, are the objects positioned further up or further down on the vertical axis.

Therefore, if we are only interested in whether observations are similar (i.e.~the pattern) graphs are more efficient. However, if you want the exact value of an observation graphs do not work well. It is hard to infer the exact value based on shapes, colours and positions.

There are many ways to visualize data, and providing principles and rules for each visualization approach would not be very useful (and not very valid). Instead, we will provide some principles for groups of visualization methods. The first two groups we will consider (and the most important distinction): are tables and graphs. In the Anscombe example above, a graph was clearly a better way to visualize data if the goal was to understand the pattern in the data. However, if we instead were interested in comparing the means across the four datasets, Table \ref{tab:viz2} would clearly be ideal. It is very hard to read the means from the graphs in Figure \ref{fig:viz3}. So the first decision rule is as follows:

\begin{itemize}
\tightlist
\item
  If we are interested in exploring, analyzing or communicating \textbf{patterns} in the data, \textbf{charts} are more useful than tables.
\item
  If we are interested exploring, analyzing or communicating \textbf{specific numbers} in the data, \textbf{tables} are more useful than graphs. In other words, if we want to look up a specific value or compare values, a table is more useful than a graph.
\end{itemize}

In general a table is very useful if we want to show a few very precise numbers (i.e.~decimal points). A table also has the advantage of being able to combine several different types of values (for example the statistics for the Anscombe example in Week 1).

\hypertarget{the-quantity-of-data}{%
\subsection*{The quantity of data}\label{the-quantity-of-data}}
\addcontentsline{toc}{subsection}{The quantity of data}

We might not a-priori know whether we are more interested in patterns or specific values. Consider the four datasets in the Anscombe example. We are simply interested in comparing these datasets. The reason Table \ref{tab:viz2} works poorly is that we are overloaded with information: eight columns with ten observations of values = eighty values. Comparing all these eighty values to each other takes time and is cognitively demanding, so this way of presenting data is not ideal.

\begin{itemize}
\tightlist
\item
  \textbf{charts} are typically more useful than tables in situations with \textbf{many data points}.
\end{itemize}

\hypertarget{table-design}{%
\section{Table design}\label{table-design}}

In some cases we might have large tables with a lot of numbers that work well. Figure \ref{fig:viz4} shows an example of a (famous) large table that works well.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{./resources/chapter_viz/figecon} 

}

\caption{An example of a table from the magazine 'The Economist'}\label{fig:viz4}
\end{figure}

So why does Figure \ref{fig:viz4} work well? Because we use it to look up numbers, it uses good table design and it clearly directs the reader to specific information.
We will return to the issue of table and graph design below. The main takeaway here is that when choosing between a table and a graph it is worth considering the amount of data to visualize and whether the purpose of the visualization is to visualize patterns or specific values.

\hypertarget{table-structure}{%
\subsection*{Table structure}\label{table-structure}}
\addcontentsline{toc}{subsection}{Table structure}

A table is organized in rows and columns. While the table representation therefore by definition is two dimensional, the table can be highly complex. At least one of the dimensions is typically numerical. The other dimension(s) might be categorical or also numerical.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{./resources/chapter_viz/tab1} 

}

\caption{A table with a categorical variable in rows and a numerical variable in columns}\label{fig:viz5}
\end{figure}

The table shown in Figure \ref{fig:viz5} is an example of a table where we have a categorical variable (products) and a numerical variable (value). We could easily add another categorical dimension to the table, by showing the value for different areas as in the table shown in Figure \ref{fig:viz6} , where we have product (categorical), area (categorical) and value (numerical).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{./resources/chapter_viz/tab2} 

}

\caption{A table with one numerical variable and two categorical variables}\label{fig:viz6}
\end{figure}

We can make the table slightly more complex by adding another hierarchical dimension. In other words there is some specific ordering of the categorical variables: ``A 2.2'' is a sub-area of ``Area 2''. We cannot just move ``A 2.1'' to ``Area 1''. A hierarchical table structure gives insights into ``conditionals'': For example, what is the average wage for a bus driver, conditional on being a woman?

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/tab3} 

}

\caption{A table with a hierarchical structure.}\label{fig:viz7}
\end{figure}

Tables can be outlined in different ways to optimize space and readability. In a \emph{unidirectional} approach categorical values are organized along one dimension. In a \emph{bidirectional} table, categorical values are organized along both rows and columns. The table shown in Figure @(fig:viz7) is a bidirectional table. We have Product categories down the rows and areas across columns. This layout saves is slightly more space and ink efficient. Can you redesign the same table to be bidirectional? Why is the table not as efficient in terms of space and ink?

To summarize, when designing a table it is worth first considering the dimensions in the data you would like to show. How many dimensions are there? Are they structured in hierarchical order? Figure @(fig:viz8) provides two table examples. The tables represent the same underlying data. One of them is doing a good job, the other not. Why not?

\begin{figure}

{\centering \includegraphics[width=0.48\linewidth]{./resources/chapter_viz/poor} \includegraphics[width=0.48\linewidth]{./resources/chapter_viz/good} 

}

\caption{A poorly designed and structured table and a table with a good structure and layout.}\label{fig:viz8}
\end{figure}

\hypertarget{table-layout-and-design}{%
\subsection*{Table layout and design}\label{table-layout-and-design}}
\addcontentsline{toc}{subsection}{Table layout and design}

It is clearly not only the structure that makes one of the tables in @(fig:viz8) good and the other one bad. The table on the left is clearly also better designed. Once we have organized our table in rows and columns, there are a number of layout features that you can adjust to improve the readability of the table. Below is a short list of design aspect to consider when designing a table.

\begin{itemize}
\item
  Columns and rows can be separated using \textbf{lines}, \textbf{white space} and \textbf{colours}. These approaches can also be used to group and highlight observations.
\item
  When formatting text we should carefully consider the \textbf{alignment}, \textbf{font type}, and \textbf{orientation}. For example, a column with quantitative values of varying widths (i.e.~varying number of digits) will be difficult to read if it is centered (right alignment is much easier to read ).
\item
  Values that summarize other values in the table should be \textbf{distinct} (by font, lines, colours, etc.).
\item
  Tables that span several pages should \textbf{repeat} titles, and column and row headers on each page.
\end{itemize}

\hypertarget{chart-design}{%
\section{Chart design}\label{chart-design}}

\hypertarget{basic-chart-structure}{%
\subsection*{Basic chart structure}\label{basic-chart-structure}}
\addcontentsline{toc}{subsection}{Basic chart structure}

While tables are organized in columns and rows, charts are typically organized in two to three axes. Most graphs have two axes: a horizontal axis (the x-axis) and a vertical axis (the y-axis). The number of data dimensions (i.e.~variables) shown in a chart is limited by the number of axes. With only two axes the graph can only represent two variables. The variable shown on the y-axis (for example unemployment) and the value shown on the x-values (for example time measured in quarters).

As charts often visualize large quantities of information, it is therefore important to prioritize clarity and simplicity. Graphs with a third ``depth'' axis (z-axis) are therefore still relatively rare least in popular media. However, graphs with a second vertical axis (typically on the right) are not uncommon.

\hypertarget{how-charts-work}{%
\subsection*{How charts work}\label{how-charts-work}}
\addcontentsline{toc}{subsection}{How charts work}

As described, charts use visual objects to represent values. But not all charts use the same tool to visualize values. Generally speaking, we can divide the chart into two types by how they visualize values:

\begin{itemize}
\item
  \textbf{Values} are represented by their \textbf{position relative to the axes}. Popular examples are line charts and scatterplots.
\item
  \textbf{Values} are represented by the \textbf{size of an area}: Popular examples are bar charts and area charts. A popular example that you typically should avoid is a pie chart (more on that later).
\item
  \textbf{Values} are represented by the \textbf{colour} or \textbf{shape/symbol}: Popular examples are scatterplots, where observations related to the same group use the same symbol. In all chart types, we use colours and shapes to group the data.
\item
  Values are \textbf{continuous} \(\rightarrow\) use chart type that visually \textbf{connects} elements, for example a line chart.
\item
  Values are \textbf{categorical} \(\rightarrow\) use chart type that visually \textbf{separates} elements, for example a bar chart.
\end{itemize}

Why is this important to think about how charts (and tables) work? First of all, when using a specific chart type it is important to know how this type of chart represents values in the chart design. Cutting the y-axes for a bar chart is therefore in principle often a poor idea, because the bar chart uses the size of the area to show the value of the variable. Secondly, when selecting a graph type it is important to think about how the values are represented.

\hypertarget{common-chart-types}{%
\subsection*{Common chart types}\label{common-chart-types}}
\addcontentsline{toc}{subsection}{Common chart types}

There are my graph types that use combinations of the methods described above (position of symbols, shapes and areas) to visualize data. We will not cover all graph types, but focus on some general guiding principles. We will return to many of these graphs later on in the unit. But for now, we will focus on four common graph types. Figure \ref{fig:viz9} shows a bar chart of the most popular data representation methods based on a small survey of three editions of the magazine The Economist. The Figure shows that line charts are used in almost every second data representation in these editions of The Economists.

\begin{figure}

{\centering \includegraphics[width=0.48\linewidth]{./resources/chapter_viz/econhist} 

}

\caption{Data representations in 'The Economist'. Data source: Own survey  of three volumes of The Economist.}\label{fig:viz9}
\end{figure}

\hypertarget{the-line-chart}{%
\subsubsection*{The line chart}\label{the-line-chart}}
\addcontentsline{toc}{subsubsection}{The line chart}

Why are line charts so popular? Let us first describe the line chart (for the case with two values):
* The vertical position of the line represents the y-value.
* The horizontal position of the line represents the x-value.
* The line chart \textbf{connects the visual elements} and thereby provides an impression of a continuous change.
* (i.e.~meaningful if there could be values between these points)
* The line chart is typically used to show the relationship between two numerical variables.
* The line chart is typically read from left to right, and gives the reader an interpretation of development.

The two last points are crucial. Connecting two categorical groups rarely makes any sense. Figure \ref{fig:viz10} for example, shows the values used in \ref{fig:viz9} using a line chart. With a line chart, we are naturally inclined to look at the change, from left to right, and less likely to focus on the group comparison (as with a bar chart). As there is no obvious ordering of the groups on the x-axis, the interpretation of a decline, from left-to-right is meaningless. In other words, a line chart is a powerful message if we want to illustrate a continuous change, for example over time).

\begin{figure}

{\centering \includegraphics[width=0.48\linewidth]{./resources/chapter_viz/econline} 

}

\caption{Data representations in 'The Economist' using a line chart. Data source: Own survey  of three volumes of The Economist.}\label{fig:viz10}
\end{figure}

\hypertarget{the-bar-chart}{%
\subsubsection*{The bar chart}\label{the-bar-chart}}
\addcontentsline{toc}{subsubsection}{The bar chart}

Let us now consider the second most popular chart type, the bar chart. Let us make the same list we created for the line chart for the bar chart:

\begin{itemize}
\tightlist
\item
  represents the data value by means of a \textbf{separated graphical element}.
\item
  can be used for categorical variables, because the values are not connected and clearly distinct.
\item
  y-axis should, whenever possible, start at zero (or other logical reference levels).
\item
  can be shown both vertically and horizontally.
\item
  can show several data series for the same categorical variable.
\end{itemize}

\hypertarget{maps}{%
\subsubsection*{Maps}\label{maps}}
\addcontentsline{toc}{subsubsection}{Maps}

Showing data in maps can provide new insights and reveal patterns. For example that cholera deaths are clustered around pumps like in the map created by John Snow, as shown in Figure \ref{fig:viz155}.\footnote{Source: \href{https://en.wikipedia.org/wiki/John_Snow\#/media/File:Snow-cholera-map-1.jpg}{Wikipedia}}

\begin{figure}

{\centering \includegraphics[width=0.48\linewidth]{./resources/chapter_viz/Snow-cholera-map-1} 

}

\caption{John Snow's map of Cholera deaths in central London. Each line represents a death.Each circle represents a water pump. Source: Wikipedia.}\label{fig:viz155}
\end{figure}

\textbf{How do we show data on maps?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Dot-density maps, where each observation (a cholera death) is indicated by a dot (or similar marker). \(\Rightarrow\) higher density of pubs \(=\) higher frequency.
\item
  Choropleth maps, where data is aggregated to geographic areas with specific boundaries (often administrative units such as countries, regions, and counties). The value is shown by the colour of the unit.
\item
  Combining standard chart types with maps. For example bar charts are placed on maps.
\end{enumerate}

\hypertarget{charts-to-avoid}{%
\subsection*{Charts to avoid}\label{charts-to-avoid}}
\addcontentsline{toc}{subsection}{Charts to avoid}

Unfortunately, there exists a wide range of non-functional charts that are widely used. Chapter 12 in \citep{few2012show} provides a good discussion of charts that ``are best forsaken'':

\hypertarget{pie-charts}{%
\subsubsection*{Pie charts}\label{pie-charts}}
\addcontentsline{toc}{subsubsection}{Pie charts}

Donut charts and pie charts are very popular chart types, but they are very often inefficient ways of fractions. First of all, these charts should only be used when showing ``part-of-a-whole''. Secondly, while donut charts and pie charts are ``cute'', they are very inefficient, especially when we want to compare the size of the pie (or donut) pieces to each other or to pieces in other donuts.

\hypertarget{charts-with-3d-effects}{%
\subsubsection*{Charts with 3D effects}\label{charts-with-3d-effects}}
\addcontentsline{toc}{subsubsection}{Charts with 3D effects}

3D effects are very popular, but as general advice: charts should never have more dimensions than the dimensions in the data. If you have two dimensions in your data, your chart should be two dimensional. If you have three dimensions in your data, the chart could potentially have 3 dimensions. 3D charts based on 3 variables are fascinating, but it can be challenging to interpret them.

So should you completely avoid all charts listed in chapter 12 of \citep{few2012show} ? There is no chart police (yet), but the point of this discussion is that several chart types are inefficient and they often can be replaced by simple line or bar charts. This might seem boring and you might want to use various chart types to keep the readers' attention, but remember the point by Cairo: They should be functional

\hypertarget{lies-junk-and-non-data-ink.}{%
\section{Lies, junk and non-data ink.}\label{lies-junk-and-non-data-ink.}}

\hypertarget{tuftes-concepts-for-good-data-visualizations.}{%
\subsection*{Tufte's concepts for good data visualizations.}\label{tuftes-concepts-for-good-data-visualizations.}}
\addcontentsline{toc}{subsection}{Tufte's concepts for good data visualizations.}

In his seminal work on data visualizations Edward Tufte introduced a number of concepts for good (or bad) data visualizations. We will here briefly discuss the most important ones.

\hypertarget{the-lie-factor}{%
\subsubsection*{The Lie Factor}\label{the-lie-factor}}
\addcontentsline{toc}{subsubsection}{The Lie Factor}

Recall above that charts use visual tools to represent the value of the data point. But what if we make the bar in a bar chart slightly larger than it is supposed to be according to the value it represents? We are then distorting the visualization and misleading the reader. We can quantify the size of this \emph{lie} by means of the Lie Factor \citep[p.~57 in][]{tufte2001visual}.
\begin{align}
    \text{Lie Factor}=\frac{\text{size of effect shown in graphic}}{\text{size of effect in data}}
\end{align}

According to Tufte, Lie Factors below 0.95 or above 1.05 are signs of substantial distortion, that cannot be attributed to inaccuracies in the production of the chart.

\hypertarget{data-ink-ratio}{%
\subsubsection*{Data-ink ratio}\label{data-ink-ratio}}
\addcontentsline{toc}{subsubsection}{Data-ink ratio}

Edward R. Tufte's quote ``Above All Else Show the Data'' \citep{tufte2001visual} focuses on what we should show: the data. But the quote also implicitly hints at what we should not show (``above all else''): the non-data part. We can quantify what we show in terms of the ``ink'' used (if it was printed on paper), and our objective should be to maximize the amount of data we show relative to the amount of ink we use. This concept, and the idea of the data-ink ratio can also be attributed to Tufte. We can formally think of the data-ink ratio as follows \citep{tufte2001visual}:

\begin{align}
  \text{Data-ink Ratio}=\frac{\text{data-ink}}{\text{total ink used to print the graphic}}
\end{align}

We should aim at maximizing this ratio. In other words we should maximize the amount of data we show relative to the amount of ink (or attention) we use. While we rarely will use this equation literally, it is a very useful concept to have in mind when designing graphs and tables. A very approachable way to work with this concept is given by \citep{few2012show}, who suggests that we always conduct the following steps (my personal rewriting of the steps):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reduce the ink that is not related to data.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Remove unnecessary non-data ink.
\item
  De-emphasize the remaining data ink
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Enhance the ink that is directly related to data.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Remove unnecessary non-data ink.
\item
  Emphasize the most important data ink.
\end{itemize}

Let's try this in practice. Figure \ref{fig:viz12} shows a bar chart that does a poor job of communicating the data.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/ex0_1} 

}

\caption{A bar chart with a low data ink ratio}\label{fig:viz12}
\end{figure}

Let's follow the instructions above to improve the chart in Figure \ref{fig:viz12} by \emph{removing unnecessary non-data ink}. We removed the background and borders. This is unnecessary ink that has nothing to do with the data. This gives us the chart shown in Figure \ref{fig:viz13}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/ex0_2} 

}

\caption{The bar chart after removing the background and borders.}\label{fig:viz13}
\end{figure}

Removing the background already improved the data-ink ratio, but there is scope for more. We can also remove the 3D effect. This is unnecessary ink that has nothing to do with the data, and only makes the chart more difficult to read. We can also remove the glow and filling effects. The resulting chart is shown in Figure \ref{fig:viz14}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/ex0_4} 

}

\caption{The bar chart after removing the 3D effects.}\label{fig:viz14}
\end{figure}

Compare Figure \ref{fig:viz14} to Figure \ref{fig:viz12}. The data-ink ratio is clearly improved. But there is scope for more. We can also remove the grid lines and the legend. Grid lines and tick marks can sometimes be helpful, but in this case I think they can be removed. We only show one data series here, so there is no need to show a legend explaining what refers to what.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/ex0_5} 

}

\caption{The bar chart after removing the grid lines and the legend.}\label{fig:viz15}
\end{figure}

The visualisation in Figure \ref{fig:viz15} is already fairly good, but we can improve the data-ink ratio by following the second steps and '' Enhance the ink that is directly related to data.''. We enhance the data by adding value labels. And because all the non-data ink is now removed. We can also increase the font size and thereby the readability of the actual data. We also added an axis title (``Unit'') as this is part of the data. The ``final'' chart is shown in Figure \ref{fig:viz16}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{./resources/chapter_viz/ex0_6} 

}

\caption{The bar chart after emphasizing the data.}\label{fig:viz16}
\end{figure}

Compare Figure \ref{fig:viz12} to Figure \ref{fig:viz16} we quickly realize how much easier it is to learn what the data says in the latter chart. It might look more boring (I admit, Figure \ref{fig:viz12} was quite ugly), but it is much more efficient. The chart is, however, not self-explanatory. Can you identify what is missing?

\hypertarget{chartjunk}{%
\subsubsection*{Chartjunk}\label{chartjunk}}
\addcontentsline{toc}{subsubsection}{Chartjunk}

Chartjunk captures all elements of a chart that are unrelated to the data information provided by the chart. By maximizing the data-ink ratio we can often minimize chart-junk. However, not all chartjunk is bad. In fact, in some (rare) examples chartjunk improves the readability of the chart and makes it more memorable.

One of the most common examples of chart-junk is when the author includes graphical elements related to the topic of the chart: ``If the chart is about students, then we want the chart to consist of students.'' or ``If the chart is about childbirths, let us include babies in the graph''. This very rarely works well. Charts are first and foremost meant to communicate quantitative information.

\hypertarget{alberto-cairos-principles-of-good-data-visualizations}{%
\subsubsection*{Alberto Cairo's principles of good data visualizations}\label{alberto-cairos-principles-of-good-data-visualizations}}
\addcontentsline{toc}{subsubsection}{Alberto Cairo's principles of good data visualizations}

The graphical journalist Alberto Cairo provides an excellent ``summary'' of what characterizes great data visualization. This summary is based on the book ``The Truthful Art'' by Alberto Cairo \citep{cairo}. The summary consists of five qualities that great data visualization should satisfy. Great visualizations are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Truthful}
  The visualization is not based on fabricated data or manipulated data work.
\item
  \textbf{Functional}
  The visualization allows the reader to get a meaningful understanding of the data.
\item
  \textbf{Beautiful}
  The visualization is aesthetically enjoyable.
\item
  \textbf{Insightful}
  The visualization provides new evidence.
\item
  \textbf{Enlightening}
  The visualization affects how the reader thinks about the specific topic or relationship.
\end{enumerate}

\hypertarget{the-self-explanatory-data-visualization}{%
\section{The self-explanatory data visualization}\label{the-self-explanatory-data-visualization}}

Tables and charts should always be self-explanatory. Self-explanatory simply means that no explanation, beyond what is given in the chart or table is necessary to understand the visualisation.

\begin{itemize}
\tightlist
\item
  Chart and table titles: The title should explain what the data visualization shows.
\item
  Axes titles: Clearly describe what is shown on the axes (unless it is self-explanatory, such as dates).
\item
  Axes units: Clearly describe the measurement units used.
\item
  Legends/column headers: Clearly describe what each variable captures.
\item
  Source: Where does the data come from.
\end{itemize}

\hypertarget{a-cookbook-for-good-data-visualizations}{%
\section{A cookbook for good data visualizations}\label{a-cookbook-for-good-data-visualizations}}

We can summarize the principles for good data visualization using a ``cookbook'' type instructions.

\textbf{A cookbook for good data visualization}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Table or chart

  \begin{itemize}
  \tightlist
  \item
    Charts are typically more effective for large datasets.
  \item
    Charts are typically preferred for visualizing patterns and tables are often the best choice for showing exact values.
  \end{itemize}
\item
  Table structure/chart types

  \begin{itemize}
  \tightlist
  \item
    How many variables are we showing?

    \begin{itemize}
    \tightlist
    \item
      Charts are typically limited to two or three variables.
    \end{itemize}
  \item
    Are the variables continuous or categorical?

    \begin{itemize}
    \tightlist
    \item
      Avoid ``connected'' chart types if variables are categorical.
    \end{itemize}
  \end{itemize}
\item
  Maximize data-ink ratio and avoid lies

  \begin{itemize}
  \tightlist
  \item
    Tables: pay attention to the use of white space, solid lines, text alignment etc.
  \item
    Chart: Remove everything in the chart that is not related to the data and is not needed to understand the chart.
  \end{itemize}
\item
  Self-explanatory

  \begin{itemize}
  \tightlist
  \item
    Does the visualization contain everything needed to understand and replicate the chart?
  \item
    Are all axes clearly labelled? Is the source clearly stated?
  \end{itemize}
\end{enumerate}

\hypertarget{summary-3}{%
\section{Summary}\label{summary-3}}

In this chapter we covered some basics for good data visualization by going through the following topics

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  How we show data matters.
\item
  Tables and charts
\item
  Table structure and layout
\item
  Chart types and layout
\item
  The self-explanatory visualization.
\item
  A cookbook for a good data visualization.
\end{enumerate}

  \bibliography{book.bib,packages.bib}

\end{document}
